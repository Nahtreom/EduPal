import re
import requests
import os
import glob
import json
import hashlib
import concurrent.futures
import threading
from bs4 import BeautifulSoup
from exa_py import Exa
from api_call import process_text
import zipfile
import glob
import subprocess
from flask import request # è°ƒç”¨cosyvoice
import shutil # ç”¨äºç§»åŠ¨æ–‡ä»¶
from datetime import datetime
from werkzeug.utils import secure_filename # ä½¿ç”¨ werkzeug çš„ secure_filename ä¿è¯å®‰å…¨

# åˆå§‹åŒ– Exa API
EXA_API_KEY = '211ed197-9199-401d-9897-a8408526f8b8'
exa = Exa(EXA_API_KEY)

# ä¸‹è½½è¿›åº¦è·Ÿè¸ª
download_progress = {
    'total': 0,
    'completed': 0,
    'failed': 0,
    'status': 'idle'  # idle, downloading, completed
}
progress_lock = threading.Lock()

def get_download_progress():
    """è·å–ä¸‹è½½è¿›åº¦"""
    with progress_lock:
        return download_progress.copy()

def update_download_progress(completed=0, failed=0, status=None):
    """æ›´æ–°ä¸‹è½½è¿›åº¦"""
    with progress_lock:
        if completed > 0:
            download_progress['completed'] += completed
        if failed > 0:
            download_progress['failed'] += failed
        if status:
            download_progress['status'] = status

def reset_download_progress(total=0):
    """é‡ç½®ä¸‹è½½è¿›åº¦"""
    with progress_lock:
        download_progress['total'] = total
        download_progress['completed'] = 0
        download_progress['failed'] = 0
        download_progress['status'] = 'downloading' if total > 0 else 'idle'

def analyze_user_need(user_input, search_type):
    """åˆ†æç”¨æˆ·éœ€æ±‚ï¼Œæç‚¼æ£€ç´¢å…³é”®è¯"""
    # æ ¹æ®æœç´¢ç±»å‹æ„å»ºä¸åŒçš„æç¤ºè¯
    if search_type == 'web':
        prompt = f"""
è¯·åˆ†æç”¨æˆ·çš„æœç´¢éœ€æ±‚ï¼Œå¹¶æç‚¼å‡ºæœ€é€‚åˆç½‘é¡µæœç´¢çš„å…³é”®è¯ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š"{user_input}"

è¯·åˆ†æç”¨æˆ·çš„çœŸå®æ„å›¾ï¼Œæç‚¼å‡º1ä¸ªæœ€æ ¸å¿ƒçš„æ£€ç´¢å…³é”®è¯ã€‚å…³é”®è¯åº”è¯¥ï¼š
1. å‡†ç¡®åæ˜ ç”¨æˆ·çš„æ ¸å¿ƒéœ€æ±‚
2. é€‚åˆç½‘é¡µæœç´¢å¼•æ“ä½¿ç”¨
3. ç®€æ´æ˜äº†ï¼Œå¯ä»¥æœ‰å®šè¯­
4. ä½¿ç”¨ä¸­æ–‡æˆ–è‹±æ–‡

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
    "keyword": "æç‚¼çš„å…³é”®è¯",
    "reasoning": "é€‰æ‹©è¿™ä¸ªå…³é”®è¯çš„ç†ç”±",
    "search_intent": "ç”¨æˆ·çš„æœç´¢æ„å›¾åˆ†æ"
}}

è¯·åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚
"""
    else:  # paper search
        prompt = f"""
è¯·åˆ†æç”¨æˆ·çš„ç ”ç©¶éœ€æ±‚ï¼Œå¹¶æç‚¼å‡ºæœ€é€‚åˆå­¦æœ¯è®ºæ–‡æœç´¢çš„å…³é”®è¯ã€‚

ç”¨æˆ·éœ€æ±‚ï¼š"{user_input}"

è¯·åˆ†æç”¨æˆ·çš„ç ”ç©¶æ„å›¾ï¼Œæç‚¼å‡º1ä¸ªæœ€æ ¸å¿ƒçš„å­¦æœ¯æ£€ç´¢å…³é”®è¯ã€‚å…³é”®è¯åº”è¯¥ï¼š
1. å‡†ç¡®åæ˜ ç”¨æˆ·çš„ç ”ç©¶é¢†åŸŸå’Œæ–¹å‘
2. é€‚åˆarXivç­‰å­¦æœ¯æ•°æ®åº“æœç´¢
3. ä½¿ç”¨å­¦æœ¯æœ¯è¯­ï¼Œç®€æ´ä¸“ä¸šï¼Œå¯ä»¥æœ‰å®šè¯­
4. ä¼˜å…ˆä½¿ç”¨è‹±æ–‡å­¦æœ¯è¯æ±‡

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼š
{{
    "keyword": "æç‚¼çš„å…³é”®è¯",
    "reasoning": "é€‰æ‹©è¿™ä¸ªå…³é”®è¯çš„ç†ç”±",
    "search_intent": "ç”¨æˆ·çš„ç ”ç©¶æ„å›¾åˆ†æ"
}}

è¯·åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚
"""
    
    # è°ƒç”¨AI API
    try:
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        api_key = config.get('api_key')
        model = config.get('model', 'gpt-4.5-preview')
        ai_response = process_text(prompt, api_key, model)
        
        # è§£æAIå“åº”
        try:
            # å°è¯•ä»å“åº”ä¸­æå–JSON
            json_start = ai_response.find('{')
            json_end = ai_response.rfind('}') + 1
            if json_start != -1 and json_end > json_start:
                json_str = ai_response[json_start:json_end]
                ai_result = json.loads(json_str)
            else:
                raise ValueError("æœªæ‰¾åˆ°JSONæ ¼å¼å“åº”")
        except (json.JSONDecodeError, ValueError) as e:
            raise Exception(f'AIå“åº”è§£æå¤±è´¥: {str(e)}')
        
        return {
            'keyword': ai_result.get('keyword', user_input),
            'reasoning': ai_result.get('reasoning', ''),
            'search_intent': ai_result.get('search_intent', ''),
            'original_input': user_input
        }
        
    except Exception as e:
        # å¦‚æœAIåˆ†æå¤±è´¥ï¼Œè¿”å›åŸå§‹è¾“å…¥ä½œä¸ºå…³é”®è¯
        return {
            'keyword': user_input,
            'reasoning': 'ç”±äºAIåˆ†æå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹è¾“å…¥ä½œä¸ºå…³é”®è¯',
            'search_intent': 'æ— æ³•åˆ†æç”¨æˆ·æ„å›¾',
            'original_input': user_input
        }

def search_web(keyword):
    """æœç´¢ç½‘é¡µ"""
    result = exa.search_and_contents(keyword, text=True, num_results=20)
    
    web_results = []
    for item in result.results:
        content = clean_web_content(item.text) if item.text else "æ— å†…å®¹"
        if len(content) > 800:
            content = content[:800] + "..."
        
        web_results.append({
            'title': item.title or "æ— æ ‡é¢˜",
            'url': item.url or "#",
            'content': content
        })
    
    return {
        'total_count': len(result.results),
        'items': web_results
    }

def search_papers(keyword):
    """æœç´¢è®ºæ–‡"""
    query = f"site:arxiv.org/abs {keyword}"
    result = exa.search_and_contents(query, text=True, num_results=20)
    
    # ç­›é€‰æœ‰æ•ˆçš„arxivè®ºæ–‡
    valid_results = []
    
    for item in result.results:
        if is_valid_arxiv_url(item.url):
            abstract = extract_abstract(item.text)
            valid_results.append({
                'title': item.title or "æ— æ ‡é¢˜",
                'url': item.url or "#",
                'abstract': abstract
            })
    
    return {
        'total_count': len(valid_results),
        'items': valid_results
    }

def smart_filter_papers(original_input, keyword, papers):
    """æ™ºèƒ½ç­›é€‰è®ºæ–‡"""
    return smart_filter_content(original_input, keyword, papers, 'paper')

def smart_filter_content(original_input, keyword, items, content_type):
    """æ™ºèƒ½ç­›é€‰å†…å®¹ï¼ˆè®ºæ–‡æˆ–ç½‘é¡µï¼‰"""
    # æ ¹æ®å†…å®¹ç±»å‹æ„å»ºä¸åŒçš„æç¤ºè¯
    if content_type == 'paper':
        content_label = "è®ºæ–‡"
        item_fields = "æ‘˜è¦"
        content_key = "abstract"
        criteria = """
1. è®ºæ–‡å†…å®¹ä¸ç”¨æˆ·éœ€æ±‚çš„åŒ¹é…åº¦
2. è®ºæ–‡çš„å­¦æœ¯ä»·å€¼å’Œå®ç”¨æ€§
3. è®ºæ–‡çš„æ·±åº¦å’Œå¹¿åº¦æ˜¯å¦é€‚åˆç”¨æˆ·éœ€æ±‚"""
    else:  # web
        content_label = "ç½‘é¡µ"
        item_fields = "å†…å®¹"
        content_key = "content"
        criteria = """
1. ç½‘é¡µå†…å®¹ä¸ç”¨æˆ·éœ€æ±‚çš„åŒ¹é…åº¦
2. ç½‘é¡µä¿¡æ¯çš„æƒå¨æ€§å’Œå¯é æ€§
3. ç½‘é¡µä¿¡æ¯çš„å®ç”¨æ€§å’Œæ—¶æ•ˆæ€§"""
    
    # æ„å»ºå‘é€ç»™AIçš„æç¤ºè¯
    prompt = f"""
è¯·æ ¹æ®ç”¨æˆ·çš„åŸå§‹éœ€æ±‚"{original_input}"ï¼Œä»ä»¥ä¸‹{content_label}åˆ—è¡¨ä¸­é€‰æ‹©æœ€ç›¸å…³å’Œæœ‰ä»·å€¼çš„{content_label}ã€‚

ç”¨æˆ·çš„åŸå§‹éœ€æ±‚ï¼š{original_input}
æç‚¼çš„å…³é”®è¯ï¼š{keyword}

{content_label}åˆ—è¡¨ï¼š
"""
    
    for i, item in enumerate(items):
        prompt += f"\n{i+1}. æ ‡é¢˜: {item.get('title', 'æ— æ ‡é¢˜')}\n"
        
        # å¤„ç†å†…å®¹å­—æ®µï¼Œç½‘é¡µå†…å®¹å¯èƒ½å¾ˆé•¿ï¼Œéœ€è¦æˆªå–
        content = item.get(content_key, f'æ— {item_fields}')
        if content_type == 'web' and len(content) > 500:
            content = content[:500] + "..."
        
        prompt += f"   {item_fields}: {content}\n"
        prompt += f"   é“¾æ¥: {item.get('url', 'æ— é“¾æ¥')}\n"
    
    prompt += f"""

è¯·ç»¼åˆè€ƒè™‘ç”¨æˆ·çš„åŸå§‹éœ€æ±‚"{original_input}"å’Œæç‚¼çš„å…³é”®è¯"{keyword}"ï¼Œåˆ†ææ¯ä¸ª{content_label}ä¸ç”¨æˆ·çœŸå®éœ€æ±‚çš„ç›¸å…³æ€§ã€‚
è¯·é€‰æ‹©æœ€ç¬¦åˆç”¨æˆ·éœ€æ±‚çš„{content_label}ï¼Œè€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š
{criteria}

è¯·ä»¥JSONæ ¼å¼è¿”å›ç»“æœï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
    "recommended_papers": [å†…å®¹ç´¢å¼•åˆ—è¡¨ï¼Œä»0å¼€å§‹],
    "reasoning": "åŸºäºç”¨æˆ·åŸå§‹éœ€æ±‚é€‰æ‹©è¿™äº›{content_label}çš„ç†ç”±",
    "total_recommended": æ¨è{content_label}æ•°é‡
}}

è¯·åªè¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–æ–‡å­—ã€‚
"""
    
    # è°ƒç”¨API - ä»é…ç½®æ–‡ä»¶è¯»å–APIå¯†é’¥
    with open('config.json', 'r', encoding='utf-8') as f:
        config = json.load(f)
    api_key = config.get('api_key')
    model = config.get('model', 'gpt-4.5-preview')
    ai_response = process_text(prompt, api_key, model)
    
    # è§£æAIå“åº”
    try:
        # å°è¯•ä»å“åº”ä¸­æå–JSON
        json_start = ai_response.find('{')
        json_end = ai_response.rfind('}') + 1
        if json_start != -1 and json_end > json_start:
            json_str = ai_response[json_start:json_end]
            ai_result = json.loads(json_str)
        else:
            raise ValueError("æœªæ‰¾åˆ°JSONæ ¼å¼å“åº”")
    except (json.JSONDecodeError, ValueError) as e:
        raise Exception(f'AIå“åº”è§£æå¤±è´¥: {str(e)}')
    
    # éªŒè¯AIè¿”å›çš„ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
    recommended_indices = ai_result.get('recommended_papers', [])
    valid_indices = [i for i in recommended_indices if 0 <= i < len(items)]
    
    # æ„å»ºæ¨èç»“æœ
    recommended_items = []
    for i in valid_indices:
        item = items[i].copy()
        item['original_index'] = i
        recommended_items.append(item)
    
    return {
        'recommended_papers': recommended_items,
        'reasoning': ai_result.get('reasoning', ''),
        'total_recommended': len(recommended_items)
    }

def crawl_papers(urls, titles):
    """çˆ¬å–è®ºæ–‡PDFï¼ˆå¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰"""
    # åˆ›å»ºä¸‹è½½ç›®å½•
    download_dir = 'downloaded_papers'
    if not os.path.exists(download_dir):
        os.makedirs(download_dir)
    
    # åŠ è½½æˆ–åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    metadata_file = os.path.join(download_dir, 'metadata.json')
    metadata = load_metadata(metadata_file)
    
    # å‡†å¤‡ä¸‹è½½ä»»åŠ¡
    download_tasks = []
    for i, url in enumerate(urls):
        pdf_url = convert_arxiv_url_to_pdf(url)
        if pdf_url:
            title = titles[i] if i < len(titles) else "æœªçŸ¥æ ‡é¢˜"
            download_tasks.append((pdf_url, title))
    
    # é‡ç½®ä¸‹è½½è¿›åº¦
    reset_download_progress(len(download_tasks))
    
    crawled_count = 0
    failed_urls = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½ï¼ˆæœ€å¤š5ä¸ªå¹¶å‘ï¼‰
    with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
        # æäº¤æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
        future_to_task = {
            executor.submit(download_single_pdf, pdf_url, download_dir, title, metadata): 
            (pdf_url, title) for pdf_url, title in download_tasks
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in concurrent.futures.as_completed(future_to_task):
            pdf_url, title = future_to_task[future]
            try:
                success, filename = future.result()
                if success:
                    crawled_count += 1
                    update_download_progress(completed=1)
                else:
                    failed_urls.append(pdf_url)
                    update_download_progress(failed=1)
            except Exception as e:
                print(f"ä¸‹è½½ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {pdf_url}, é”™è¯¯: {str(e)}")
                failed_urls.append(pdf_url)
                update_download_progress(failed=1)
    
    # ä¿å­˜å…ƒæ•°æ®
    save_metadata(metadata_file, metadata)
    
    # æ›´æ–°å®ŒæˆçŠ¶æ€
    update_download_progress(status='completed')
    
    return {
        'crawled_count': crawled_count,
        'total_count': len(urls),
        'failed_count': len(failed_urls),
        'failed_urls': failed_urls if failed_urls else None
    }

def download_single_pdf(pdf_url, download_dir, title, metadata):
    """ä¸‹è½½å•ä¸ªPDFæ–‡ä»¶ï¼ˆçº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼‰"""
    try:
        # ä»URLä¸­æå–è®ºæ–‡IDä½œä¸ºæ–‡ä»¶å
        paper_id = pdf_url.split('/')[-1].replace('.pdf', '')
        filename = f"{paper_id}.pdf"
        filepath = os.path.join(download_dir, filename)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½ä½†æ›´æ–°å…ƒæ•°æ®
        if os.path.exists(filepath):
            print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {filename}")
            with progress_lock:
                metadata[filename] = title
            return True, filename
        
        # ä¸‹è½½PDF
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # å‡å°‘è¶…æ—¶æ—¶é—´å¹¶æ·»åŠ é‡è¯•æœºåˆ¶
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.get(pdf_url, headers=headers, timeout=3000)
                response.raise_for_status()
                break
            except requests.exceptions.Timeout:
                if attempt < max_retries - 1:
                    print(f"ä¸‹è½½è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯• ({attempt + 1}/{max_retries}): {filename}")
                    continue
                else:
                    raise
        
        # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºPDF
        content_type = response.headers.get('content-type', '')
        if 'pdf' not in content_type.lower():
            print(f"å“åº”ä¸æ˜¯PDFæ–‡ä»¶: {content_type}")
            return False, None
        
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'wb') as f:
            f.write(response.content)
        
        # çº¿ç¨‹å®‰å…¨åœ°ä¿å­˜æ ‡é¢˜åˆ°å…ƒæ•°æ®
        with progress_lock:
            metadata[filename] = title
        
        print(f"æˆåŠŸä¸‹è½½: {filename}")
        return True, filename
        
    except requests.exceptions.RequestException as e:
        print(f"ä¸‹è½½å¤±è´¥: {pdf_url}, é”™è¯¯: {str(e)}")
        return False, None
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")
        return False, None

def crawl_webpages(urls, titles):
    """çˆ¬å–ç½‘é¡µå†…å®¹ï¼ˆå¹¶è¡Œä¼˜åŒ–ç‰ˆï¼‰"""
    # åˆ›å»ºä¸‹è½½ç›®å½•
    download_dir = 'downloaded_webpages'
    if not os.path.exists(download_dir):
        os.makedirs(download_dir)
    
    # åŠ è½½æˆ–åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    metadata_file = os.path.join(download_dir, 'metadata.json')
    metadata = load_metadata(metadata_file)
    
    # å‡†å¤‡ä¸‹è½½ä»»åŠ¡
    download_tasks = []
    for i, url in enumerate(urls):
        title = titles[i] if i < len(titles) else "æœªçŸ¥æ ‡é¢˜"
        download_tasks.append((url, title))
    
    # é‡ç½®ä¸‹è½½è¿›åº¦
    reset_download_progress(len(download_tasks))
    
    crawled_count = 0
    failed_urls = []
    
    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œä¸‹è½½ï¼ˆæœ€å¤š3ä¸ªå¹¶å‘ï¼Œç½‘é¡µä¸‹è½½ç›¸å¯¹æ›´å¿«ï¼‰
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        # æäº¤æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
        future_to_task = {
            executor.submit(download_single_webpage, url, download_dir, title, metadata): 
            (url, title) for url, title in download_tasks
        }
        
        # å¤„ç†å®Œæˆçš„ä»»åŠ¡
        for future in concurrent.futures.as_completed(future_to_task):
            url, title = future_to_task[future]
            try:
                success, filename = future.result()
                if success:
                    crawled_count += 1
                    update_download_progress(completed=1)
                else:
                    failed_urls.append(url)
                    update_download_progress(failed=1)
            except Exception as e:
                print(f"ä¸‹è½½ç½‘é¡µä»»åŠ¡æ‰§è¡Œå¤±è´¥: {url}, é”™è¯¯: {str(e)}")
                failed_urls.append(url)
                update_download_progress(failed=1)
    
    # ä¿å­˜å…ƒæ•°æ®
    save_metadata(metadata_file, metadata)
    
    # æ›´æ–°å®ŒæˆçŠ¶æ€
    update_download_progress(status='completed')
    
    return {
        'crawled_count': crawled_count,
        'total_count': len(urls),
        'failed_count': len(failed_urls),
        'failed_urls': failed_urls if failed_urls else None
    }

def download_single_webpage(url, download_dir, title, metadata):
    """ä¸‹è½½å•ä¸ªç½‘é¡µï¼ˆçº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼‰"""
    try:
        # ç”ŸæˆåŸºäºURLçš„å”¯ä¸€æ–‡ä»¶å
        url_hash = hashlib.md5(url.encode('utf-8')).hexdigest()[:8]
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
        filename = f"{safe_title}_{url_hash}.html"
        filepath = os.path.join(download_dir, filename)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½ä½†æ›´æ–°å…ƒæ•°æ®
        if os.path.exists(filepath):
            print(f"ç½‘é¡µæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {filename}")
            with progress_lock:
                metadata[filename] = title
            return True, filename
        
        # ä¸‹è½½ç½‘é¡µ
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        # ç½‘é¡µä¸‹è½½è¶…æ—¶æ—¶é—´è®¾ç½®ä¸º10ç§’
        response = requests.get(url, headers=headers, timeout=3000)
        response.raise_for_status()
        
        # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºHTML
        content_type = response.headers.get('content-type', '')
        if 'html' not in content_type.lower():
            print(f"å“åº”ä¸æ˜¯HTMLæ–‡ä»¶: {content_type}")
            return False, None
        
        # è§£æHTMLå¹¶æ¸…ç†
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
        for script in soup(["script", "style"]):
            script.decompose()
        
        # æ·»åŠ åŸºç¡€æ ·å¼ä½¿é¡µé¢æ›´æ˜“è¯»
        if soup.head:
            style_tag = soup.new_tag("style")
            style_tag.string = """
                body { 
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
                    line-height: 1.6; 
                    max-width: 800px; 
                    margin: 0 auto; 
                    padding: 20px;
                    background: #fff;
                    color: #333;
                }
                img { max-width: 100%; height: auto; }
                pre { background: #f5f5f5; padding: 10px; border-radius: 4px; overflow-x: auto; }
                code { background: #f5f5f5; padding: 2px 4px; border-radius: 2px; }
                blockquote { border-left: 3px solid #ddd; margin-left: 0; padding-left: 20px; color: #666; }
            """
            soup.head.append(style_tag)
        
        # ä¿å­˜HTMLæ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(str(soup))
        
        # çº¿ç¨‹å®‰å…¨åœ°ä¿å­˜æ ‡é¢˜åˆ°å…ƒæ•°æ®
        with progress_lock:
            metadata[filename] = title
        
        print(f"æˆåŠŸä¸‹è½½ç½‘é¡µ: {filename}")
        return True, filename
        
    except requests.exceptions.RequestException as e:
        print(f"ä¸‹è½½ç½‘é¡µå¤±è´¥: {url}, é”™è¯¯: {str(e)}")
        return False, None
    except Exception as e:
        print(f"ä¿å­˜ç½‘é¡µå¤±è´¥: {str(e)}")
        return False, None

def get_pdf_list():
    """è·å–å·²ä¸‹è½½çš„PDFæ–‡ä»¶åˆ—è¡¨"""
    download_dir = 'downloaded_papers'
    if not os.path.exists(download_dir):
        return {'pdfs': [], 'count': 0}
    
    # åŠ è½½å…ƒæ•°æ®
    metadata_file = os.path.join(download_dir, 'metadata.json')
    metadata = load_metadata(metadata_file)
    
    pdf_files = []
    for filepath in glob.glob(os.path.join(download_dir, '*.pdf')):
        filename = os.path.basename(filepath)
        file_size = os.path.getsize(filepath)
        
        # ä»å…ƒæ•°æ®ä¸­è·å–æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ–‡ä»¶å
        title = metadata.get(filename, filename.replace('.pdf', ''))
        
        pdf_files.append({
            'filename': filename,
            'title': title,
            'size': file_size,
            'path': filepath
        })
    
    # æŒ‰æ ‡é¢˜æ’åº
    pdf_files.sort(key=lambda x: x['title'])
    
    return {'pdfs': pdf_files, 'count': len(pdf_files)}

def get_all_papers_list():
    """
    è·å–æ‰€æœ‰è®ºæ–‡å†…å®¹ï¼ŒåŒ…æ‹¬å•ç¯‡PDFå’Œæ–‡ä»¶å¤¹ã€‚
    """
    download_dir = 'downloaded_papers'
    if not os.path.exists(download_dir):
        return []

    all_content = []
    
    # 1. é¦–å…ˆï¼Œè·å–æ‰€æœ‰å•ç¯‡PDFæ–‡ä»¶ (æ ¹ç›®å½•ä¸‹çš„)
    # è¿™éƒ¨åˆ†é€»è¾‘æ‚¨å¯èƒ½å·²ç»æœ‰äº†ï¼Œå¯ä»¥ç›´æ¥å¤ç”¨
    metadata_file = os.path.join(download_dir, 'metadata.json')
    metadata = load_metadata(metadata_file) # å‡è®¾æ‚¨æœ‰ load_metadata å‡½æ•°
    
    # ä½¿ç”¨ glob æ‰¾åˆ°æ‰€æœ‰æ ¹ç›®å½•ä¸‹çš„ pdf
    for filepath in glob.glob(os.path.join(download_dir, '*.pdf')):
        filename = os.path.basename(filepath)
        # å¿…é¡»æ˜¯ "upload_" å¼€å¤´çš„ï¼Œä»¥å’Œæ–‡ä»¶å¤¹å†…çš„æ–‡ä»¶åŒºåˆ†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if filename.startswith('upload_'):
            all_content.append({
                'type': 'file',  # <--- æ ‡è®°ç±»å‹ä¸º "æ–‡ä»¶"
                'filename': filename,
                'title': metadata.get(filename, filename.replace('.pdf', '')),
                'size': os.path.getsize(filepath)
            })

    # 2. ç„¶åï¼ŒæŸ¥æ‰¾æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼ˆå³ä¸Šä¼ çš„è®ºæ–‡é›†ï¼‰
    for item in os.scandir(download_dir):
        if item.is_dir():
            folder_path = item.path
            folder_name_full = item.name # ä¾‹å¦‚ "MyPapers_batch_12345"
            
            # # ä»æ–‡ä»¶å¤¹åä¸­è§£æå‡ºåŸå§‹åç§°å’Œ batch_id
            # parts = folder_name_full.rsplit('_', 1)
            # original_folder_name = parts[0]
            # batch_id = parts[1] if len(parts) > 1 else "unknown_id"

            # ã€ä¿®æ”¹ã€‘ä¼˜å…ˆä»å…ƒæ•°æ®è¯»å–æ–‡ä»¶å¤¹å
            original_folder_name = ''
            folder_meta_path = os.path.join(folder_path, 'folder_metadata.json')
            if os.path.exists(folder_meta_path):
                with open(folder_meta_path, 'r', encoding='utf-8') as f:
                    folder_meta = json.load(f)
                    original_folder_name = folder_meta.get('original_name')
            
            # å¦‚æœå…ƒæ•°æ®ä¸å­˜åœ¨ï¼ˆä¸ºäº†å…¼å®¹æ—§æ•°æ®ï¼‰ï¼Œåˆ™é€€å›åŸæ¥çš„è§£ææ–¹å¼
            if not original_folder_name:
                parts = folder_name_full.rsplit('_', 1)
                original_folder_name = parts[0]

            batch_id = folder_name_full.rsplit('_', 1)[-1]
            

            folder_files = []
            # éå†æ–‡ä»¶å¤¹å†…éƒ¨çš„PDF
            for sub_filepath in glob.glob(os.path.join(folder_path, '*.pdf')):
                sub_filename = os.path.basename(sub_filepath)
                folder_files.append({
                    "original_name": sub_filename,
                    "saved_name": f"{folder_name_full}/{sub_filename}"
                })

            if folder_files: # åªæœ‰æ–‡ä»¶å¤¹ä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ 
                all_content.append({
                    'type': 'folder', # <--- æ ‡è®°ç±»å‹ä¸º "æ–‡ä»¶å¤¹"
                    'name': original_folder_name,
                    'batch_id': batch_id,
                    'files': folder_files,
                    'file_count': len(folder_files)
                })

    # å¯ä»¥æ ¹æ®åç§°æˆ–ç±»å‹æ’åºï¼Œè®©æ–‡ä»¶å¤¹æ€»åœ¨å‰é¢
    all_content.sort(key=lambda x: (x['type'] == 'file', x.get('title', x.get('name'))))

    return all_content

def get_webpage_list():
    """è·å–å·²ä¸‹è½½çš„ç½‘é¡µæ–‡ä»¶åˆ—è¡¨"""
    download_dir = 'downloaded_webpages'
    if not os.path.exists(download_dir):
        return {'webpages': [], 'count': 0}
    
    # åŠ è½½å…ƒæ•°æ®
    metadata_file = os.path.join(download_dir, 'metadata.json')
    metadata = load_metadata(metadata_file)
    
    webpage_files = []
    for filepath in glob.glob(os.path.join(download_dir, '*.html')):
        filename = os.path.basename(filepath)
        file_size = os.path.getsize(filepath)
        
        # ä»å…ƒæ•°æ®ä¸­è·å–æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨æ–‡ä»¶å
        title = metadata.get(filename, filename.replace('.html', ''))
        
        webpage_files.append({
            'filename': filename,
            'title': title,
            'size': file_size,
            'path': filepath
        })
    
    # æŒ‰æ ‡é¢˜æ’åº
    webpage_files.sort(key=lambda x: x['title'])
    
    return {'webpages': webpage_files, 'count': len(webpage_files)}

def clear_all_content():
    """æ¸…é™¤æ‰€æœ‰å·²ä¸‹è½½çš„å†…å®¹ï¼ˆè®ºæ–‡å’Œç½‘é¡µï¼‰"""
    total_deleted_count = 0
    
    # æ¸…é™¤è®ºæ–‡æ–‡ä»¶
    papers_dir = 'downloaded_papers'
    if os.path.exists(papers_dir):
        # è·å–æ‰€æœ‰PDFæ–‡ä»¶
        pdf_files = glob.glob(os.path.join(papers_dir, '*.pdf'))
        
        # åˆ é™¤æ‰€æœ‰PDFæ–‡ä»¶
        for filepath in pdf_files:
            try:
                os.remove(filepath)
                total_deleted_count += 1
                print(f"å·²åˆ é™¤PDFæ–‡ä»¶: {os.path.basename(filepath)}")
            except Exception as e:
                print(f"åˆ é™¤PDFæ–‡ä»¶å¤±è´¥: {filepath}, é”™è¯¯: {str(e)}")
        
        # åˆ é™¤è®ºæ–‡å…ƒæ•°æ®æ–‡ä»¶
        metadata_file = os.path.join(papers_dir, 'metadata.json')
        if os.path.exists(metadata_file):
            try:
                os.remove(metadata_file)
                print("å·²åˆ é™¤è®ºæ–‡å…ƒæ•°æ®æ–‡ä»¶")
            except Exception as e:
                print(f"åˆ é™¤è®ºæ–‡å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        # ===========================================================
        # â–¼ ã€åœ¨è¿™é‡Œå¢åŠ ä»¥ä¸‹ä»£ç ã€‘â–¼
        # ===========================================================
        # æ–°å¢é€»è¾‘ï¼šæŸ¥æ‰¾å¹¶åˆ é™¤æ‰€æœ‰å­æ–‡ä»¶å¤¹ï¼ˆå³ä¸Šä¼ çš„è®ºæ–‡é›†ï¼‰
        for item_name in os.listdir(papers_dir):
            item_path = os.path.join(papers_dir, item_name)
            if os.path.isdir(item_path):
                try:
                    # shutil.rmtree ä¼šåˆ é™¤æ•´ä¸ªæ–‡ä»¶å¤¹åŠå…¶æ‰€æœ‰å†…å®¹
                    shutil.rmtree(item_path)
                    print(f"å·²åˆ é™¤æ–‡ä»¶å¤¹: {item_name}")
                    total_deleted_count += 1 # å°†æ•´ä¸ªæ–‡ä»¶å¤¹ç®—ä½œä¸€ä¸ªåˆ é™¤é¡¹
                except Exception as e:
                    print(f"åˆ é™¤æ–‡ä»¶å¤¹ {item_path} å¤±è´¥: {e}")
        # ===========================================================
        # â–² ã€å¢åŠ çš„ä»£ç åˆ°æ­¤ç»“æŸã€‘â–²
        # ===========================================================


        # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
        try:
            remaining_files = os.listdir(papers_dir)
            if not remaining_files:
                os.rmdir(papers_dir)
                print("å·²åˆ é™¤è®ºæ–‡ç›®å½•")
        except Exception as e:
            print(f"åˆ é™¤è®ºæ–‡ç›®å½•å¤±è´¥: {str(e)}")
    
    # æ¸…é™¤ç½‘é¡µæ–‡ä»¶
    webpages_dir = 'downloaded_webpages'
    if os.path.exists(webpages_dir):
        # è·å–æ‰€æœ‰HTMLæ–‡ä»¶
        html_files = glob.glob(os.path.join(webpages_dir, '*.html'))
        
        # åˆ é™¤æ‰€æœ‰HTMLæ–‡ä»¶
        for filepath in html_files:
            try:
                os.remove(filepath)
                total_deleted_count += 1
                print(f"å·²åˆ é™¤ç½‘é¡µæ–‡ä»¶: {os.path.basename(filepath)}")
            except Exception as e:
                print(f"åˆ é™¤ç½‘é¡µæ–‡ä»¶å¤±è´¥: {filepath}, é”™è¯¯: {str(e)}")
        
        # åˆ é™¤ç½‘é¡µå…ƒæ•°æ®æ–‡ä»¶
        metadata_file = os.path.join(webpages_dir, 'metadata.json')
        if os.path.exists(metadata_file):
            try:
                os.remove(metadata_file)
                print("å·²åˆ é™¤ç½‘é¡µå…ƒæ•°æ®æ–‡ä»¶")
            except Exception as e:
                print(f"åˆ é™¤ç½‘é¡µå…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {str(e)}")
        
        # å¦‚æœç›®å½•ä¸ºç©ºï¼Œåˆ é™¤ç›®å½•
        try:
            remaining_files = os.listdir(webpages_dir)
            if not remaining_files:
                os.rmdir(webpages_dir)
                print("å·²åˆ é™¤ç½‘é¡µç›®å½•")
        except Exception as e:
            print(f"åˆ é™¤ç½‘é¡µç›®å½•å¤±è´¥: {str(e)}")
    
    return {
        'deleted_count': total_deleted_count,
        'message': f'æˆåŠŸæ¸…é™¤äº† {total_deleted_count} ä¸ªæ–‡ä»¶'
    }

def delete_single_content(filename, content_type):
    """åˆ é™¤å•ä¸ªå†…å®¹æ–‡ä»¶"""
    if content_type == 'pdf':
        download_dir = 'downloaded_papers'
        file_extension = '.pdf'
    elif content_type == 'webpage':
        download_dir = 'downloaded_webpages'
        file_extension = '.html'
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å†…å®¹ç±»å‹: {content_type}")
    
    # æ£€æŸ¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(download_dir):
        return {
            'deleted': False,
            'message': 'ç›®å½•ä¸å­˜åœ¨'
        }
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    filepath = os.path.join(download_dir, filename)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(filepath):
        return {
            'deleted': False,
            'message': 'æ–‡ä»¶ä¸å­˜åœ¨'
        }
    
    try:
        # åˆ é™¤æ–‡ä»¶
        os.remove(filepath)
        
        # æ›´æ–°å…ƒæ•°æ®
        metadata_file = os.path.join(download_dir, 'metadata.json')
        metadata = load_metadata(metadata_file)
        
        if filename in metadata:
            del metadata[filename]
            save_metadata(metadata_file, metadata)
        
        return {
            'deleted': True,
            'message': f'æˆåŠŸåˆ é™¤ {filename}'
        }
        
    except Exception as e:
        return {
            'deleted': False,
            'message': f'åˆ é™¤å¤±è´¥: {str(e)}'
        }

def upload_pdf_file(file):
    """ä¸Šä¼ PDFæ–‡ä»¶"""
    from werkzeug.utils import secure_filename
    import time
    
    # åˆ›å»ºä¸‹è½½ç›®å½•
    download_dir = 'downloaded_papers'
    if not os.path.exists(download_dir):
        os.makedirs(download_dir)
    
    # å®‰å…¨å¤„ç†æ–‡ä»¶å
    original_filename = secure_filename(file.filename)
    
    # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶åï¼ˆåŸºäºæ—¶é—´æˆ³å’ŒåŸæ–‡ä»¶åï¼‰
    timestamp = int(time.time())
    filename = f"upload_{timestamp}_{original_filename}"
    filepath = os.path.join(download_dir, filename)
    
    # ä¿å­˜æ–‡ä»¶
    file.save(filepath)
    
    # åŠ è½½æˆ–åˆ›å»ºå…ƒæ•°æ®æ–‡ä»¶
    metadata_file = os.path.join(download_dir, 'metadata.json')
    metadata = load_metadata(metadata_file)
    
    # ä¿å­˜æ ‡é¢˜åˆ°å…ƒæ•°æ®ï¼ˆä½¿ç”¨åŸæ–‡ä»¶åå»é™¤æ‰©å±•åä½œä¸ºæ ‡é¢˜ï¼‰
    title = original_filename.replace('.pdf', '')
    metadata[filename] = title
    
    # ä¿å­˜å…ƒæ•°æ®
    save_metadata(metadata_file, metadata)
    
    return {
        'filename': filename,
        'title': title,
        'message': f'æˆåŠŸä¸Šä¼ PDFæ–‡ä»¶: {title}'
    }



# ========================= è¾…åŠ©å‡½æ•° =========================

def clean_web_content(content):
    """æ¸…ç†ç½‘é¡µå†…å®¹"""
    if not content:
        return ""
    
    # ç§»é™¤å›¾ç‰‡å’Œé“¾æ¥
    content = re.sub(r'!\[.*?\]\(.*?\)', '', content)
    content = re.sub(r'<img[^>]*>', '', content, flags=re.IGNORECASE)
    content = re.sub(r'\[.*?\]\(https?://[^\)]+\)', '', content)
    content = re.sub(r'https?://[^\s]+', '', content)
    content = re.sub(r'<[^>]+>', '', content)
    
    # ç§»é™¤æ— æ„ä¹‰å†…å®¹
    unwanted_patterns = [
        r'é˜…è¯»é‡\d+[.\d]*[wkä¸‡åƒ]?', r'æ”¶è—\d+[.\d]*[wkä¸‡åƒ]?', r'ç‚¹èµ\d+[.\d]*[wkä¸‡åƒ]?',
        r'å·²äº\s*\d{4}-\d{2}-\d{2}.*?ä¿®æ”¹', r'\s*åŸåˆ›\s*', r'\s*è½¬è½½\s*',
        r'Â©.*?ç‰ˆæƒ.*?', r'ç‰ˆæƒå£°æ˜.*?', r'ç›¸å…³æ¨è.*?', r'çŒœä½ å–œæ¬¢.*?',
        r'å¹¿å‘Š.*?', r'ç™»å½•.*?æ³¨å†Œ', r'è®¢é˜….*?å…³æ³¨', r'åˆ†äº«.*?è¯„è®º'
    ]
    
    for pattern in unwanted_patterns:
        content = re.sub(pattern, '', content, flags=re.IGNORECASE)
    
    # æ¸…ç†ç©ºç™½å­—ç¬¦
    content = re.sub(r'\n+', ' ', content)
    content = re.sub(r'\s+', ' ', content)
    content = re.sub(r'^[^\w\u4e00-\u9fff]*', '', content)
    content = re.sub(r'[^\w\u4e00-\u9fff.!?]*$', '', content)
    
    return content.strip()

def extract_abstract(text):
    """æå–è®ºæ–‡æ‘˜è¦"""
    if not text:
        return "æ— æ‘˜è¦"
    
    # æ¸…ç†æ–‡æœ¬
    text = re.sub(r'Download PDF.*?(?=\n|$)', '', text, flags=re.IGNORECASE)
    text = re.sub(r'Authors?:\s*\[.*?\].*?(?=\n|$)', '', text, flags=re.IGNORECASE)
    text = re.sub(r'Submitted on.*?(?=\n|$)', '', text, flags=re.IGNORECASE)
    text = re.sub(r'Comments:.*?(?=\n|$)', '', text, flags=re.IGNORECASE)
    text = re.sub(r'Subjects:.*?(?=\n|$)', '', text, flags=re.IGNORECASE)
    text = re.sub(r'\[.*?\]\(https?://.*?\)', '', text)
    
    # æå–æ‘˜è¦
    abstract_patterns = [
        r'(?i)(?:^|\n)\s*abstract\s*:?\s*(.*?)(?=\n\s*(?:keywords?|introduction|1\.|references|related work|background|\n\s*[A-Z][a-z]+\s*:|\n\s*\d+\s+[A-Z])|$)',
        r'(?i)(?:^|\n)\s*#{1,6}\s*abstract\s*:?\s*(.*?)(?=\n\s*#{1,6}|\n\s*\d+\s+[A-Z]|$)',
        r'(?i)abstract\s*:?\s*(.*?)(?=\n\s*(?:keywords?|introduction|1\.|references)|$)',
    ]
    
    for pattern in abstract_patterns:
        match = re.search(pattern, text, re.DOTALL | re.MULTILINE)
        if match:
            abstract = match.group(1).strip()
            abstract = clean_abstract(abstract)
            if is_valid_abstract(abstract):
                return abstract
    
    return "æœªæ‰¾åˆ°æ‘˜è¦"

def clean_abstract(abstract):
    """æ¸…ç†æ‘˜è¦æ–‡æœ¬"""
    if not abstract:
        return ""
    
    abstract = re.sub(r'\n+', ' ', abstract)
    abstract = re.sub(r'\s+', ' ', abstract)
    abstract = abstract.strip()
    
    # ç§»é™¤Abstractæ ‡è®°
    abstract_lower = abstract.lower()
    if abstract_lower.startswith('abstract:'):
        abstract = abstract[9:].strip()
    elif abstract_lower.startswith('abstract '):
        abstract = abstract[9:].strip()
    elif abstract_lower.startswith('abstract'):
        abstract = abstract[8:].strip()
    
    # æ¸…ç†æ— å…³å†…å®¹
    unwanted_patterns = [
        r'Download PDF.*?(?=\s|$)', r'Authors?:\s*.*?(?=\s|$)',
        r'Submitted on.*?(?=\s|$)', r'Comments:.*?(?=\s|$)',
        r'Subjects:.*?(?=\s|$)', r'\[.*?\]\(https?://.*?\)',
        r'https?://[^\s]+', r'arXiv:\d+\.\d+', r'^\s*\d+\s*$'
    ]
    
    for pattern in unwanted_patterns:
        abstract = re.sub(pattern, '', abstract, flags=re.IGNORECASE)
    
    abstract = re.sub(r'^[^\w\s]*', '', abstract)
    abstract = re.sub(r'[^\w\s.!?]*$', '', abstract)
    
    return abstract.strip()

def is_valid_abstract(abstract):
    """æ£€æŸ¥æ‘˜è¦æœ‰æ•ˆæ€§"""
    if not abstract or len(abstract) < 50:
        return False
    
    invalid_indicators = [
        r'(?i)download\s+pdf', r'(?i)authors?:\s*\[', r'(?i)submitted\s+on',
        r'(?i)comments:', r'(?i)subjects:', r'(?i)^\s*\d+\s*$',
        r'(?i)^\s*table\s+of\s+contents', r'(?i)^\s*references\s*$'
    ]
    
    for pattern in invalid_indicators:
        if re.search(pattern, abstract):
            return False
    
    sentences = re.split(r'[.!?]+', abstract)
    valid_sentences = [s.strip() for s in sentences if len(s.strip()) > 10]
    return len(valid_sentences) >= 2

def is_valid_arxiv_url(url):
    """æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„arxiv URL"""
    if not url:
        return False
    return re.match(r'https://arxiv\.org/abs/\d+\.\d+(v\d+)?', url) is not None

def convert_arxiv_url_to_pdf(abs_url):
    """å°†arxivçš„abs URLè½¬æ¢ä¸ºpdf URL"""
    if not abs_url:
        return None
    
    # å°† https://arxiv.org/abs/2404.15583v1 è½¬æ¢ä¸º https://arxiv.org/pdf/2404.15583v1.pdf
    if 'arxiv.org/abs/' in abs_url:
        pdf_url = abs_url.replace('/abs/', '/pdf/') + '.pdf'
        return pdf_url
    
    return None

def load_metadata(metadata_file):
    """åŠ è½½å…ƒæ•°æ®æ–‡ä»¶"""
    if os.path.exists(metadata_file):
        try:
            with open(metadata_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"è¯»å–å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {str(e)}")
    return {}

def save_metadata(metadata_file, metadata):
    """ä¿å­˜å…ƒæ•°æ®æ–‡ä»¶"""
    try:
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ä¿å­˜å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {str(e)}")

def download_pdf_with_title(pdf_url, download_dir, title, metadata):
    """ä¸‹è½½PDFæ–‡ä»¶å¹¶ä¿å­˜æ ‡é¢˜ä¿¡æ¯"""
    try:
        # ä»URLä¸­æå–è®ºæ–‡IDä½œä¸ºæ–‡ä»¶å
        paper_id = pdf_url.split('/')[-1].replace('.pdf', '')
        filename = f"{paper_id}.pdf"
        filepath = os.path.join(download_dir, filename)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½ä½†æ›´æ–°å…ƒæ•°æ®
        if os.path.exists(filepath):
            print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {filename}")
            metadata[filename] = title
            return True, filename
        
        # ä¸‹è½½PDF
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(pdf_url, headers=headers, timeout=3000)
        response.raise_for_status()
        
        # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºPDF
        content_type = response.headers.get('content-type', '')
        if 'pdf' not in content_type.lower():
            print(f"å“åº”ä¸æ˜¯PDFæ–‡ä»¶: {content_type}")
            return False, None
        
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'wb') as f:
            f.write(response.content)
        
        # ä¿å­˜æ ‡é¢˜åˆ°å…ƒæ•°æ®
        metadata[filename] = title
        
        print(f"æˆåŠŸä¸‹è½½: {filename}")
        return True, filename
        
    except requests.exceptions.RequestException as e:
        print(f"ä¸‹è½½å¤±è´¥: {pdf_url}, é”™è¯¯: {str(e)}")
        return False, None
    except Exception as e:
        print(f"ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}")
        return False, None

def download_webpage(url, download_dir, title, metadata):
    """ä¸‹è½½ç½‘é¡µå†…å®¹å¹¶ä¿å­˜ä¸ºHTMLæ–‡ä»¶"""
    try:
        # ç”ŸæˆåŸºäºURLçš„å”¯ä¸€æ–‡ä»¶å
        url_hash = hashlib.md5(url.encode('utf-8')).hexdigest()[:8]
        safe_title = "".join(c for c in title if c.isalnum() or c in (' ', '-', '_')).rstrip()[:50]
        filename = f"{safe_title}_{url_hash}.html"
        filepath = os.path.join(download_dir, filename)
        
        # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½ä½†æ›´æ–°å…ƒæ•°æ®
        if os.path.exists(filepath):
            print(f"æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡ä¸‹è½½: {filename}")
            metadata[filename] = title
            return True, filename
        
        # ä¸‹è½½ç½‘é¡µ
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        }
        
        response = requests.get(url, headers=headers, timeout=3000)
        response.raise_for_status()
        
        # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºHTML
        content_type = response.headers.get('content-type', '')
        if 'html' not in content_type.lower():
            print(f"å“åº”ä¸æ˜¯HTMLæ–‡ä»¶: {content_type}")
            return False, None
        
        # è§£æHTMLå¹¶æ¸…ç†
        soup = BeautifulSoup(response.content, 'html.parser')
        
        # ç§»é™¤è„šæœ¬å’Œæ ·å¼æ ‡ç­¾
        for script in soup(["script", "style"]):
            script.decompose()
        
        # æ·»åŠ åŸºç¡€æ ·å¼ä½¿é¡µé¢æ›´æ˜“è¯»
        if soup.head:
            style_tag = soup.new_tag("style")
            style_tag.string = """
                body { 
                    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif; 
                    line-height: 1.6; 
                    max-width: 800px; 
                    margin: 0 auto; 
                    padding: 20px;
                    background: #fff;
                    color: #333;
                }
                img { max-width: 100%; height: auto; }
                pre { background: #f5f5f5; padding: 10px; border-radius: 4px; overflow-x: auto; }
                code { background: #f5f5f5; padding: 2px 4px; border-radius: 2px; }
                blockquote { border-left: 3px solid #ddd; margin-left: 0; padding-left: 20px; color: #666; }
            """
            soup.head.append(style_tag)
        
        # ä¿å­˜HTMLæ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(str(soup))
        
        # ä¿å­˜æ ‡é¢˜åˆ°å…ƒæ•°æ®
        metadata[filename] = title
        
        print(f"æˆåŠŸä¸‹è½½ç½‘é¡µ: {filename}")
        return True, filename
        
    except requests.exceptions.RequestException as e:
        print(f"ä¸‹è½½ç½‘é¡µå¤±è´¥: {url}, é”™è¯¯: {str(e)}")
        return False, None
    except Exception as e:
        print(f"ä¿å­˜ç½‘é¡µå¤±è´¥: {str(e)}")
        return False, None 

# ========================= è®ºæ–‡å¤„ç†æµç¨‹ç›¸å…³å‡½æ•° =========================

import subprocess
import uuid
from datetime import datetime
from werkzeug.utils import secure_filename
import time 
# å¤„ç†çŠ¶æ€è·Ÿè¸ª
processing_jobs = {}
processing_results = {}
processing_lock = threading.Lock()

# =================================================================
# ========================= è®ºæ–‡å¤„ç†æ ¸å¿ƒå‡½æ•° =========================
# =================================================================

# å•ç¯‡è®ºæ–‡é¢„å¤„ç†
def start_paper_processing(pdf_path, pdf_filename, video_duration='medium', voice_type='female', output_format='video', background_choice='default', auto_continue=False):
    """
    å¯åŠ¨è®ºæ–‡å¤„ç†æµç¨‹
    ä¿®æ”¹å‡½æ•°ç­¾åï¼Œå¢åŠ  unique_base_name å‚æ•°,å¢åŠ  background_choice å‚æ•°
    ä½¿ç”¨ FormData å¯¹è±¡æ¥åŒæ—¶æäº¤æ™®é€šè¡¨å•æ•°æ®å’Œæ–‡ä»¶
    """
    
    # ç”Ÿæˆå”¯ä¸€çš„å¤„ç†ID
    process_id = str(uuid.uuid4())
    # è·å–PDFæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰ä½œä¸ºè¾“å‡ºç›®å½•åŸºç¡€å
    base_name = os.path.splitext(pdf_filename)[0]
    

    # å¤„ç†è‡ªå®šä¹‰éŸ³è‰²æ–‡ä»¶å’Œæ–‡æœ¬
    custom_voice_path = None
    custom_voice_text = request.form.get('voiceText', '') # ä»è¡¨å•æ•°æ®ä¸­è·å–æ–‡æœ¬
    voice_file = request.files.get('voiceFile') # ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­è·å–éŸ³è‰²æ–‡ä»¶

    if voice_type == 'custom' and voice_file:
        # å¦‚æœæ˜¯è‡ªå®šä¹‰éŸ³è‰²ï¼Œä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶
        temp_dir = f'Paper2Video/{base_name}_output/temp'
        os.makedirs(temp_dir, exist_ok=True)

        safe_filename = secure_filename(voice_file.filename)
        custom_voice_path = os.path.join(temp_dir, safe_filename)
        voice_file.save(custom_voice_path)
        print(f"âœ… è‡ªå®šä¹‰éŸ³è‰²æ–‡ä»¶å·²ä¿å­˜è‡³: {custom_voice_path}")
    # ã€è°ƒè¯•ä»£ç ã€‘
    # print(f"--- [SERVICE DEBUG] start_paper_processing ---")
    # print(f"  æ¥æ”¶åˆ°çš„ voice_type å‚æ•°: [{voice_type}]") # ç”¨ä¸­æ‹¬å·åŒ…èµ·æ¥ï¼Œé˜²æ­¢ç©ºæ ¼ç­‰ä¸å¯è§å­—ç¬¦
    # å¤„ç†è‡ªå®šä¹‰èƒŒæ™¯æ–‡ä»¶
    custom_background_path = None
    background_file = request.files.get('backgroundFile') # ä»ä¸Šä¼ çš„æ–‡ä»¶ä¸­è·å–èƒŒæ™¯æ–‡ä»¶

    if background_choice == 'custom' and background_file:
        # ç¡®ä¿ temp ç›®å½•å­˜åœ¨ï¼ˆå¦‚æœå‰é¢éŸ³è‰²éƒ¨åˆ†å·²åˆ›å»ºï¼Œè¿™é‡Œä¼šè·³è¿‡ï¼‰
        temp_dir = f'Paper2Video/{base_name}_output/temp'
        os.makedirs(temp_dir, exist_ok=True)
        # å®‰å…¨åœ°ä¿å­˜èƒŒæ™¯æ–‡ä»¶
        safe_bg_filename = secure_filename(background_file.filename)
        custom_background_path = os.path.join(temp_dir, safe_bg_filename)
        background_file.save(custom_background_path)
        print(f"âœ… è‡ªå®šä¹‰èƒŒæ™¯æ–‡ä»¶å·²ä¿å­˜è‡³: {custom_background_path}")

    # åˆ›å»ºå¤„ç†è®°å½•
    job_info = {
        'process_id': process_id,
        'pdf_path': pdf_path,
        'pdf_filename': pdf_filename,
        'base_name': base_name,
        'video_duration': video_duration,
        'voice_type': voice_type,
        'output_format': output_format,  # <--- ã€æ–°å¢ã€‘å­˜å‚¨è¾“å‡ºæ ¼å¼

        'custom_voice_path': custom_voice_path, # å­˜å‚¨ä¿å­˜åçš„è·¯å¾„
        'custom_voice_text': custom_voice_text, # å­˜å‚¨æ–‡æœ¬
        'background_choice': background_choice, # å­˜å‚¨èƒŒæ™¯é€‰æ‹©
        'custom_background_path': custom_background_path, # å­˜å‚¨è‡ªå®šä¹‰èƒŒæ™¯è·¯å¾„

        'auto_continue': auto_continue,

        'status': 'starting',
        'progress': 0,
        'start_time': datetime.now().isoformat(),
        'last_update': datetime.now().isoformat(),
        'current_step': 'Step 0: å‡†å¤‡å¼€å§‹',
        'log_messages': [],
        'output_dir': None,
        'final_video_path': None,
        'final_output_path': None, # å­˜å‚¨æœ€ç»ˆè¾“å‡ºè·¯å¾„ï¼ˆè§†é¢‘æˆ–å‹ç¼©åŒ…ï¼‰
        'error': None,
        'stage': 'initial'  # initial, waiting_for_edit, continuing, completed
    }
    
    print(f"  å³å°†å­˜å…¥ job_info çš„ voice_type: [{job_info['voice_type']}]")
    print(f"-------------------------------------------")

    with processing_lock:
        processing_jobs[process_id] = job_info
    
    # å¯åŠ¨å¼‚æ­¥å¤„ç†çº¿ç¨‹ - åªæ‰§è¡Œåˆ°Step 3
    processing_thread = threading.Thread(
        target=run_initial_processing, 
        args=(process_id, pdf_path, base_name)
    )
    processing_thread.daemon = True
    processing_thread.start()
    
    return {
        'process_id': process_id,
        'message': f'å¼€å§‹å¤„ç†è®ºæ–‡: {pdf_filename}',
        'status': 'starting'
    }

def run_initial_processing(process_id, pdf_path, base_name):
    """
    è¿è¡Œåˆå§‹å¤„ç†æµç¨‹ã€‚
    æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„è¾“å‡ºæ ¼å¼ï¼Œè°ƒç”¨ä¸åŒçš„é¢„å¤„ç†è„šæœ¬ (all_pipeline_video.py æˆ– all_pipeline_markdown.py)ã€‚
    """
    # å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼Œä¿æŒä¸å˜
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, output_dir=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if output_dir: job['output_dir'] = output_dir
                if stage: job['stage'] = stage
                job['last_update'] = datetime.now().isoformat()
    
    try:
        # 1. æ ¹æ®ç”¨æˆ·é€‰æ‹©ï¼Œç¡®å®šè¦æ‰§è¡Œçš„è„šæœ¬å’Œåˆå§‹æ­¥éª¤ä¿¡æ¯
        with processing_lock:
            job = processing_jobs[process_id]
            chosen_format = job.get('output_format', 'video')

        script_to_run = ''
        initial_step_message = ''
        
        if chosen_format == 'video':
            script_to_run = 'all_pipeline_video.py'
            initial_step_message = 'ğŸš€ å¼€å§‹æ‰§è¡Œè§†é¢‘é¢„å¤„ç†æµç¨‹ (è°ƒç”¨ all_pipeline_video.py)'
            update_job_status(progress=10, step='ğŸ’» Step 1-3: è§†é¢‘å†…å®¹ç”Ÿæˆ')
        elif chosen_format == 'markdown':
            script_to_run = 'all_pipeline_markdown.py'
            initial_step_message = 'ğŸš€ å¼€å§‹æ‰§è¡ŒMarkdowné¢„å¤„ç†æµç¨‹ (è°ƒç”¨ all_pipeline_markdown.py)'
            update_job_status(progress=10, step='ğŸ’» Step 1: è®ºæ–‡ç« èŠ‚åˆ‡åˆ†')
        elif chosen_format == 'ppt':
            # ä¸ºPPTé¢„ç•™çš„æ¥å£ï¼Œç›®å‰æ˜¯æŠ¥å‘Š"æœªå®ç°"å¹¶é€€å‡º
            # update_job_status(
            #     status='failed',
            #     progress=10,
            #     step='åŠŸèƒ½æœªå®ç°',
            #     error='PPTç”ŸæˆåŠŸèƒ½æš‚æœªå¼€æ”¾ï¼Œæ•¬è¯·æœŸå¾…ã€‚',
            #     stage='completed'
            # )
            # return # ç›´æ¥é€€å‡ºå‡½æ•°
            script_to_run = 'all_pipeline_ppt.py'
            initial_step_message = 'ğŸš€ å¼€å§‹æ‰§è¡ŒPPTé¢„å¤„ç†æµç¨‹ (è°ƒç”¨ all_pipeline_ppt.py)'
            update_job_status(progress=10, step='ğŸ’» Step 1-3: PPTå†…å®¹ç”Ÿæˆ')
        else:
            # å¤„ç†æœªçŸ¥æ ¼å¼
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {chosen_format}")

        # 2. å‡†å¤‡å¹¶æ‰§è¡ŒåŠ¨æ€æ„å»ºçš„å‘½ä»¤
        update_job_status(status='running', progress=5, step='ğŸ“‹ å‡†å¤‡æ‰§è¡Œåˆå§‹æµç¨‹', 
                         log_msg=f'ğŸ”§ å‡†å¤‡å¤„ç†PDFæ–‡ä»¶: {pdf_path}')
        
        # ã€é‡è¦ã€‘åŠ¨æ€æ„å»ºå‘½ä»¤
        cmd = ['python3', script_to_run, pdf_path, '--output-dir', f'{base_name}_output']
        
        update_job_status(log_msg=initial_step_message)
        update_job_status(log_msg=f'âš™ï¸ å°†è¦æ‰§è¡Œå‘½ä»¤: {" ".join(cmd)}') # å¢åŠ æ—¥å¿—æ–¹ä¾¿è°ƒè¯•
        
        # æ‰§è¡Œå¤„ç†è„šæœ¬
        env = os.environ.copy()
        env['PYTHONUNBUFFERED'] = '1'
        env['PYTHONIOENCODING'] = 'utf-8'
        
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            universal_newlines=True,
            bufsize=1, # ä½¿ç”¨è¡Œç¼“å†²
            encoding='utf-8',
            env=env
        )
        
        # å®æ—¶è¯»å–è¾“å‡º
        current_progress = 10
        if process.stdout:
            for line in process.stdout:
                line = line.strip()
                if line:
                    update_job_status(log_msg=line)
                    # ç®€åŒ–çš„è¿›åº¦æ›´æ–°
                    if 'Step' in line and current_progress < 65:
                         current_progress += 5
                         update_job_status(progress=min(current_progress, 65))
        
        process.wait()
        
        # 3. é¢„å¤„ç†è„šæœ¬æ‰§è¡Œå®Œæ¯•åï¼Œæ ¹æ®æ ¼å¼é€‰æ‹©ä¸‹ä¸€æ­¥æ“ä½œ
        if process.returncode == 0:
            update_job_status(progress=70, log_msg=f'âœ… {script_to_run} æ‰§è¡ŒæˆåŠŸ!')
            
            # åç»­ä»»åŠ¡çš„äºŒæ¬¡åˆ†æµ
            if chosen_format == 'markdown':
                # å¦‚æœæ˜¯Markdownï¼Œåˆ™è°ƒç”¨æ–‡æ¡£ç”Ÿæˆå’Œæ‰“åŒ…å‡½æ•°
                update_job_status(status='running', step='ğŸ“ Step 2: ç”Ÿæˆå¹¶æ‰“åŒ…Markdownæ–‡æ¡£')
                # è¿™ä¸ª run_markdown_generation å‡½æ•°æ˜¯æˆ‘ä»¬ä¹‹å‰å·²ç»å†™å¥½çš„
                run_markdown_generation(process_id, base_name)

            elif chosen_format == 'video':
                # å¦‚æœæ˜¯è§†é¢‘ï¼Œåˆ™ç»§ç»­æ‰§è¡Œè§†é¢‘ç‹¬æœ‰çš„åç»­æ­¥éª¤
                update_job_status(progress=70, step='ğŸ“ Step 3.5: å¤åˆ¶coveråœºæ™¯æ–‡ä»¶',
                                log_msg='ğŸ”„ å¼€å§‹å¤åˆ¶coveræ–‡ä»¶åˆ°Codeç›®å½•...')
                
                output_dir = f"Paper2Video/{base_name}_output"
                code_dir = f"{output_dir}/final_results/Code"
                try:
                    if os.path.exists("cover") and os.path.exists(code_dir):
                        import shutil
                        for py_file in glob.glob("cover/*.py"):
                            filename = os.path.basename(py_file)
                            shutil.copy2(py_file, os.path.join(code_dir, filename))
                            update_job_status(log_msg=f'âœ… å¤åˆ¶: {filename}')
                        
                        logo_source = "/home/EduAgent/static/template_images/EDUPAL_logo.png"
                        if os.path.exists(logo_source):
                            shutil.copy2(logo_source, os.path.join(code_dir, "EDUPAL_logo.png"))
                            update_job_status(log_msg=f'âœ… å¤åˆ¶logoæ–‡ä»¶: EDUPAL_logo.png')
                        else:
                            update_job_status(log_msg='âš ï¸ æœªæ‰¾åˆ°logoæ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶')
                        
                    else:
                        update_job_status(log_msg='âš ï¸ coverç›®å½•æˆ–Codeç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶æ­¥éª¤')
                    
                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ å¤åˆ¶coveræ–‡ä»¶æ—¶å‡ºé”™: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤')
                
                update_job_status(progress=75, step='ğŸ¬ Step 3.6: ç”Ÿæˆå°é¢å†…å®¹',
                                log_msg='ğŸ”„ å¼€å§‹ç”Ÿæˆå°é¢å†…å®¹...',
                                output_dir=output_dir)
                
                try:
                    cover_result = generate_cover_content(process_id)
                    if cover_result.get('status') == 'success':
                        update_job_status(log_msg=f'âœ… å°é¢å†…å®¹ç”ŸæˆæˆåŠŸ: {cover_result.get("title", "æ— æ ‡é¢˜")}')
                    else:
                        update_job_status(log_msg=f'âš ï¸ å°é¢ç”Ÿæˆé—®é¢˜: {cover_result.get("note", cover_result.get("error", "æœªçŸ¥é”™è¯¯"))}')
                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ å°é¢ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤')
                
                # æ’å…¥è‡ªåŠ¨åº”ç”¨èƒŒæ™¯å›¾çš„é€»è¾‘
                try:
                    with processing_lock:
                        job = processing_jobs[process_id]
                        # ä» job_info ä¸­è·å–ä¹‹å‰å­˜å‚¨çš„èƒŒæ™¯è®¾ç½®
                        choice = job.get('background_choice', 'default')
                        custom_path = job.get('custom_background_path')

                    # code_dir å˜é‡åœ¨ä¹‹å‰çš„ä»£ç ä¸­å·²ç»å®šä¹‰
                    background_to_apply = None

                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åº”ç”¨èƒŒæ™¯
                    if choice and choice != 'default':
                        update_job_status(log_msg=f'ğŸ¨ æ£€æµ‹åˆ°ç”¨æˆ·é€‰æ‹©èƒŒæ™¯: {choice}ï¼Œå¼€å§‹åº”ç”¨...')
                        
                        # æƒ…å†µä¸€ï¼šç”¨æˆ·ä¸Šä¼ äº†è‡ªå®šä¹‰èƒŒæ™¯
                        if choice == 'custom' and custom_path and os.path.exists(custom_path):
                            filename = os.path.basename(custom_path)
                            destination_path = os.path.join(code_dir, filename)
                            
                            update_job_status(log_msg=f'    -> æ­£åœ¨å¤åˆ¶è‡ªå®šä¹‰èƒŒæ™¯: {filename} åˆ°Codeç›®å½•')
                            shutil.copy2(custom_path, destination_path)
                            background_to_apply = filename

                        # æƒ…å†µäºŒï¼šç”¨æˆ·é€‰æ‹©äº†é¢„è®¾èƒŒæ™¯ (ä¾‹å¦‚ 'SJTU.png')
                        elif choice != 'custom':
                            # é¢„è®¾èƒŒæ™¯å›¾å­˜æ”¾åœ¨ static/backgrounds/
                            preset_source_path = os.path.join('static', 'backgrounds', choice)
                            if os.path.exists(preset_source_path):
                                destination_path = os.path.join(code_dir, choice)
                                update_job_status(log_msg=f'    -> æ­£åœ¨å¤åˆ¶é¢„è®¾èƒŒæ™¯: {choice} åˆ°Codeç›®å½•')
                                shutil.copy2(preset_source_path, destination_path)
                                background_to_apply = choice
                            else:
                                update_job_status(log_msg=f'    âš ï¸ é¢„è®¾èƒŒæ™¯æ–‡ä»¶ä¸å­˜åœ¨: {preset_source_path}ï¼Œè·³è¿‡åº”ç”¨')
                        
                        # å¦‚æœæˆåŠŸå¤åˆ¶äº†èƒŒæ™¯æ–‡ä»¶ï¼Œåˆ™è°ƒç”¨è„šæœ¬åº”ç”¨å®ƒ
                        if background_to_apply:
                            update_job_status(log_msg=f'    -> è°ƒç”¨è„šæœ¬ä»¥åº”ç”¨èƒŒæ™¯: {background_to_apply}')
                            # apply_background_to_code æ˜¯ä¹‹å‰å†™å¥½çš„å‡½æ•°ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨
                            try:
                                # æ³¨æ„ï¼šapply_background_to_code å‡½æ•°éœ€è¦ process_id å’Œæ–‡ä»¶å
                                apply_result = apply_background_to_code(process_id, background_to_apply)
                                update_job_status(log_msg=f'    âœ… èƒŒæ™¯åº”ç”¨å®Œæˆ: {apply_result.get("message", "æ— è¿”å›ä¿¡æ¯")}')
                            except Exception as apply_error:
                                update_job_status(log_msg=f'    âŒ åº”ç”¨èƒŒæ™¯è„šæœ¬æ—¶å‡ºé”™: {str(apply_error)}')
                        else:
                             update_job_status(log_msg='    -> æœªèƒ½å®šä½åˆ°æœ‰æ•ˆèƒŒæ™¯æ–‡ä»¶ï¼Œè·³è¿‡åº”ç”¨ã€‚')

                    else:
                        update_job_status(log_msg='ğŸ¨ ç”¨æˆ·æœªæŒ‡å®šç‰¹æ®ŠèƒŒæ™¯ï¼Œä½¿ç”¨é»˜è®¤èƒŒæ™¯ã€‚')

                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ åº”ç”¨èƒŒæ™¯å›¾æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}ï¼Œå¤„ç†å°†ç»§ç»­ä½†èƒŒæ™¯å¯èƒ½ä¸ä¼šç”Ÿæ•ˆã€‚')

                update_job_status(progress=80, step='ğŸ¥ Step 4.5: å¼€å§‹é¢„è§ˆè§†é¢‘æ¸²æŸ“',
                                log_msg='ğŸ‰ åˆå§‹å¤„ç†å®Œæˆï¼å¼€å§‹ç”Ÿæˆé¢„è§ˆè§†é¢‘...',
                                output_dir=output_dir,
                                status='rendering_preview',
                                stage='rendering_preview')
                
                render_preview_video(process_id, base_name)


                # ã€æ–°å¢é€»è¾‘ã€‘æ ¹æ® job_info ä¸­çš„è®¾ç½®ï¼Œå†³å®šæ˜¯å¦è‡ªåŠ¨æ‰§è¡Œåç»­æ­¥éª¤
                try:
                    with processing_lock:
                        job = processing_jobs[process_id]
                        auto_continue = job.get('auto_continue', False) # ä»ä»»åŠ¡çŠ¶æ€ä¸­è¯»å–

                    if auto_continue:
                        update_job_status(log_msg='âš™ï¸ è‡ªåŠ¨æ¨¡å¼å·²å¯ç”¨ï¼Œæ— ç¼è¡”æ¥åç»­å¤„ç†...')
                        # ä¸ºäº†å…¼å®¹ continue_paper_processingï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®å®ƒæœŸæœ›çš„ stage
                        with processing_lock:
                            processing_jobs[process_id]['stage'] = 'waiting_for_edit'
                        
                        continue_paper_processing(process_id)
                except Exception as e:
                    update_job_status(
                        status='failed', 
                        step='âŒ è‡ªåŠ¨è¡”æ¥å¤±è´¥', 
                        error=f'è°ƒç”¨ continue_paper_processing æ—¶å‡ºé”™: {str(e)}'
                    )


            elif chosen_format == 'ppt':
                update_job_status(progress=70, step='ğŸ“ Step 3.5: å¤åˆ¶coveråœºæ™¯æ–‡ä»¶',
                                log_msg='ğŸ”„ å¼€å§‹å¤åˆ¶coveræ–‡ä»¶åˆ°Codeç›®å½•...')
                
                output_dir = f"Paper2Video/{base_name}_output"
                code_dir = f"{output_dir}/final_results/Code"
                try:
                    if os.path.exists("pptcover") and os.path.exists(code_dir):
                        import shutil
                        for py_file in glob.glob("pptcover/*.py"):
                            filename = os.path.basename(py_file)
                            shutil.copy2(py_file, os.path.join(code_dir, filename))
                            update_job_status(log_msg=f'âœ… å¤åˆ¶: {filename}')
                        
                        logo_source = "/home/EduAgent/pptcover/logo_test.png"
                        if os.path.exists(logo_source):
                            shutil.copy2(logo_source, os.path.join(code_dir, "logo_test.png"))
                            update_job_status(log_msg=f'âœ… å¤åˆ¶logoæ–‡ä»¶: logo_test.png')
                        else:
                            update_job_status(log_msg='âš ï¸ æœªæ‰¾åˆ°logoæ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶')
                        
                    else:
                        update_job_status(log_msg='âš ï¸ coverç›®å½•æˆ–Codeç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶æ­¥éª¤')
                    
                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ å¤åˆ¶coveræ–‡ä»¶æ—¶å‡ºé”™: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤')
                
                update_job_status(progress=75, step='ğŸ¬ Step 3.6: ç”Ÿæˆå°é¢å†…å®¹',
                                log_msg='ğŸ”„ å¼€å§‹ç”Ÿæˆå°é¢å†…å®¹...',
                                output_dir=output_dir)
                
                try:
                    cover_result = generate_pptcover_content(process_id)
                    subprocess.run(['echo', 'å¼€å§‹å¼€å§‹ç”ŸæˆPPTå°é¢å†…å®¹...'], check=True)
                    #subprocess.run(['echo', cover_result])
                    if cover_result.get('status') == 'success':
                        update_job_status(log_msg=f'âœ… å°é¢å†…å®¹ç”ŸæˆæˆåŠŸ: {cover_result.get("title", "æ— æ ‡é¢˜")}')
                        subprocess.run(['echo', 'æˆåŠŸç”Ÿæˆå°é¢å†…å®¹'], check=True)
                    else:
                        update_job_status(log_msg=f'âš ï¸ å°é¢ç”Ÿæˆé—®é¢˜: {cover_result.get("note", cover_result.get("error", "æœªçŸ¥é”™è¯¯"))}')
                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ å°é¢ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤')
                    subprocess.run(['echo', 'å°é¢ç”Ÿæˆå¤±è´¥å¤±è´¥å¤±è´¥'], check=True)
                

                update_job_status(progress=80, step='ğŸ¥ Step 4.5: å¼€å§‹é¢„è§ˆPPT',
                                log_msg='ğŸ‰ åˆå§‹å¤„ç†å®Œæˆï¼å¼€å§‹ç”Ÿæˆé¢„è§ˆPPT...',
                                output_dir=output_dir,
                                status='rendering_preview',
                                stage='rendering_preview')
                
                render_preview_ppt(process_id, base_name)
                
                # ã€æ–°å¢é€»è¾‘ã€‘æ ¹æ® job_info ä¸­çš„è®¾ç½®ï¼Œå†³å®šæ˜¯å¦è‡ªåŠ¨æ‰§è¡Œåç»­æ­¥éª¤
                try:
                    with processing_lock:
                        job = processing_jobs[process_id]
                        auto_continue = job.get('auto_continue', False) # ä»ä»»åŠ¡çŠ¶æ€ä¸­è¯»å–

                    if auto_continue:
                        update_job_status(log_msg='âš™ï¸ è‡ªåŠ¨æ¨¡å¼å·²å¯ç”¨ï¼Œæ— ç¼è¡”æ¥åç»­å¤„ç†...')
                        # ä¸ºäº†å…¼å®¹ continue_paper_processingï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®å®ƒæœŸæœ›çš„ stage
                        with processing_lock:
                            processing_jobs[process_id]['stage'] = 'waiting_for_edit'
                        
                        continue_paper_processing(process_id)
                except Exception as e:
                    update_job_status(
                        status='failed', 
                        step='âŒ è‡ªåŠ¨è¡”æ¥å¤±è´¥', 
                        error=f'è°ƒç”¨ continue_paper_processing æ—¶å‡ºé”™: {str(e)}'
                    )
        else:
            # é¢„å¤„ç†å¤±è´¥çš„é€»è¾‘
            update_job_status(
                status='failed', 
                step='âŒ é¢„å¤„ç†å¤±è´¥', 
                error=f'è„šæœ¬ {script_to_run} æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {process.returncode}',
                log_msg=f'é¢„å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚'
            )
    
    except Exception as e:
        # å¼‚å¸¸å¤„ç†é€»è¾‘
        update_job_status(
            status='failed', 
            step='âŒ å¤„ç†å¼‚å¸¸', 
            error=str(e),
            log_msg=f'åˆå§‹å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}'
        )

# è®ºæ–‡é›†é¢„å¤„ç†
def start_folder_processing(folder_path, folder_name, unique_base_name, video_duration='medium', voice_type='female', output_format='video', background_choice='default', auto_continue=False):
    """
    å¯åŠ¨æ•´ä¸ªæ–‡ä»¶å¤¹çš„å¤„ç†æµç¨‹ã€‚
    è¿™ä¸ªå‡½æ•°æ¥æ”¶çš„æ˜¯ä¸€ä¸ªæ–‡ä»¶å¤¹è·¯å¾„ã€‚
    ä¿®æ”¹å‡½æ•°ç­¾åï¼Œå¢åŠ  unique_base_name å‚æ•°,å¢åŠ  background_choice å‚æ•°
    ä½¿ç”¨ FormData å¯¹è±¡æ¥åŒæ—¶æäº¤æ™®é€šè¡¨å•æ•°æ®å’Œæ–‡ä»¶
    åŒ…å«ä¸å•ç¯‡å¤„ç†å®Œå…¨ä¸€è‡´çš„è‡ªå®šä¹‰éŸ³è‰²å¤„ç†é€»è¾‘
    """
    # ä¸å•ç¯‡å¤„ç†ï¼Œæ·»åŠ å®Œå…¨ç›¸åŒçš„å…¥å£æ—¥å¿—ï¼Œç¡®è®¤å‡½æ•°è¢«è°ƒç”¨ä¸”å‚æ•°æ­£ç¡®
    print(f"--- [SERVICE DEBUG] start_FOLDER_processing ---")
    print(f"  æ¥æ”¶åˆ°çš„ folder_path å‚æ•°: [{folder_path}]")
    print(f"  æ¥æ”¶åˆ°çš„ folder_name å‚æ•°: [{folder_name}]")
    print(f"  æ¥æ”¶åˆ°çš„ voice_type å‚æ•°: [{voice_type}]")

    process_id = str(uuid.uuid4()) # ä¸ºæ•´ä¸ªæ‰¹æ¬¡åˆ›å»ºä¸€ä¸ªæ€»çš„ process_id
    base_name = unique_base_name # ã€æ ¸å¿ƒã€‘ç›´æ¥ä½¿ç”¨ä»è·¯ç”±å±‚ä¼ é€’è¿‡æ¥çš„å”¯ä¸€åŸºç¡€å
    # å®Œå…¨å¤ç”¨å•ç¯‡å¤„ç†ä¸­çš„è‡ªå®šä¹‰éŸ³è‰²æ–‡ä»¶å’Œæ–‡æœ¬å¤„ç†é€»è¾‘
    custom_voice_path = None 
    custom_voice_text = request.form.get('voiceText', '')
    voice_file = request.files.get('voiceFile')
    output_dir = f"Paper2Video/{base_name}_output"   # å®šä¹‰è¾“å‡ºç›®å½•ï¼Œç”¨äºå­˜æ”¾ä¸´æ—¶éŸ³è‰²æ–‡ä»¶

    if voice_type == 'custom' and voice_file:
        temp_dir = f'{output_dir}/temp' # å°†ä¸´æ—¶æ–‡ä»¶å­˜æ”¾åœ¨è¯¥æ‰¹æ¬¡ä»»åŠ¡çš„è¾“å‡ºç›®å½•ä¸‹
        os.makedirs(temp_dir, exist_ok=True)
        safe_filename = secure_filename(voice_file.filename)
        custom_voice_path = os.path.join(temp_dir, safe_filename)
        voice_file.save(custom_voice_path)
        print(f"âœ… æ–‡ä»¶å¤¹å¤„ç†ä»»åŠ¡ {process_id}: è‡ªå®šä¹‰éŸ³è‰²æ–‡ä»¶å·²ä¿å­˜è‡³: {custom_voice_path}")

    # å¤„ç†è‡ªå®šä¹‰èƒŒæ™¯æ–‡ä»¶
    custom_background_path = None
    background_file = request.files.get('backgroundFile')

    if background_choice == 'custom' and background_file:
        temp_dir = f'{output_dir}/temp'  # output_dir åœ¨è¿™ä¹‹å‰å·²ç»å®šä¹‰
        os.makedirs(temp_dir, exist_ok=True)
        safe_bg_filename = secure_filename(background_file.filename)
        custom_background_path = os.path.join(temp_dir, safe_bg_filename)
        background_file.save(custom_background_path)
        print(f"âœ… æ–‡ä»¶å¤¹å¤„ç†ä»»åŠ¡: è‡ªå®šä¹‰èƒŒæ™¯æ–‡ä»¶å·²ä¿å­˜è‡³: {custom_background_path}")

    # åˆ›å»ºå¤„ç†è®°å½•ï¼Œæ³¨æ„è¿™é‡Œè®°å½•çš„æ˜¯ folder_path
    # åˆ›å»ºå¤„ç†è®°å½•ï¼Œç°åœ¨åŒ…å«äº†æ‰€æœ‰å¿…è¦çš„å­—æ®µ
    job_info = {
        'process_id': process_id,
        'folder_path': folder_path,       # åŒºåˆ«ï¼šè®°å½•æ–‡ä»¶å¤¹è·¯å¾„
        'folder_name': folder_name,       # åŒºåˆ«ï¼šè®°å½•æ–‡ä»¶å¤¹å
        'base_name': base_name,
        'video_duration': video_duration,
        'voice_type': voice_type,
        'output_format': output_format,

        'custom_voice_path': custom_voice_path, 
        'custom_voice_text': custom_voice_text, 
        'background_choice': background_choice,
        'custom_background_path': custom_background_path,

        'auto_continue': auto_continue,

        'status': 'starting',
        'progress': 0,
        'start_time': datetime.now().isoformat(),
        'last_update': datetime.now().isoformat(),
        'current_step': 'Step 0: å‡†å¤‡å¼€å§‹',
        'log_messages': [],
        'output_dir': None,
        'final_video_path': None,
        'final_output_path': None,
        'error': None,
        'stage': 'initial'
    }

    # --- [è°ƒè¯•ç‚¹2] ---
    # print(f"  å³å°†ä¸ºæ–‡ä»¶å¤¹å¤„ç†åˆ›å»º job_infoï¼Œvoice_type ä¸º: [{job_info['voice_type']}]")
    # print(f"-------------------------------------------")


    with processing_lock:
        processing_jobs[process_id] = job_info

    # å¯åŠ¨å¼‚æ­¥å¤„ç†çº¿ç¨‹ï¼Œè°ƒç”¨ä¸€ä¸ªæ–°çš„è¿è¡Œå‡½æ•°
    processing_thread = threading.Thread(
        target=run_folder_processing, # <-- è°ƒç”¨ä¸ºæ–‡ä»¶å¤¹è®¾è®¡çš„è¿è¡Œå‡½æ•°
        args=(process_id, folder_path, base_name)
    )
    processing_thread.daemon = True
    processing_thread.start()

    return {
        'process_id': process_id,
        'message': f'å¼€å§‹å¤„ç†æ–‡ä»¶å¤¹: {folder_name}',
        'status': 'starting'
    }

def run_folder_processing(process_id, folder_path, base_name):
    """
    è¿è¡ŒåŸºäºæ–‡ä»¶å¤¹çš„åˆå§‹å¤„ç†æµç¨‹ã€‚
    é€»è¾‘ä¸ run_initial_processing éå¸¸ç›¸ä¼¼ï¼Œä½†ä¼ é€’ç»™è„šæœ¬çš„æ˜¯æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    """
    # å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼Œä¿æŒä¸å˜
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, output_dir=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if output_dir: job['output_dir'] = output_dir
                if stage: job['stage'] = stage
                job['last_update'] = datetime.now().isoformat()
    # --- [è°ƒè¯•ç‚¹ 3] ---
    # åˆ¤æ–­çº¿ç¨‹æ˜¯å¦æˆåŠŸå¯åŠ¨
    # print(f"\n--- [BACKGROUND THREAD] æ–‡ä»¶å¤¹å¤„ç†çº¿ç¨‹ {process_id} å·²æˆåŠŸå¯åŠ¨ï¼ ---\n")
    update_job_status(status='running', progress=5, step='å‡†å¤‡ç¯å¢ƒ') # <--- åˆå§‹çŠ¶æ€æ›´æ–°
    try:
        with processing_lock:
            job = processing_jobs[process_id]
            chosen_format = job.get('output_format', 'video')

        # é€‰æ‹©è¦æ‰§è¡Œçš„è„šæœ¬ (è¿™éƒ¨åˆ†é€»è¾‘å’Œå•æ–‡ä»¶å¤„ç†å®Œå…¨ä¸€æ ·)
        script_to_run = ''
        if chosen_format == 'video':
            script_to_run = 'all_pipeline_video.py'
        elif chosen_format == 'markdown':
            script_to_run = 'all_pipeline_markdown.py'
        elif chosen_format == 'ppt':
            script_to_run = 'all_pipeline_ppt.py'
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„è¾“å‡ºæ ¼å¼: {chosen_format}")

        script_path = os.path.abspath(script_to_run)
        output_dir_path = os.path.abspath(f"Paper2Video/{base_name}_output")
        
        # ã€é‡è¦ã€‘åœ¨å¯åŠ¨å‰ï¼Œå°±å°†æœ€ç»ˆçš„è¾“å‡ºç›®å½•ä¿å­˜åˆ°job_infoä¸­
        update_job_status(output_dir=output_dir_path)
        
        cmd = ['python3', script_path, folder_path, '--output-dir', output_dir_path]

        update_job_status(log_msg=f'ğŸš€ å¼€å§‹æ‰§è¡Œæ‰¹é‡å¤„ç†æµç¨‹ (è°ƒç”¨ {script_to_run})')
        update_job_status(log_msg=f'âš™ï¸ å°†è¦æ‰§è¡Œå‘½ä»¤: {" ".join(cmd)}')

        # æ‰§è¡Œå¤„ç†è„šæœ¬ (è¿™éƒ¨åˆ†ä»£ç ä¿æŒä¸å˜)
        env = os.environ.copy()
        env['PYTHONUNBUFFERED'] = '1'
        env['PYTHONIOENCODING'] = 'utf-8'
        
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            universal_newlines=True,
            bufsize=1, # ä½¿ç”¨è¡Œç¼“å†²
            encoding='utf-8',
            env=env
        )
        
        # å®æ—¶è¯»å–è¾“å‡º (è¿™éƒ¨åˆ†ä»£ç ä¿æŒä¸å˜)
        current_progress = 10
        update_job_status(progress=current_progress, step='Step 1: è®ºæ–‡è§£æ')

        if process.stdout:
            for line in process.stdout:
                line = line.strip()
                if line:
                    # all_pipeline_video.py å†…éƒ¨åœ¨å¹²ä»€ä¹ˆ
                    # print(f"  [SUBPROCESS OUTPUT] > {line}") 
                    update_job_status(log_msg=line)
                    # ç®€åŒ–çš„è¿›åº¦æ›´æ–°
                    if 'Step' in line and current_progress < 65:
                         current_progress += 5
                         update_job_status(progress=min(current_progress, 65))
        
        process.wait()
        # åˆ¤æ–­å­è¿›ç¨‹æ˜¯æˆåŠŸè¿˜æ˜¯å¤±è´¥
        # print(f"\n--- [BACKGROUND THREAD] å­è¿›ç¨‹å¤„ç†å®Œæ¯•ï¼Œè¿”å›ç : {process.returncode} ---\n")
        # 3. é¢„å¤„ç†è„šæœ¬æ‰§è¡Œå®Œæ¯•åï¼Œæ ¹æ®æ ¼å¼é€‰æ‹©ä¸‹ä¸€æ­¥æ“ä½œ
        if process.returncode == 0:
            update_job_status(log_msg=f'âœ… {script_to_run} å¯¹æ–‡ä»¶å¤¹å¤„ç†æˆåŠŸ!')
            # åç»­ä»»åŠ¡çš„äºŒæ¬¡åˆ†æµ
            if chosen_format == 'markdown':
                # å¦‚æœæ˜¯Markdownï¼Œåˆ™è°ƒç”¨æ–‡æ¡£ç”Ÿæˆå’Œæ‰“åŒ…å‡½æ•°
                update_job_status(status='running', step='ğŸ“ Step 2: ç”Ÿæˆå¹¶æ‰“åŒ…Markdownæ–‡æ¡£')
                # è¿™ä¸ª run_markdown_generation å‡½æ•°æ˜¯æˆ‘ä»¬ä¹‹å‰å·²ç»å†™å¥½çš„
                run_folder_markdown_generation(process_id, base_name)

            elif chosen_format == 'video':
                # å¦‚æœæ˜¯è§†é¢‘ï¼Œåˆ™ç»§ç»­æ‰§è¡Œè§†é¢‘ç‹¬æœ‰çš„åç»­æ­¥éª¤
                update_job_status(progress=70, step='ğŸ“ Step 3.5: å¤åˆ¶coveråœºæ™¯æ–‡ä»¶',
                                log_msg='ğŸ”„ å¼€å§‹å¤åˆ¶coveræ–‡ä»¶åˆ°Codeç›®å½•...')
                
                output_dir = f"Paper2Video/{base_name}_output"
                code_dir = f"{output_dir}/final_results/Code"
                try:
                    if os.path.exists("cover") and os.path.exists(code_dir):
                        import shutil
                        for py_file in glob.glob("cover/*.py"):
                            filename = os.path.basename(py_file)
                            shutil.copy2(py_file, os.path.join(code_dir, filename))
                            update_job_status(log_msg=f'âœ… å¤åˆ¶: {filename}')
                        
                        logo_source = "/home/EduAgent/static/template_images/EDUPAL_logo.png"
                        if os.path.exists(logo_source):
                            shutil.copy2(logo_source, os.path.join(code_dir, "EDUPAL_logo.png"))
                            update_job_status(log_msg=f'âœ… å¤åˆ¶logoæ–‡ä»¶: EDUPAL_logo.png')
                        else:
                            update_job_status(log_msg='âš ï¸ æœªæ‰¾åˆ°logoæ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶')
                        
                    else:
                        update_job_status(log_msg='âš ï¸ coverç›®å½•æˆ–Codeç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶æ­¥éª¤')
                    
                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ å¤åˆ¶coveræ–‡ä»¶æ—¶å‡ºé”™: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤')
                
                update_job_status(progress=75, step='ğŸ¬ Step 3.6: ç”Ÿæˆå°é¢å†…å®¹',
                                log_msg='ğŸ”„ å¼€å§‹ç”Ÿæˆå°é¢å†…å®¹...',
                                output_dir=output_dir)
                
                try:
                    cover_result = generate_cover_content(process_id)
                    if cover_result.get('status') == 'success':
                        update_job_status(log_msg=f'âœ… å°é¢å†…å®¹ç”ŸæˆæˆåŠŸ: {cover_result.get("title", "æ— æ ‡é¢˜")}')
                    else:
                        update_job_status(log_msg=f'âš ï¸ å°é¢ç”Ÿæˆé—®é¢˜: {cover_result.get("note", cover_result.get("error", "æœªçŸ¥é”™è¯¯"))}')
                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ å°é¢ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤')
                
                # è‡ªåŠ¨åº”ç”¨èƒŒæ™¯å›¾
                try:
                    with processing_lock:
                        job = processing_jobs[process_id]
                        # ä» job_info ä¸­è·å–ä¹‹å‰å­˜å‚¨çš„èƒŒæ™¯è®¾ç½®
                        choice = job.get('background_choice', 'default')
                        custom_path = job.get('custom_background_path')

                    # code_dir å˜é‡åœ¨ä¹‹å‰çš„ä»£ç ä¸­å·²ç»å®šä¹‰
                    background_to_apply = None

                    # æ£€æŸ¥æ˜¯å¦éœ€è¦åº”ç”¨èƒŒæ™¯
                    if choice and choice != 'default':
                        update_job_status(log_msg=f'ğŸ¨ æ£€æµ‹åˆ°ç”¨æˆ·é€‰æ‹©èƒŒæ™¯: {choice}ï¼Œå¼€å§‹åº”ç”¨...')
                        
                        # æƒ…å†µä¸€ï¼šç”¨æˆ·ä¸Šä¼ äº†è‡ªå®šä¹‰èƒŒæ™¯
                        if choice == 'custom' and custom_path and os.path.exists(custom_path):
                            filename = os.path.basename(custom_path)
                            destination_path = os.path.join(code_dir, filename)
                            
                            update_job_status(log_msg=f'    -> æ­£åœ¨å¤åˆ¶è‡ªå®šä¹‰èƒŒæ™¯: {filename} åˆ°Codeç›®å½•')
                            shutil.copy2(custom_path, destination_path)
                            background_to_apply = filename

                        # æƒ…å†µäºŒï¼šç”¨æˆ·é€‰æ‹©äº†é¢„è®¾èƒŒæ™¯ (ä¾‹å¦‚ 'SJTU.png')
                        elif choice != 'custom':
                            # é¢„è®¾èƒŒæ™¯å›¾å­˜æ”¾åœ¨ static/backgrounds/
                            preset_source_path = os.path.join('static', 'backgrounds', choice)
                            if os.path.exists(preset_source_path):
                                destination_path = os.path.join(code_dir, choice)
                                update_job_status(log_msg=f'    -> æ­£åœ¨å¤åˆ¶é¢„è®¾èƒŒæ™¯: {choice} åˆ°Codeç›®å½•')
                                shutil.copy2(preset_source_path, destination_path)
                                background_to_apply = choice
                            else:
                                update_job_status(log_msg=f'    âš ï¸ é¢„è®¾èƒŒæ™¯æ–‡ä»¶ä¸å­˜åœ¨: {preset_source_path}ï¼Œè·³è¿‡åº”ç”¨')
                        
                        # å¦‚æœæˆåŠŸå¤åˆ¶äº†èƒŒæ™¯æ–‡ä»¶ï¼Œåˆ™è°ƒç”¨è„šæœ¬åº”ç”¨å®ƒ
                        if background_to_apply:
                            update_job_status(log_msg=f'    -> è°ƒç”¨è„šæœ¬ä»¥åº”ç”¨èƒŒæ™¯: {background_to_apply}')
                            # apply_background_to_code æ˜¯ä¹‹å‰å†™å¥½å‡½æ•°ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨
                            try:
                                # æ³¨æ„ï¼šapply_background_to_code å‡½æ•°éœ€è¦ process_id å’Œæ–‡ä»¶å
                                apply_result = apply_background_to_code(process_id, background_to_apply)
                                update_job_status(log_msg=f'    âœ… èƒŒæ™¯åº”ç”¨å®Œæˆ: {apply_result.get("message", "æ— è¿”å›ä¿¡æ¯")}')
                            except Exception as apply_error:
                                update_job_status(log_msg=f'    âŒ åº”ç”¨èƒŒæ™¯è„šæœ¬æ—¶å‡ºé”™: {str(apply_error)}')
                        else:
                             update_job_status(log_msg='    -> æœªèƒ½å®šä½åˆ°æœ‰æ•ˆèƒŒæ™¯æ–‡ä»¶ï¼Œè·³è¿‡åº”ç”¨ã€‚')

                    else:
                        update_job_status(log_msg='ğŸ¨ ç”¨æˆ·æœªæŒ‡å®šç‰¹æ®ŠèƒŒæ™¯ï¼Œä½¿ç”¨é»˜è®¤èƒŒæ™¯ã€‚')

                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ åº”ç”¨èƒŒæ™¯å›¾æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {str(e)}ï¼Œå¤„ç†å°†ç»§ç»­ä½†èƒŒæ™¯å¯èƒ½ä¸ä¼šç”Ÿæ•ˆã€‚')

                update_job_status(progress=80, step='ğŸ¥ Step 4.5: å¼€å§‹é¢„è§ˆè§†é¢‘æ¸²æŸ“',
                                log_msg='ğŸ‰ åˆå§‹å¤„ç†å®Œæˆï¼å¼€å§‹ç”Ÿæˆé¢„è§ˆè§†é¢‘...',
                                output_dir=output_dir,
                                status='rendering_preview',
                                stage='rendering_preview')
                
                render_preview_video(process_id, base_name)

                # ã€æ–°å¢é€»è¾‘ã€‘æ ¹æ® job_info ä¸­çš„è®¾ç½®ï¼Œå†³å®šæ˜¯å¦è‡ªåŠ¨æ‰§è¡Œåç»­æ­¥éª¤
                try:
                    with processing_lock:
                        job = processing_jobs[process_id]
                        auto_continue = job.get('auto_continue', False) # ä»ä»»åŠ¡çŠ¶æ€ä¸­è¯»å–

                    if auto_continue:
                        update_job_status(log_msg='âš™ï¸ è‡ªåŠ¨æ¨¡å¼å·²å¯ç”¨ï¼Œæ— ç¼è¡”æ¥åç»­å¤„ç†...')
                        # ä¸ºäº†å…¼å®¹ continue_paper_processingï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®å®ƒæœŸæœ›çš„ stage
                        with processing_lock:
                            processing_jobs[process_id]['stage'] = 'waiting_for_edit'
                        
                        continue_paper_processing(process_id)
                except Exception as e:
                    update_job_status(
                        status='failed', 
                        step='âŒ è‡ªåŠ¨è¡”æ¥å¤±è´¥', 
                        error=f'è°ƒç”¨ continue_paper_processing æ—¶å‡ºé”™: {str(e)}'
                    )

            elif chosen_format == 'ppt':
                # å¦‚æœæ˜¯è§†é¢‘ï¼Œåˆ™ç»§ç»­æ‰§è¡Œè§†é¢‘ç‹¬æœ‰çš„åç»­æ­¥éª¤
                update_job_status(progress=70, step='ğŸ“ Step 3.5: å¤åˆ¶coveråœºæ™¯æ–‡ä»¶',
                                log_msg='ğŸ”„ å¼€å§‹å¤åˆ¶coveræ–‡ä»¶åˆ°Codeç›®å½•...')
                
                output_dir = f"Paper2Video/{base_name}_output"
                code_dir = f"{output_dir}/final_results/Code"
                try:
                    if os.path.exists("pptcover") and os.path.exists(code_dir):
                        import shutil
                        for py_file in glob.glob("pptcover/*.py"):
                            filename = os.path.basename(py_file)
                            shutil.copy2(py_file, os.path.join(code_dir, filename))
                            update_job_status(log_msg=f'âœ… å¤åˆ¶: {filename}')
                        
                        logo_source = "/home/EduAgent/logo_test.png"
                        if os.path.exists(logo_source):
                            shutil.copy2(logo_source, os.path.join(code_dir, "logo_test.png"))
                            update_job_status(log_msg=f'âœ… å¤åˆ¶logoæ–‡ä»¶: logo_test.png')
                        else:
                            update_job_status(log_msg='âš ï¸ æœªæ‰¾åˆ°logoæ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶')
                        
                    else:
                        update_job_status(log_msg='âš ï¸ coverç›®å½•æˆ–Codeç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤åˆ¶æ­¥éª¤')
                    
                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ å¤åˆ¶coveræ–‡ä»¶æ—¶å‡ºé”™: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤')
                
                update_job_status(progress=75, step='ğŸ¬ Step 3.6: ç”Ÿæˆå°é¢å†…å®¹',
                                log_msg='ğŸ”„ å¼€å§‹ç”Ÿæˆå°é¢å†…å®¹...',
                                output_dir=output_dir)
                
                try:
                    cover_result = generate_pptcover_content(process_id)
                    subprocess.run(['echo', 'å¼€å§‹å¼€å§‹ç”ŸæˆPPTå°é¢å†…å®¹...'], check=True)
                    #subprocess.run(['echo', cover_result])
                    if cover_result.get('status') == 'success':
                        update_job_status(log_msg=f'âœ… å°é¢å†…å®¹ç”ŸæˆæˆåŠŸ: {cover_result.get("title", "æ— æ ‡é¢˜")}')
                        subprocess.run(['echo', 'æˆåŠŸç”Ÿæˆå°é¢å†…å®¹'], check=True)
                    else:
                        update_job_status(log_msg=f'âš ï¸ å°é¢ç”Ÿæˆé—®é¢˜: {cover_result.get("note", cover_result.get("error", "æœªçŸ¥é”™è¯¯"))}')
                except Exception as e:
                    update_job_status(log_msg=f'âš ï¸ å°é¢ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤')
                    subprocess.run(['echo', 'å°é¢ç”Ÿæˆå¤±è´¥å¤±è´¥å¤±è´¥'], check=True)
                
                update_job_status(progress=80, step='ğŸ¥ Step 4.5: å¼€å§‹é¢„è§ˆPPTæ¸²æŸ“',
                                log_msg='ğŸ‰ åˆå§‹å¤„ç†å®Œæˆï¼å¼€å§‹ç”Ÿæˆé¢„è§ˆPPT...',
                                output_dir=output_dir,
                                status='rendering_preview',
                                stage='rendering_preview')
                
                render_preview_ppt(process_id, base_name)
                
                # ã€æ–°å¢é€»è¾‘ã€‘æ ¹æ® job_info ä¸­çš„è®¾ç½®ï¼Œå†³å®šæ˜¯å¦è‡ªåŠ¨æ‰§è¡Œåç»­æ­¥éª¤
                try:
                    with processing_lock:
                        job = processing_jobs[process_id]
                        auto_continue = job.get('auto_continue', False) # ä»ä»»åŠ¡çŠ¶æ€ä¸­è¯»å–

                    if auto_continue:
                        update_job_status(log_msg='âš™ï¸ è‡ªåŠ¨æ¨¡å¼å·²å¯ç”¨ï¼Œæ— ç¼è¡”æ¥åç»­å¤„ç†...')
                        # ä¸ºäº†å…¼å®¹ continue_paper_processingï¼Œéœ€è¦æ‰‹åŠ¨è®¾ç½®å®ƒæœŸæœ›çš„ stage
                        with processing_lock:
                            processing_jobs[process_id]['stage'] = 'waiting_for_edit'
                        
                        continue_paper_processing(process_id)
                except Exception as e:
                    update_job_status(
                        status='failed', 
                        step='âŒ è‡ªåŠ¨è¡”æ¥å¤±è´¥', 
                        error=f'è°ƒç”¨ continue_paper_processing æ—¶å‡ºé”™: {str(e)}'
                    )
        else:
            # é¢„å¤„ç†å¤±è´¥çš„é€»è¾‘
            update_job_status(
                status='failed', 
                step='âŒ é¢„å¤„ç†å¤±è´¥', 
                error=f'è„šæœ¬ {script_to_run} æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {process.returncode}',
                log_msg=f'é¢„å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—ã€‚'
            )
            print(f'é€€å‡ºç ï¼š{process.returncode}')
    
    except Exception as e:
        import traceback
        print(f"\n--- [CRITICAL THREAD ERROR] æ–‡ä»¶å¤¹å¤„ç†çº¿ç¨‹ {process_id} å‘ç”Ÿå´©æºƒï¼ ---\n")
        traceback.print_exc()
        # å¼‚å¸¸å¤„ç†é€»è¾‘
        update_job_status(
            status='failed', 
            step='âŒ å¤„ç†å¼‚å¸¸', 
            error=str(e),
            log_msg=f'åˆå§‹å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}'
        )


# å•è®ºæ–‡&è®ºæ–‡é›†åç»­å¤„ç†æ­¥éª¤
# åå¤„ç†æ€»å…¥å£
def continue_paper_processing(process_id):
    """ç»§ç»­è®ºæ–‡å¤„ç†æµç¨‹ï¼ˆStep 4.5-9ï¼‰"""
    import os # ã€æ–°å¢ã€‘
    import json # ã€æ–°å¢ã€‘

    with processing_lock:
        if process_id not in processing_jobs:
            raise Exception('å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨')
        
        job = processing_jobs[process_id]
        if job['stage'] != 'waiting_for_edit':
            raise Exception(f'å½“å‰é˜¶æ®µä¸æ”¯æŒç»§ç»­å¤„ç†: {job["stage"]}')
        
        # æ›´æ–°çŠ¶æ€ä¸ºç»§ç»­å¤„ç†
        job['stage'] = 'continuing'
        job['status'] = 'running'
        base_name = job['base_name']
    
    # å¯åŠ¨ç»§ç»­å¤„ç†çº¿ç¨‹
    print('å¼€å§‹å¯åŠ¨å¤„ç†')
    job = processing_jobs[process_id]
    chosen_format = job.get('output_format', 'video')
    if chosen_format == 'video':
        processing_thread = threading.Thread(
            target=run_continue_processing, 
            # target=run_final_processing, 
            args=(process_id, base_name)
        )
    elif chosen_format == 'ppt':
        processing_thread = threading.Thread(
            target=run_continue_processing_ppt, 
            # target=run_final_processing, 
            args=(process_id, base_name)
        )
    processing_thread.daemon = True
    processing_thread.start()
    
    return {
        'process_id': process_id,
        'message': 'å¼€å§‹ç»§ç»­å¤„ç†åç»­æ­¥éª¤',
        'status': 'running'
    }

# videoåˆ†æµ
def run_continue_processing(process_id, base_name):
    """è¿è¡Œç»§ç»­å¤„ç†æµç¨‹ï¼ˆStep 4.5-9ï¼‰- è·³è¿‡åé¦ˆç¼–è¾‘"""
    import os
    import json
    import traceback
    import subprocess
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, final_video=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if final_video: job['final_video_path'] = final_video
                if stage: job['stage'] = stage
                
                job['last_update'] = datetime.now().isoformat()
    
    try:
        update_job_status(progress=85, step='ğŸ“¹ Step 4.5: å¼€å§‹åç»­å¤„ç†',
                         log_msg='ğŸ”„ ç»§ç»­æ‰§è¡ŒStep 4.5-9...')
        
        # output_dir = f"{base_name}_output"
        project_root = os.path.abspath(os.path.dirname(__file__))
        output_dir_name = f"{base_name}_output"
                # === åˆ›å»ºé…ç½®æ–‡ä»¶ (è¿™æ˜¯æ‚¨ç¼ºå¤±çš„å…³é”®é€»è¾‘) ===
        with processing_lock:
            job = processing_jobs[process_id]
            custom_voice_path_rel = job.get("custom_voice_path")
            custom_voice_path_abs = None
            if custom_voice_path_rel:
                custom_voice_path_abs = os.path.join(project_root, custom_voice_path_rel)
            config_to_pass = {
                "voice_type": job.get("voice_type"),
                "custom_voice_path": custom_voice_path_abs,
                "custom_voice_text": job.get("custom_voice_text"),
            }
        
        print(f"--- [SERVICE DEBUG] run_continue_processing ---")
        print(f"  ä¸º {process_id} åˆ›å»º job_config.json")
        print(f"  å†…å®¹: {config_to_pass}")
        print(f"---------------------------------------------")
        
        temp_dir_abs = os.path.join(project_root, 'Paper2Video', output_dir_name, 'temp')
        os.makedirs(temp_dir_abs, exist_ok=True)
        config_path_abs = os.path.join(temp_dir_abs, 'job_config.json')
        with open(config_path_abs, 'w', encoding='utf-8') as f:
            json.dump(config_to_pass, f, ensure_ascii=False)
        
        # === æ„å»º cmdï¼Œå°†é…ç½®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ä½œä¸ºå‚æ•°ä¼ é€’ ===
        print('åˆ°äº†è¿™ä¸€æ­¥')
        job = processing_jobs[process_id]
        chosen_format = job.get('output_format', 'video')
        if chosen_format == 'video':
            script_path = os.path.join(project_root, 'continue_pipeline.sh')
        elif chosen_format == 'ppt':
            script_path = os.path.join(project_root, 'continue_pipeline_ppt.sh')
        cmd = ['bash', script_path, output_dir_name, config_path_abs]

        # # æ„å»ºç»§ç»­å¤„ç†å‘½ä»¤ - ä½¿ç”¨ç‰¹æ®Šçš„è„šæœ¬åªæ‰§è¡Œåç»­æ­¥éª¤
        # cmd = ['bash', 'continue_pipeline.sh', output_dir]
        
        # æ‰§è¡Œå¤„ç†è„šæœ¬
        env = os.environ.copy()
        env['PYTHONUNBUFFERED'] = '1'
        env['PYTHONIOENCODING'] = 'utf-8'
        
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            universal_newlines=True,
            bufsize=0,
            encoding='utf-8',
            env=env
        )
        
        current_progress = 85
        
        if process.stdout:
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                
                if line:
                    line = line.rstrip()
                    if line:
                        update_job_status(log_msg=line)
                        
                        # æ ¹æ®è¾“å‡ºæ›´æ–°è¿›åº¦
                        if "Step 4.5" in line:
                            current_progress = max(current_progress, 87)
                            update_job_status(progress=current_progress, step="ğŸ“¹ Step 4.5: è§†é¢‘é¢„è§ˆæ¸²æŸ“")
                        elif "Step 5" in line:
                            current_progress = max(current_progress, 89)
                            update_job_status(progress=current_progress, step="ğŸ’¬ Step 5: åé¦ˆä¸ç¼–è¾‘")
                        elif "Step 6" in line:
                            current_progress = max(current_progress, 91)
                            update_job_status(progress=current_progress, step="ğŸµ Step 6: è¯­éŸ³åˆæˆ")
                        elif "Step 7" in line:
                            current_progress = max(current_progress, 94)
                            update_job_status(progress=current_progress, step="ğŸ”„ Step 7: éŸ³è§†é¢‘å¯¹é½")
                        elif "Step 8" in line:
                            current_progress = max(current_progress, 97)
                            update_job_status(progress=current_progress, step="ğŸ¬ Step 8: è§†é¢‘æ¸²æŸ“")
                        elif "Step 9" in line:
                            current_progress = max(current_progress, 99)
                            update_job_status(progress=current_progress, step="ğŸ¦ Step 9: è§†é¢‘éŸ³é¢‘åˆå¹¶")
                        elif "å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•" in line or "æ•™å­¦è§†é¢‘å·²ç”Ÿæˆ" in line:
                            current_progress = 100
                            update_job_status(progress=current_progress, step="âœ… å®Œæˆ: å¤„ç†æµç¨‹ç»“æŸ")
        process.wait()
        return_code = process.returncode

        if return_code == 0:
        # if process.returncode == 0:
            # æŸ¥æ‰¾æœ€ç»ˆè¾“å‡ºæ–‡ä»¶
            if chosen_format == 'video':
                final_output = f"Paper2Video/{base_name}_output/final_results/Video_with_voice/Full.mp4"
                update_job_status(
                    status='completed', 
                    progress=100, 
                    step='âœ… å¤„ç†å®Œæˆ', 
                    log_msg='ğŸ‰ å®Œæ•´çš„è®ºæ–‡å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆï¼',
                    final_video=final_output if os.path.exists(final_output) else None,
                    stage='completed'
                )
                # è®¾ç½® final_output_path
                with processing_lock:
                    if process_id in processing_jobs:
                        processing_jobs[process_id]['final_output_path'] = final_output if os.path.exists(final_output) else None
            elif chosen_format == 'ppt':
                final_output = f"Paper2Video/{base_name}_output/final_results/full_presentation.pptx"
                update_job_status(
                    status='completed', 
                    progress=100, 
                    step='âœ… å¤„ç†å®Œæˆ', 
                    log_msg='ğŸ‰ å®Œæ•´çš„PPTç”Ÿæˆæµç¨‹å…¨éƒ¨å®Œæˆï¼',
                    stage='completed'
                )
                # å¯¹äºPPTï¼Œè®¾ç½® final_output_path è€Œä¸æ˜¯ final_video_path
                with processing_lock:
                    if process_id in processing_jobs:
                        processing_jobs[process_id]['final_output_path'] = final_output if os.path.exists(final_output) else None
        else:
            update_job_status(
                status='failed', 
                step='âŒ åç»­å¤„ç†å¤±è´¥', 
                error=f'å¤„ç†è„šæœ¬é€€å‡ºç : {process.returncode}',
                log_msg='åç»­å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯'
            )
    
    except Exception as e:
        update_job_status(
            status='failed', 
            step='âŒ å¤„ç†å¼‚å¸¸', 
            error=str(e),
            log_msg=f'åç»­å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}'
        )

# pptåˆ†æµ
def run_continue_processing_ppt(process_id, base_name):
    """è¿è¡Œç»§ç»­å¤„ç†æµç¨‹ï¼ˆStep 4.5-9ï¼‰- è·³è¿‡åé¦ˆç¼–è¾‘"""
    import os
    import json
    import traceback
    import subprocess
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, final_video=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if final_video: job['final_video_path'] = final_video
                if stage: job['stage'] = stage
                
                job['last_update'] = datetime.now().isoformat()
    
    try:
        update_job_status(progress=85, step='ğŸ“¹ Step 4.5: å¼€å§‹åç»­å¤„ç†',
                         log_msg='ğŸ”„ ç»§ç»­æ‰§è¡ŒStep 4.5-5...')
        
        # output_dir = f"{base_name}_output"
        project_root = os.path.abspath(os.path.dirname(__file__))
        output_dir_name = f"{base_name}_output"
        
        # === æ„å»º cmdï¼Œå°†é…ç½®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ä½œä¸ºå‚æ•°ä¼ é€’ ===
        print('åˆ°äº†pptä¸­è¿™ä¸€æ­¥')
        job = processing_jobs[process_id]
        chosen_format = job.get('output_format', 'video')
        script_path = os.path.join(project_root, 'continue_pipeline_ppt.sh')
        output_dir = f"{base_name}_output"
        
        # æ„å»ºé¢„è§ˆè§†é¢‘æ¸²æŸ“å‘½ä»¤
        cmd = ['bash', 'render_ppt_final.sh', output_dir_name]
        
        # æ‰§è¡Œé¢„è§ˆæ¸²æŸ“è„šæœ¬
        import os
        env = os.environ.copy()
        env['PYTHONUNBUFFERED'] = '1'
        env['PYTHONIOENCODING'] = 'utf-8'
        
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            universal_newlines=True,
            bufsize=0,
            env=env
        )
        
        current_progress = 82
        
        if process.stdout:
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                
                if line:
                    line = line.strip()
                    print(f"[{process_id}] {line}")
                    
                    # æ ¹æ®è¾“å‡ºæ›´æ–°è¿›åº¦
                    if "Step 4.5" in line:
                        current_progress = min(current_progress + 2, 88)
                        update_job_status(progress=current_progress, log_msg=line)
                    elif "é¢„è§ˆPPT" in line:
                        current_progress = min(current_progress + 1, 88)
                        update_job_status(progress=current_progress, log_msg=line)
                    else:
                        update_job_status(log_msg=line)
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        return_code = process.wait()
        
        # cmd = ['bash', script_path, output_dir_name]

        # # # æ„å»ºç»§ç»­å¤„ç†å‘½ä»¤ - ä½¿ç”¨ç‰¹æ®Šçš„è„šæœ¬åªæ‰§è¡Œåç»­æ­¥éª¤
        # # cmd = ['bash', 'continue_pipeline.sh', output_dir]
        
        # # æ‰§è¡Œå¤„ç†è„šæœ¬
        # env = os.environ.copy()
        # env['PYTHONUNBUFFERED'] = '1'
        # env['PYTHONIOENCODING'] = 'utf-8'
        # print(f"æ‰§è¡Œå‘½ä»¤: {cmd}")
        
        # process = subprocess.Popen(
        #     cmd, 
        #     stdout=subprocess.PIPE, 
        #     stderr=subprocess.STDOUT, 
        #     universal_newlines=True,
        #     bufsize=0,
        #     encoding='utf-8',
        #     env=env
        # )
        # print(f"å¯åŠ¨æˆåŠŸprocess: {process}")
        
        # current_progress = 85
        
        # if process.stdout:
        #     while True:
        #         line = process.stdout.readline()
        #         if not line and process.poll() is not None:
        #             break
                
        #         if line:
        #             line = line.rstrip()
        #             if line:
        #                 update_job_status(log_msg=line)
                        
        #                 # æ ¹æ®è¾“å‡ºæ›´æ–°è¿›åº¦
        #                 if "Step 4.5" in line:
        #                     current_progress = max(current_progress, 87)
        #                     update_job_status(progress=current_progress, step="ğŸ“¹ Step 4.5: è§†é¢‘é¢„è§ˆæ¸²æŸ“")
        #                 elif "Step 5" in line:
        #                     current_progress = max(current_progress, 89)
        #                     update_job_status(progress=current_progress, step="ğŸ’¬ Step 5: åé¦ˆä¸ç¼–è¾‘")
        #                 elif "Step 6" in line:
        #                     current_progress = max(current_progress, 91)
        #                     update_job_status(progress=current_progress, step="ğŸµ Step 6: è¯­éŸ³åˆæˆ")
        #                 elif "Step 7" in line:
        #                     current_progress = max(current_progress, 94)
        #                     update_job_status(progress=current_progress, step="ğŸ”„ Step 7: éŸ³è§†é¢‘å¯¹é½")
        #                 elif "Step 8" in line:
        #                     current_progress = max(current_progress, 97)
        #                     update_job_status(progress=current_progress, step="ğŸ¬ Step 8: è§†é¢‘æ¸²æŸ“")
        #                 elif "Step 9" in line:
        #                     current_progress = max(current_progress, 99)
        #                     update_job_status(progress=current_progress, step="ğŸ¦ Step 9: è§†é¢‘éŸ³é¢‘åˆå¹¶")
        #                 elif "å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•" in line or "æ•™å­¦è§†é¢‘å·²ç”Ÿæˆ" in line:
        #                     current_progress = 100
        #                     update_job_status(progress=current_progress, step="âœ… å®Œæˆ: å¤„ç†æµç¨‹ç»“æŸ")
        # process.wait()
        # return_code = process.returncode
        # print(f"å¤„ç†è„šæœ¬è¿”å›ç : {return_code}")

        if return_code == 0:
        # if process.returncode == 0:
            # æŸ¥æ‰¾æœ€ç»ˆPPTæ–‡ä»¶
            final_output = f"Paper2Video/{base_name}_output/final_results/full_presentation.pptx"
            update_job_status(
                status='completed', 
                progress=100, 
                step='âœ… å¤„ç†å®Œæˆ', 
                log_msg='ğŸ‰ å®Œæ•´çš„PPTç”Ÿæˆæµç¨‹å…¨éƒ¨å®Œæˆï¼',
                stage='completed'
            )
            # è®¾ç½® final_output_path
            with processing_lock:
                if process_id in processing_jobs:
                    processing_jobs[process_id]['final_output_path'] = final_output if os.path.exists(final_output) else None
        else:
            update_job_status(
                status='failed', 
                step='âŒ åç»­å¤„ç†å¤±è´¥', 
                error=f'å¤„ç†è„šæœ¬é€€å‡ºç : {process.returncode}',
                log_msg='åç»­å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯'
            )
    
    except Exception as e:
        update_job_status(
            status='failed', 
            step='âŒ å¤„ç†å¼‚å¸¸', 
            error=str(e),
            log_msg=f'åç»­å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}'
        )

# =================================================================
# ========================= è®ºæ–‡å¤„ç†æ ¸å¿ƒå‡½æ•° =========================
# =================================================================


def generate_cover_content(process_id):
    """ç”Ÿæˆå°é¢å†…å®¹ï¼ˆæ›¿ä»£generate_cover.shè„šæœ¬åŠŸèƒ½ï¼‰"""
    from pathlib import Path
    import shutil
    import re
    import json
    import sys
    
    # å¯¼å…¥cover_generator.pyçš„åŠŸèƒ½
    sys.path.append('/home/EduAgent')
    try:
        # å°è¯•å¯¼å…¥cover_generator.pyä¸­çš„åŠŸèƒ½
        from cover_generator import load_config, get_paper_info_with_llm, fuse_titles_with_llm
        from api_call import APIClient
    except ImportError as e:
        return {
            'error': f'å¯¼å…¥cover_generator.pyå¤±è´¥: {str(e)}',
            'status': 'failed'
        }
    
    with processing_lock:
        if process_id not in processing_jobs:
            return {
                'error': 'å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨',
                'status': 'failed'
            }
        
        job = processing_jobs[process_id]
        pdf_path = job.get('pdf_path')
        base_name = job.get('base_name')
        
        # æ›´æ–°çŠ¶æ€
        job['log_messages'].append({
            'time': datetime.now().isoformat(), 
            'message': 'ğŸ¬ å¼€å§‹æ‰§è¡ŒStep 3.6: ç”Ÿæˆå°é¢å†…å®¹...'
        })
    
    try:
        # è®¾ç½®è·¯å¾„
        source_manim_template_path = Path("/home/EduAgent/cover/1Introduction_code.py")
        mineru_output_dir = Path(f"/home/EduAgent/MinerU/outputs_clean/{base_name}")
        p2v_output_dir = Path(f"/home/EduAgent/Paper2Video/{base_name}_output")
        code_dir = p2v_output_dir / "final_results" / "Code"
        speech_dir = p2v_output_dir / "final_results" / "Speech"
        
        # æ£€æŸ¥å¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not source_manim_template_path.exists():
            raise FileNotFoundError(f"Manimæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {source_manim_template_path}")
        
        if not code_dir.exists():
            raise FileNotFoundError(f"Codeç›®å½•ä¸å­˜åœ¨: {code_dir}")
            
        if not speech_dir.exists():
            speech_dir.mkdir(parents=True, exist_ok=True)
            
        # æ£€æŸ¥MinerUè¾“å‡ºç›®å½•
        if not mineru_output_dir.exists():
            # å°è¯•åˆ›å»ºæˆ–æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„ç›®å½•
            alt_mineru_dir = Path(f"/home/EduAgent/MinerU/outputs/{base_name}")
            if alt_mineru_dir.exists():
                mineru_output_dir = alt_mineru_dir
            else:
                # å¦‚æœæ‰¾ä¸åˆ°MinerUè¾“å‡ºï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
                with processing_lock:
                    if process_id in processing_jobs:
                        job = processing_jobs[process_id]
                        job['log_messages'].append({
                            'time': datetime.now().isoformat(), 
                            'message': f'âš ï¸ è­¦å‘Š: MinerUè¾“å‡ºç›®å½•ä¸å­˜åœ¨: {mineru_output_dir}ï¼Œå°†ä½¿ç”¨é»˜è®¤æ ‡é¢˜'
                        })
                
                # ä½¿ç”¨é»˜è®¤æ¨¡æ¿åˆ›å»ºå°é¢
                create_default_cover(code_dir, speech_dir, base_name)
                
                return {
                    'message': 'ä½¿ç”¨é»˜è®¤å†…å®¹ç”Ÿæˆå°é¢æˆåŠŸ',
                    'status': 'success',
                    'note': 'MinerUè¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨äº†é»˜è®¤æ ‡é¢˜'
                }
        
        # åŠ è½½é…ç½®
        config = load_config()
        api_client = APIClient(api_key=config['api_key'], model=config['model'])
        
        # æŸ¥æ‰¾mdæ–‡ä»¶
        md_files = list(mineru_output_dir.glob('*.md'))
        if not md_files:
            # æ£€æŸ¥å­ç›®å½•
            for subdir in mineru_output_dir.iterdir():
                if subdir.is_dir():
                    md_files.extend(subdir.glob('*.md'))
        
        if not md_files:
            # å¦‚æœæ‰¾ä¸åˆ°mdæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
            with processing_lock:
                if process_id in processing_jobs:
                    job = processing_jobs[process_id]
                    job['log_messages'].append({
                        'time': datetime.now().isoformat(), 
                        'message': f'âš ï¸ è­¦å‘Š: åœ¨MinerUè¾“å‡ºç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•.mdæ–‡ä»¶: {mineru_output_dir}ï¼Œå°†ä½¿ç”¨é»˜è®¤æ ‡é¢˜'
                    })
            
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿åˆ›å»ºå°é¢
            create_default_cover(code_dir, speech_dir, base_name)
            
            return {
                'message': 'ä½¿ç”¨é»˜è®¤å†…å®¹ç”Ÿæˆå°é¢æˆåŠŸ',
                'status': 'success',
                'note': 'MinerUè¾“å‡ºç›®å½•ä¸­æœªæ‰¾åˆ°.mdæ–‡ä»¶ï¼Œä½¿ç”¨äº†é»˜è®¤æ ‡é¢˜'
            }
        
        # æå–æ‰€æœ‰è®ºæ–‡ä¿¡æ¯
        all_titles = []
        all_authors = []
        all_affiliations = []
        
        for md_file in md_files:
            info = get_paper_info_with_llm(md_file, api_client)
            if info:
                all_titles.append(info["title"])
                all_authors.append(info["authors"])
                all_affiliations.append(info["affiliations"])
                
        if not all_titles:
            # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
            with processing_lock:
                if process_id in processing_jobs:
                    job = processing_jobs[process_id]
                    job['log_messages'].append({
                        'time': datetime.now().isoformat(), 
                        'message': 'âš ï¸ è­¦å‘Š: æœªèƒ½ä»MDæ–‡ä»¶ä¸­æå–æ ‡é¢˜ï¼Œå°†ä½¿ç”¨é»˜è®¤æ ‡é¢˜'
                    })
            
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿åˆ›å»ºå°é¢
            create_default_cover(code_dir, speech_dir, base_name)
            
            return {
                'message': 'ä½¿ç”¨é»˜è®¤å†…å®¹ç”Ÿæˆå°é¢æˆåŠŸ',
                'status': 'success',
                'note': 'ä»MDæ–‡ä»¶æå–æ ‡é¢˜å¤±è´¥ï¼Œä½¿ç”¨äº†é»˜è®¤æ ‡é¢˜'
            }
        
        # æ˜¯å¦ä¸ºæ‰¹é‡æ¨¡å¼
        is_batch = len(all_titles) > 1
        
        # å¤„ç†å•ä½ä¿¡æ¯å»é‡
        unique_affiliations = set()
        for aff_group in all_affiliations:
            if aff_group:  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                # æŒ‰é€—å·åˆ†å‰²ï¼Œå¹¶å»é™¤æ¯ä¸ªå•ä½å‰åçš„ç©ºæ ¼
                affs = [aff.strip() for aff in aff_group.split(',') if aff.strip()]
                unique_affiliations.update(affs)
        
        # å°†å»é‡åçš„å•ä½æ’åºå¹¶åˆå¹¶æˆä¸€ä¸ªå­—ç¬¦ä¸²
        final_affiliations = ", ".join(sorted(list(unique_affiliations))) if unique_affiliations else "æœªçŸ¥å•ä½"
        
        # è®°å½•å•ä½å¤„ç†æ—¥å¿—
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                job['log_messages'].append({
                    'time': datetime.now().isoformat(), 
                    'message': f'ğŸ“‹ å•ä½ä¿¡æ¯å¤„ç†: åŸå§‹{len(all_affiliations)}ä¸ª -> å»é‡å{len(unique_affiliations)}ä¸ª'
                })
        
        # å‡†å¤‡æœ€ç»ˆçš„æ ‡é¢˜å’Œä½œè€…
        if is_batch:
            final_title = fuse_titles_with_llm(all_titles, api_client)
            final_authors = ", ".join(all_authors)
        else:
            final_title = all_titles[0] if all_titles else ""
            final_authors = all_authors[0] if all_authors else ""
        
        # æ›¿æ¢ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢ä»£ç è¯­æ³•é”™è¯¯
        final_title_escaped = final_title.replace('"', '\\"')
        final_authors_escaped = final_authors.replace('"', '\\"')
        final_affiliations_escaped = final_affiliations.replace('"', '\\"')
        
        # åˆ›å»ºå°é¢åœºæ™¯ä»£ç æ–‡ä»¶
        destination_manim_path = code_dir / "1Introduction_code.py"
        
        # ä»æºæ¨¡æ¿è¯»å–å†…å®¹
        content = source_manim_template_path.read_text(encoding='utf-8')
        
        # æ›¿æ¢æ ‡é¢˜ã€ä½œè€…å’Œå•ä½
        content = re.sub(r'title_text = ".*"', f'title_text = "{final_title_escaped}"', content)
        content = re.sub(r'author_text = ".*"', f'author_text = "{final_authors_escaped}"', content)
        content = re.sub(r'affiliation_text = ".*"', f'affiliation_text = "{final_affiliations_escaped}"', content)
        
        # å°†ä¿®æ”¹åçš„å†…å®¹å†™å…¥æœ€ç»ˆçš„ç›®æ ‡æ–‡ä»¶
        destination_manim_path.write_text(content, encoding='utf-8')
        
        # ç”Ÿæˆè®²ç¨¿æ–‡ä»¶
        speech_file = speech_dir / "1Introduction_speech.txt"
        template = "ä»Šå¤©æˆ‘ä»¬æ¥è®²è§£ä¸€ä¸‹ä»¥ã€{title}ã€‘ä¸ºä¸»é¢˜çš„å‡ ç¯‡è®ºæ–‡" if is_batch else "ä»Šå¤©æˆ‘ä»¬æ¥è®²è§£ä¸€ä¸‹ã€{title}ã€‘è¿™ç¯‡è®ºæ–‡"
        speech_content = template.format(title=final_title)
        speech_file.write_text(speech_content, encoding='utf-8')
        
        # å¤åˆ¶logoæ–‡ä»¶
        source_logo_path = Path("/home/EduAgent/logo_test.png")
        if source_logo_path.exists():
            try:
                shutil.copy(source_logo_path, code_dir)
                with processing_lock:
                    if process_id in processing_jobs:
                        job = processing_jobs[process_id]
                        job['log_messages'].append({
                            'time': datetime.now().isoformat(), 
                            'message': f'âœ… æˆåŠŸå¤åˆ¶logoæ–‡ä»¶: {source_logo_path} -> {code_dir}'
                        })
            except Exception as e:
                with processing_lock:
                    if process_id in processing_jobs:
                        job = processing_jobs[process_id]
                        job['log_messages'].append({
                            'time': datetime.now().isoformat(), 
                            'message': f'âš ï¸ è­¦å‘Š: å¤åˆ¶logoæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤'
                        })
        else:
            with processing_lock:
                if process_id in processing_jobs:
                    job = processing_jobs[process_id]
                    job['log_messages'].append({
                        'time': datetime.now().isoformat(), 
                        'message': f'âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°æºlogoæ–‡ä»¶: {source_logo_path}'
                    })
        
        # --- æ–°å¢åŠŸèƒ½ï¼šå¤åˆ¶å…¶ä½™çš„pyæ–‡ä»¶å’Œæ‰€æœ‰txtæ–‡ä»¶ ---
        source_cover_dir = Path("/home/EduAgent/cover/")
        # 1. å¤åˆ¶å…¶ä½™çš„pyæ–‡ä»¶ (é™¤äº†1Introduction_code.py)
        # with processing_lock:
        #     job['log_messages'].append({'time': datetime.now().isoformat(), 'message': 'ğŸ“‹ å¼€å§‹å¤åˆ¶å…¶ä½™çš„code.pyæ–‡ä»¶...'})
        # try:
        #     py_files_to_copy = [f for f in source_cover_dir.glob('*.py') if f.name != '1Introduction_code.py']
        #     if not py_files_to_copy:
        #         with processing_lock:
        #             job['log_messages'].append({'time': datetime.now().isoformat(), 'message': '   - âš ï¸ åœ¨æºç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å…¶ä»–éœ€è¦å¤åˆ¶çš„.pyæ–‡ä»¶ã€‚'})
        #     else:
        #         for source_file in py_files_to_copy:
        #             destination_file = code_dir / source_file.name
        #             shutil.copy(source_file, destination_file)
        #             with processing_lock:
        #                 job['log_messages'].append({'time': datetime.now().isoformat(), 'message': f'   - âœ… æˆåŠŸå¤åˆ¶: {source_file.name} -> {destination_file}'})
        # except Exception as e:
        #     with processing_lock:
        #         job['log_messages'].append({'time': datetime.now().isoformat(), 'message': f'   - âŒ å¤åˆ¶å…¶ä½™.pyæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}'})

        # 2. å¤åˆ¶æ‰€æœ‰çš„txtæ–‡ä»¶ (é™¤äº†1Introduction_speech.txt)
        with processing_lock:
            job['log_messages'].append({'time': datetime.now().isoformat(), 'message': 'ğŸ“‹ å¼€å§‹å¤åˆ¶æ‰€æœ‰çš„speech.txtæ–‡ä»¶...'})
        try:
            txt_files_to_copy = [f for f in source_cover_dir.glob('*.txt') if f.name != '1Introduction_speech.txt']
            if not txt_files_to_copy:
                with processing_lock:
                    job['log_messages'].append({'time': datetime.now().isoformat(), 'message': '   - âš ï¸ åœ¨æºç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°éœ€è¦å¤åˆ¶çš„.txtæ–‡ä»¶ã€‚'})
            else:
                for source_file in txt_files_to_copy:
                    destination_file = speech_dir / source_file.name
                    shutil.copy(source_file, destination_file)
                    with processing_lock:
                        job['log_messages'].append({'time': datetime.now().isoformat(), 'message': f'   - âœ… æˆåŠŸå¤åˆ¶: {source_file.name} -> {destination_file}'})
        except Exception as e:
            with processing_lock:
                job['log_messages'].append({'time': datetime.now().isoformat(), 'message': f'   - âŒ å¤åˆ¶.txtæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}'})
        # --- æ–°å¢åŠŸèƒ½ç»“æŸ ---

        # æ›´æ–°çŠ¶æ€
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                job['log_messages'].append({
                    'time': datetime.now().isoformat(), 
                    'message': 'âœ… å°é¢å†…å®¹ç”Ÿæˆå®Œæˆï¼'
                })
        
        return {
            'message': 'å°é¢å†…å®¹ç”ŸæˆæˆåŠŸ',
            'title': final_title,
            'authors': final_authors,
            'affiliations': final_affiliations,
            'is_batch': is_batch,
            'status': 'success'
        }
        
    except Exception as e:
        # å‘ç”Ÿé”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                job['log_messages'].append({
                    'time': datetime.now().isoformat(), 
                    'message': f'âŒ é”™è¯¯: å°é¢ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æ¨¡æ¿'
                })
        
        try:
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿åˆ›å»ºå°é¢
            create_default_cover(code_dir, speech_dir, base_name)
            
            return {
                'message': 'ä½¿ç”¨é»˜è®¤å†…å®¹ç”Ÿæˆå°é¢æˆåŠŸ',
                'status': 'success',
                'error': str(e),
                'note': 'å°é¢ç”Ÿæˆå¤±è´¥ï¼Œå·²ä½¿ç”¨é»˜è®¤æ ‡é¢˜'
            }
        except Exception as e2:
            return {
                'error': f'å°é¢ç”Ÿæˆå¤±è´¥ï¼Œä¸”é»˜è®¤æ¨¡æ¿ä¹Ÿå¤±è´¥: {str(e2)}',
                'original_error': str(e),
                'status': 'failed'
            }
        
def generate_pptcover_content(process_id):
    """ç”Ÿæˆå°é¢å†…å®¹ï¼ˆæ›¿ä»£generate_cover.shè„šæœ¬åŠŸèƒ½ï¼‰"""
    from pathlib import Path
    import shutil
    import re
    import json
    import sys
    
    # å¯¼å…¥cover_generator.pyçš„åŠŸèƒ½
    sys.path.append('/home/EduAgent')
    try:
        # å°è¯•å¯¼å…¥cover_generator.pyä¸­çš„åŠŸèƒ½
        from cover_generator import load_config, get_paper_info_with_llm, fuse_titles_with_llm
        from api_call import APIClient
    except ImportError as e:
        return {
            'error': f'å¯¼å…¥cover_generator.pyå¤±è´¥: {str(e)}',
            'status': 'failed'
        }
    
    with processing_lock:
        if process_id not in processing_jobs:
            return {
                'error': 'å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨',
                'status': 'failed'
            }
        
        job = processing_jobs[process_id]
        pdf_path = job.get('pdf_path')
        base_name = job.get('base_name')
        
        # æ›´æ–°çŠ¶æ€
        job['log_messages'].append({
            'time': datetime.now().isoformat(), 
            'message': 'ğŸ¬ å¼€å§‹æ‰§è¡ŒStep 3.6: ç”Ÿæˆå°é¢å†…å®¹...'
        })
    
    try:
        # è®¾ç½®è·¯å¾„
        source_manim_template_path = Path("/home/EduAgent/pptcover/beginpage.py")
        mineru_output_dir = Path(f"/home/EduAgent/MinerU/outputs_clean/{base_name}")
        p2v_output_dir = Path(f"/home/EduAgent/Paper2Video/{base_name}_output")
        code_dir = p2v_output_dir / "final_results" / "Code"
        
        # æ£€æŸ¥å¿…è¦çš„ç›®å½•å’Œæ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not source_manim_template_path.exists():
            raise FileNotFoundError(f"PPTæ¨¡æ¿æ–‡ä»¶ä¸å­˜åœ¨: {source_manim_template_path}")
        
        if not code_dir.exists():
            raise FileNotFoundError(f"Codeç›®å½•ä¸å­˜åœ¨: {code_dir}")
            
        # æ£€æŸ¥MinerUè¾“å‡ºç›®å½•
        if not mineru_output_dir.exists():
            # å°è¯•åˆ›å»ºæˆ–æŸ¥æ‰¾å…¶ä»–å¯èƒ½çš„ç›®å½•
            alt_mineru_dir = Path(f"/home/EduAgent/MinerU/outputs/{base_name}")
            if alt_mineru_dir.exists():
                mineru_output_dir = alt_mineru_dir
            else:
                # å¦‚æœæ‰¾ä¸åˆ°MinerUè¾“å‡ºï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
                with processing_lock:
                    if process_id in processing_jobs:
                        job = processing_jobs[process_id]
                        job['log_messages'].append({
                            'time': datetime.now().isoformat(), 
                            'message': f'âš ï¸ è­¦å‘Š: MinerUè¾“å‡ºç›®å½•ä¸å­˜åœ¨: {mineru_output_dir}ï¼Œå°†ä½¿ç”¨é»˜è®¤æ ‡é¢˜'
                        })
                
                # ä½¿ç”¨é»˜è®¤æ¨¡æ¿åˆ›å»ºå°é¢
                # create_default_cover(code_dir, speech_dir, base_name)
                
                return {
                    'message': 'ä¸ç”Ÿæˆå°é¢',
                    'status': 'success',
                    'note': 'MinerUè¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œä½¿ç”¨äº†é»˜è®¤æ ‡é¢˜'
                }
        
        # åŠ è½½é…ç½®
        config = load_config()
        api_client = APIClient(api_key=config['api_key'], model=config['model'])
        
        # æŸ¥æ‰¾mdæ–‡ä»¶
        md_files = list(mineru_output_dir.glob('*.md'))
        if not md_files:
            # æ£€æŸ¥å­ç›®å½•
            for subdir in mineru_output_dir.iterdir():
                if subdir.is_dir():
                    md_files.extend(subdir.glob('*.md'))
        
        if not md_files:
            # å¦‚æœæ‰¾ä¸åˆ°mdæ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
            with processing_lock:
                if process_id in processing_jobs:
                    job = processing_jobs[process_id]
                    job['log_messages'].append({
                        'time': datetime.now().isoformat(), 
                        'message': f'âš ï¸ è­¦å‘Š: åœ¨MinerUè¾“å‡ºç›®å½•ä¸­æœªæ‰¾åˆ°ä»»ä½•.mdæ–‡ä»¶: {mineru_output_dir}ï¼Œå°†ä½¿ç”¨é»˜è®¤æ ‡é¢˜'
                    })
            
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿åˆ›å»ºå°é¢
            #create_default_cover(code_dir, speech_dir, base_name)
            
            return {
                'message': 'ä¸ç”Ÿæˆå°é¢',
                'status': 'success',
                'note': 'MinerUè¾“å‡ºç›®å½•ä¸­æœªæ‰¾åˆ°.mdæ–‡ä»¶ï¼Œä½¿ç”¨äº†é»˜è®¤æ ‡é¢˜'
            }
        
        # æå–æ‰€æœ‰è®ºæ–‡ä¿¡æ¯
        all_titles = []
        all_authors = []
        all_affiliations = []
        subprocess.run(['echo', 'aaaaaaaaaaaaaaaaaaa'])
        
        for md_file in md_files:
            info = get_paper_info_with_llm(md_file, api_client)
            if info:
                all_titles.append(info["title"])
                all_authors.append(info["authors"])
                all_affiliations.append(info["affiliations"])
                
        if not all_titles:
            # å¦‚æœæå–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
            with processing_lock:
                if process_id in processing_jobs:
                    job = processing_jobs[process_id]
                    job['log_messages'].append({
                        'time': datetime.now().isoformat(), 
                        'message': 'âš ï¸ è­¦å‘Š: æœªèƒ½ä»MDæ–‡ä»¶ä¸­æå–æ ‡é¢˜ï¼Œå°†ä½¿ç”¨é»˜è®¤æ ‡é¢˜'
                    })
            
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿åˆ›å»ºå°é¢
            # create_default_cover(code_dir, speech_dir, base_name)
            
            return {
                'message': 'ä¸ç”Ÿæˆå°é¢',
                'status': 'success',
                'note': 'ä»MDæ–‡ä»¶æå–æ ‡é¢˜å¤±è´¥ï¼Œä½¿ç”¨äº†é»˜è®¤æ ‡é¢˜'
            }
        
        # æ˜¯å¦ä¸ºæ‰¹é‡æ¨¡å¼
        is_batch = len(all_titles) > 1
        
        # å¤„ç†å•ä½ä¿¡æ¯å»é‡
        unique_affiliations = set()
        for aff_group in all_affiliations:
            if aff_group:  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                # æŒ‰é€—å·åˆ†å‰²ï¼Œå¹¶å»é™¤æ¯ä¸ªå•ä½å‰åçš„ç©ºæ ¼
                affs = [aff.strip() for aff in aff_group.split(',') if aff.strip()]
                unique_affiliations.update(affs)
        
        # å°†å»é‡åçš„å•ä½æ’åºå¹¶åˆå¹¶æˆä¸€ä¸ªå­—ç¬¦ä¸²
        final_affiliations = ", ".join(sorted(list(unique_affiliations))) if unique_affiliations else "æœªçŸ¥å•ä½"
        
        # è®°å½•å•ä½å¤„ç†æ—¥å¿—
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                job['log_messages'].append({
                    'time': datetime.now().isoformat(), 
                    'message': f'ğŸ“‹ å•ä½ä¿¡æ¯å¤„ç†: åŸå§‹{len(all_affiliations)}ä¸ª -> å»é‡å{len(unique_affiliations)}ä¸ª'
                })
        
        # å‡†å¤‡æœ€ç»ˆçš„æ ‡é¢˜å’Œä½œè€…
        if is_batch:
            final_title = fuse_titles_with_llm(all_titles, api_client)
            final_authors = ", ".join(all_authors)
        else:
            final_title = all_titles[0] if all_titles else ""
            final_authors = all_authors[0] if all_authors else ""
        
        # æ›¿æ¢ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢ä»£ç è¯­æ³•é”™è¯¯
        final_title_escaped = final_title.replace('"', '\\"')
        final_authors_escaped = final_authors.replace('"', '\\"')
        final_affiliations_escaped = final_affiliations.replace('"', '\\"')
        
        # åˆ›å»ºå°é¢åœºæ™¯ä»£ç æ–‡ä»¶
        subprocess.run(['echo', 'åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢'])
        destination_manim_path = code_dir / "pptcover_é¡µ0_code.py"
        print("åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢")
        # ä»æºæ¨¡æ¿è¯»å–å†…å®¹
        content = source_manim_template_path.read_text(encoding='utf-8')
        
        # æ›¿æ¢æ ‡é¢˜ã€ä½œè€…å’Œå•ä½
        content = re.sub(r'title_text = ".*"', f'title_text = "{final_title_escaped}"', content)
        content = re.sub(r'author_text = ".*"', f'author_text = "{final_authors_escaped}"', content)
        content = re.sub(r'affiliation_text = ".*"', f'affiliation_text = "{final_affiliations_escaped}"', content)
        
        # å°†ä¿®æ”¹åçš„å†…å®¹å†™å…¥æœ€ç»ˆçš„ç›®æ ‡æ–‡ä»¶
        destination_manim_path.write_text(content, encoding='utf-8')
        print("åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢åˆ›å»ºå°é¢æˆåŠŸæˆåŠŸæˆåŠŸæˆåŠŸ")
        subprocess.run(['echo', 'æˆåŠŸæˆåŠŸæˆåŠŸæˆåŠŸæˆåŠŸæˆåŠŸæˆåŠŸæˆåŠŸ'])
        
        # å¤åˆ¶logoæ–‡ä»¶
        source_logo_path = Path("/home/EduAgent/logo_test.png")
        if source_logo_path.exists():
            try:
                shutil.copy(source_logo_path, code_dir)
                with processing_lock:
                    if process_id in processing_jobs:
                        job = processing_jobs[process_id]
                        job['log_messages'].append({
                            'time': datetime.now().isoformat(), 
                            'message': f'âœ… æˆåŠŸå¤åˆ¶logoæ–‡ä»¶: {source_logo_path} -> {code_dir}'
                        })
            except Exception as e:
                with processing_lock:
                    if process_id in processing_jobs:
                        job = processing_jobs[process_id]
                        job['log_messages'].append({
                            'time': datetime.now().isoformat(), 
                            'message': f'âš ï¸ è­¦å‘Š: å¤åˆ¶logoæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}ï¼Œä½†ä¸å½±å“åç»­æ­¥éª¤'
                        })
        else:
            with processing_lock:
                if process_id in processing_jobs:
                    job = processing_jobs[process_id]
                    job['log_messages'].append({
                        'time': datetime.now().isoformat(), 
                        'message': f'âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°æºlogoæ–‡ä»¶: {source_logo_path}'
                    })
        
        # æ›´æ–°çŠ¶æ€
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                job['log_messages'].append({
                    'time': datetime.now().isoformat(), 
                    'message': 'âœ… å°é¢å†…å®¹ç”Ÿæˆå®Œæˆï¼'
                })
        
        return {
            'message': 'å°é¢å†…å®¹ç”ŸæˆæˆåŠŸ',
            'title': final_title,
            'authors': final_authors,
            'affiliations': final_affiliations,
            'is_batch': is_batch,
            'status': 'success'
        }
        
    except Exception as e:
        # å‘ç”Ÿé”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å†…å®¹
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                job['log_messages'].append({
                    'time': datetime.now().isoformat(), 
                    'message': f'âŒ é”™è¯¯: å°é¢ç”Ÿæˆå¤±è´¥: {str(e)}ï¼Œå°è¯•ä½¿ç”¨é»˜è®¤æ¨¡æ¿'
                })
        
            return {
                'error': f'å°é¢ç”Ÿæˆå¤±è´¥: {str(e)}',
                'original_error': str(e),
                'status': 'failed'
            }

def create_default_cover(code_dir, speech_dir, base_name):
    """åˆ›å»ºé»˜è®¤çš„å°é¢å†…å®¹ï¼ˆå½“æ— æ³•æå–è®ºæ–‡ä¿¡æ¯æ—¶ï¼‰"""
    from pathlib import Path
    import re
    import shutil
    
    # é»˜è®¤æ ‡é¢˜ã€ä½œè€…å’Œå•ä½
    default_title = f"è®ºæ–‡ã€Š{base_name}ã€‹è¯¦è§£"
    default_authors = "æœªçŸ¥ä½œè€…"
    default_affiliations = "æœªçŸ¥å•ä½"
    
    # åˆ›å»ºå°é¢åœºæ™¯ä»£ç æ–‡ä»¶
    source_manim_template_path = Path("/home/EduAgent/cover/1Introduction_code.py")
    destination_manim_path = code_dir / "1Introduction_code.py"
    
    # ä»æºæ¨¡æ¿è¯»å–å†…å®¹
    if source_manim_template_path.exists():
        content = source_manim_template_path.read_text(encoding='utf-8')
        
        # æ›¿æ¢æ ‡é¢˜ã€ä½œè€…å’Œå•ä½
        content = re.sub(r'title_text = ".*"', f'title_text = "{default_title}"', content)
        content = re.sub(r'author_text = ".*"', f'author_text = "{default_authors}"', content)
        content = re.sub(r'affiliation_text = ".*"', f'affiliation_text = "{default_affiliations}"', content)
        
        # å°†ä¿®æ”¹åçš„å†…å®¹å†™å…¥æœ€ç»ˆçš„ç›®æ ‡æ–‡ä»¶
        destination_manim_path.write_text(content, encoding='utf-8')
    
    # ç”Ÿæˆè®²ç¨¿æ–‡ä»¶
    speech_dir.mkdir(parents=True, exist_ok=True)
    speech_file = speech_dir / "1Introduction_speech.txt"
    speech_content = f"ä»Šå¤©æˆ‘ä»¬æ¥è®²è§£ä¸€ä¸‹ã€{default_title}ã€‘è¿™ç¯‡è®ºæ–‡"
    speech_file.write_text(speech_content, encoding='utf-8')
    
    # å¤åˆ¶logoæ–‡ä»¶
    source_logo_path = Path("/home/EduAgent/logo_test.png")
    if source_logo_path.exists():
        try:
            shutil.copy(source_logo_path, code_dir)
            print(f"âœ… æˆåŠŸå¤åˆ¶logoæ–‡ä»¶: {source_logo_path} -> {code_dir}")
        except Exception as e:
            print(f"âš ï¸ å¤åˆ¶logoæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
    else:
        print(f"âš ï¸ æœªæ‰¾åˆ°æºlogoæ–‡ä»¶: {source_logo_path}")

def render_preview_video(process_id, base_name):
    """æ¸²æŸ“é¢„è§ˆè§†é¢‘ï¼Œå®Œæˆåè¿›å…¥ç­‰å¾…äº¤äº’ç¼–è¾‘çŠ¶æ€"""
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, final_video=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if final_video: job['final_video_path'] = final_video
                if stage: job['stage'] = stage
                
                job['last_update'] = datetime.now().isoformat()
    
    try:
        update_job_status(progress=82, step='ğŸ¥ Step 4.5: æ‰§è¡Œé¢„è§ˆè§†é¢‘æ¸²æŸ“',
                         log_msg='ğŸ”„ å¼€å§‹ç”Ÿæˆé¢„è§ˆè§†é¢‘...')
        
        output_dir = f"{base_name}_output"
        
        # æ„å»ºé¢„è§ˆè§†é¢‘æ¸²æŸ“å‘½ä»¤
        cmd = ['bash', 'render_preview.sh', output_dir]
        
        # æ‰§è¡Œé¢„è§ˆæ¸²æŸ“è„šæœ¬
        import os
        env = os.environ.copy()
        env['PYTHONUNBUFFERED'] = '1'
        env['PYTHONIOENCODING'] = 'utf-8'
        
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            universal_newlines=True,
            bufsize=0,
            env=env
        )
        
        current_progress = 82
        
        if process.stdout:
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                
                if line:
                    line = line.strip()
                    print(f"[{process_id}] {line}")
                    
                    # æ ¹æ®è¾“å‡ºæ›´æ–°è¿›åº¦
                    if "Step 4.5" in line:
                        current_progress = min(current_progress + 2, 88)
                        update_job_status(progress=current_progress, log_msg=line)
                    elif "é¢„è§ˆè§†é¢‘" in line:
                        current_progress = min(current_progress + 1, 88)
                        update_job_status(progress=current_progress, log_msg=line)
                    else:
                        update_job_status(log_msg=line)
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        return_code = process.wait()
        
        if return_code == 0:
            # é¢„è§ˆè§†é¢‘æ¸²æŸ“æˆåŠŸï¼Œè¿›å…¥ç­‰å¾…äº¤äº’ç¼–è¾‘çŠ¶æ€
            update_job_status(
                status='waiting_for_edit',
                progress=90,
                step='ğŸ’¬ é¢„è§ˆå®Œæˆ: ç­‰å¾…äº¤äº’ç¼–è¾‘',
                log_msg='ğŸ¬ é¢„è§ˆè§†é¢‘å·²ç”Ÿæˆï¼ç°åœ¨å¯ä»¥æŸ¥çœ‹é¢„è§ˆæ•ˆæœå¹¶è¿›è¡Œäº¤äº’å¼ç¼–è¾‘',
                stage='waiting_for_edit'
            )
        else:
            # é¢„è§ˆè§†é¢‘æ¸²æŸ“å¤±è´¥ï¼Œä½†å¯ä»¥ç»§ç»­ç¼–è¾‘
            update_job_status(
                status='waiting_for_edit',
                progress=90,
                step='âš ï¸ é¢„è§ˆå¤±è´¥ä½†å¯ç»§ç»­ç¼–è¾‘',
                log_msg='âš ï¸ é¢„è§ˆè§†é¢‘æ¸²æŸ“å¤±è´¥ï¼Œä½†æ‚¨ä»å¯ä»¥è¿›è¡Œäº¤äº’å¼ç¼–è¾‘',
                stage='waiting_for_edit'
            )
    
    except Exception as e:
        # é¢„è§ˆå¤±è´¥ï¼Œä½†å¯ä»¥ç»§ç»­ç¼–è¾‘
        update_job_status(
            status='waiting_for_edit',
            progress=90,
            step='âš ï¸ é¢„è§ˆå¼‚å¸¸ä½†å¯ç»§ç»­ç¼–è¾‘',
            log_msg=f'âš ï¸ é¢„è§ˆè§†é¢‘æ¸²æŸ“å¼‚å¸¸: {str(e)}ï¼Œä½†æ‚¨ä»å¯ä»¥è¿›è¡Œäº¤äº’å¼ç¼–è¾‘',
            stage='waiting_for_edit'
        )




def start_preview_and_feedback(process_id):
    """æ£€æŸ¥é¢„è§ˆå’Œç¼–è¾‘çŠ¶æ€ï¼ˆé¢„è§ˆå·²é›†æˆåˆ°åˆå§‹æµç¨‹ä¸­ï¼‰"""
    with processing_lock:
        if process_id not in processing_jobs:
            raise Exception('å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨')
        
        job = processing_jobs[process_id]
        if job['stage'] != 'waiting_for_edit':
            raise Exception(f'å½“å‰é˜¶æ®µä¸æ”¯æŒé¢„è§ˆå’Œåé¦ˆ: {job["stage"]}')
    
    return {
        'process_id': process_id,
        'message': 'é¢„è§ˆè§†é¢‘å·²ç”Ÿæˆï¼Œç°åœ¨å¯ä»¥è¿›è¡Œäº¤äº’å¼ç¼–è¾‘',
        'status': 'waiting_for_edit'
    }




def render_preview_ppt(process_id, base_name):
    """æ¸²æŸ“é¢„è§ˆè§†é¢‘ï¼Œå®Œæˆåè¿›å…¥ç­‰å¾…äº¤äº’ç¼–è¾‘çŠ¶æ€"""
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, final_video=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if final_video: job['final_video_path'] = final_video
                if stage: job['stage'] = stage
                
                job['last_update'] = datetime.now().isoformat()
    
    try:
        update_job_status(progress=82, step='ğŸ¥ Step 4.5: æ‰§è¡Œé¢„è§ˆPPTæ¸²æŸ“',
                         log_msg='ğŸ”„ å¼€å§‹ç”Ÿæˆé¢„è§ˆPPT...')
        
        output_dir = f"{base_name}_output"
        
        # æ„å»ºé¢„è§ˆè§†é¢‘æ¸²æŸ“å‘½ä»¤
        cmd = ['bash', 'render_preview_ppt.sh', output_dir]
        
        # æ‰§è¡Œé¢„è§ˆæ¸²æŸ“è„šæœ¬
        import os
        env = os.environ.copy()
        env['PYTHONUNBUFFERED'] = '1'
        env['PYTHONIOENCODING'] = 'utf-8'
        
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            universal_newlines=True,
            bufsize=0,
            env=env
        )
        
        current_progress = 82
        
        if process.stdout:
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                
                if line:
                    line = line.strip()
                    print(f"[{process_id}] {line}")
                    
                    # æ ¹æ®è¾“å‡ºæ›´æ–°è¿›åº¦
                    if "Step 4.5" in line:
                        current_progress = min(current_progress + 2, 88)
                        update_job_status(progress=current_progress, log_msg=line)
                    elif "é¢„è§ˆPPT" in line:
                        current_progress = min(current_progress + 1, 88)
                        update_job_status(progress=current_progress, log_msg=line)
                    else:
                        update_job_status(log_msg=line)
        
        # ç­‰å¾…è¿›ç¨‹å®Œæˆ
        return_code = process.wait()
        
        if return_code == 0:
            # é¢„è§ˆè§†é¢‘æ¸²æŸ“æˆåŠŸï¼Œè¿›å…¥ç­‰å¾…äº¤äº’ç¼–è¾‘çŠ¶æ€
            update_job_status(
                status='waiting_for_edit',
                progress=90,
                step='ğŸ’¬ é¢„è§ˆå®Œæˆ: ç­‰å¾…äº¤äº’ç¼–è¾‘',
                log_msg='ğŸ¬ é¢„è§ˆPPTå·²ç”Ÿæˆï¼ç°åœ¨å¯ä»¥æŸ¥çœ‹é¢„è§ˆæ•ˆæœå¹¶è¿›è¡Œäº¤äº’å¼ç¼–è¾‘',
                stage='waiting_for_edit'
            )
        else:
            # é¢„è§ˆè§†é¢‘æ¸²æŸ“å¤±è´¥ï¼Œä½†å¯ä»¥ç»§ç»­ç¼–è¾‘
            update_job_status(
                status='waiting_for_edit',
                progress=90,
                step='âš ï¸ é¢„è§ˆå¤±è´¥ä½†å¯ç»§ç»­ç¼–è¾‘',
                log_msg='âš ï¸ é¢„è§ˆPPTæ¸²æŸ“å¤±è´¥ï¼Œä½†æ‚¨ä»å¯ä»¥è¿›è¡Œäº¤äº’å¼ç¼–è¾‘',
                stage='waiting_for_edit'
            )
    
    except Exception as e:
        # é¢„è§ˆå¤±è´¥ï¼Œä½†å¯ä»¥ç»§ç»­ç¼–è¾‘
        update_job_status(
            status='waiting_for_edit',
            progress=90,
            step='âš ï¸ é¢„è§ˆå¼‚å¸¸ä½†å¯ç»§ç»­ç¼–è¾‘',
            log_msg=f'âš ï¸ é¢„è§ˆPPTæ¸²æŸ“å¼‚å¸¸: {str(e)}ï¼Œä½†æ‚¨ä»å¯ä»¥è¿›è¡Œäº¤äº’å¼ç¼–è¾‘',
            stage='waiting_for_edit'
        )

def run_preview_only(process_id, base_name):
    """åªè¿è¡ŒStep 4.5é¢„è§ˆè§†é¢‘æ¸²æŸ“ï¼Œç„¶åè¿›å…¥ç­‰å¾…åé¦ˆç¼–è¾‘çŠ¶æ€"""
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, final_video=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if final_video: job['final_video_path'] = final_video
                if stage: job['stage'] = stage
                
                job['last_update'] = datetime.now().isoformat()
    
    try:
        update_job_status(progress=50, step='ğŸ¥ Step 4.5: å¼€å§‹é¢„è§ˆè§†é¢‘æ¸²æŸ“',
                         log_msg='ğŸ”„ å¼€å§‹ç”Ÿæˆé¢„è§ˆè§†é¢‘...')
        
        output_dir = f"{base_name}_output"
        
        # æ„å»ºé¢„è§ˆè§†é¢‘æ¸²æŸ“å‘½ä»¤
        cmd = ['bash', 'render_preview.sh', output_dir]
        
        # æ‰§è¡Œé¢„è§ˆæ¸²æŸ“è„šæœ¬
        import os
        env = os.environ.copy()
        env['PYTHONUNBUFFERED'] = '1'
        env['PYTHONIOENCODING'] = 'utf-8'
        
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            universal_newlines=True,
            bufsize=0,
            env=env
        )
        
        current_progress = 50
        
        if process.stdout:
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                
                if line:
                    line = line.strip()
                    print(f"[{process_id}] {line}")
                    
                    # æ ¹æ®è¾“å‡ºæ›´æ–°è¿›åº¦
                    if "Step 4.5" in line:
                        current_progress = min(current_progress + 5, 55)
                        update_job_status(progress=current_progress, log_msg=line)
                    elif "é¢„è§ˆè§†é¢‘" in line:
                        current_progress = min(current_progress + 2, 55)
                        update_job_status(progress=current_progress, log_msg=line)
                    else:
                        update_job_status(log_msg=line)
        
        return_code = process.wait()
        
        if return_code == 0:
            # é¢„è§ˆè§†é¢‘æ¸²æŸ“æˆåŠŸï¼Œè¿›å…¥ç­‰å¾…åé¦ˆç¼–è¾‘çŠ¶æ€
            update_job_status(
                status='waiting_feedback',
                progress=55,
                step='ğŸ’¬ ç­‰å¾…åé¦ˆç¼–è¾‘',
                log_msg='ğŸ¬ é¢„è§ˆè§†é¢‘å·²ç”Ÿæˆï¼Œç­‰å¾…åé¦ˆç¼–è¾‘',
                stage='waiting_feedback'
            )
        else:
            # é¢„è§ˆè§†é¢‘æ¸²æŸ“å¤±è´¥
            update_job_status(
                status='failed',
                error=f'é¢„è§ˆè§†é¢‘æ¸²æŸ“å¤±è´¥ï¼Œé€€å‡ºç : {return_code}',
                log_msg='âŒ é¢„è§ˆè§†é¢‘æ¸²æŸ“è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯'
            )
    
    except Exception as e:
        update_job_status(
            status='failed',
            error=str(e),
            log_msg=f'âŒ é¢„è§ˆè§†é¢‘æ¸²æŸ“å¼‚å¸¸: {str(e)}'
        )

def continue_after_feedback(process_id):
    """äº¤äº’ç¼–è¾‘å®Œæˆåç»§ç»­å¤„ç†ï¼ˆStep 6-9ï¼‰"""
    with processing_lock:
        if process_id not in processing_jobs:
            raise Exception('å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨')
        
        job = processing_jobs[process_id]
        if job['stage'] != 'waiting_for_edit':
            raise Exception(f'å½“å‰é˜¶æ®µä¸æ”¯æŒç»§ç»­å¤„ç†: {job["stage"]}')
        
        # æ›´æ–°çŠ¶æ€ä¸ºç»§ç»­å¤„ç†
        job['stage'] = 'final_processing'
        job['status'] = 'running'
        base_name = job['base_name']
    
    # å¯åŠ¨æœ€ç»ˆå¤„ç†çº¿ç¨‹
    processing_thread = threading.Thread(
        target=run_final_processing, 
        args=(process_id, base_name)
    )
    processing_thread.daemon = True
    processing_thread.start()
    
    return {
        'process_id': process_id,
        'message': 'å¼€å§‹æœ€ç»ˆå¤„ç†æ­¥éª¤ï¼ˆè¯­éŸ³åˆæˆå’Œè§†é¢‘æ¸²æŸ“ï¼‰',
        'status': 'running'
    }

def run_final_processing(process_id, base_name):
    """è¿è¡Œæœ€ç»ˆå¤„ç†æµç¨‹ï¼ˆStep 6-9ï¼‰ï¼ŒåŒ…å«åŠ¨æ€éŸ³è‰²é…ç½®"""
    import os # ã€æ–°å¢ã€‘åœ¨å‡½æ•°å¼€å¤´å¯¼å…¥ os æ¨¡å—
    import json # ã€æ–°å¢ã€‘åŒæ—¶å¯¼å…¥ json æ¨¡å—ï¼Œä»¥é˜²ä¸‡ä¸€
    
    # å†…éƒ¨çš„ update_job_status è¾…åŠ©å‡½æ•°ä¿æŒä¸å˜
    """è¿è¡Œæœ€ç»ˆå¤„ç†æµç¨‹ï¼ˆStep 6-9ï¼‰"""
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, output_dir=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if output_dir: job['output_dir'] = output_dir
                if stage: job['stage'] = stage
                job['last_update'] = datetime.now().isoformat()
    
    try:
        update_job_status(progress=10, step='ğŸµ Step 6: å¼€å§‹æœ€ç»ˆå¤„ç†',
                         log_msg='ğŸ”„ å¼€å§‹æ‰§è¡ŒStep 6-9: è¯­éŸ³åˆæˆå’Œè§†é¢‘æ¸²æŸ“...')
        
        output_dir = f"{base_name}_output"
        # ã€æ–°å¢ã€‘åœ¨è°ƒç”¨è„šæœ¬å‰ï¼Œåˆ›å»ºåŒ…å« job é…ç½®çš„ JSON æ–‡ä»¶
        # with processing_lock:
        #     job = processing_jobs[process_id]
        #     config_to_pass = {
        #         "voice_type": job.get("voice_type"),
        #         "custom_voice_path": job.get("custom_voice_path"),
        #         "custom_voice_text": job.get("custom_voice_text"),
        #     }
        
        #         # æ‰“å°è°ƒè¯•ä¿¡æ¯ï¼Œç¡®è®¤é…ç½®æ˜¯å¦æ­£ç¡®
        # print(f"--- [SERVICE DEBUG] run_final_processing ---")
        # print(f"  ä¸º {process_id} åˆ›å»º job_config.json")
        # print(f"  å†…å®¹: {config_to_pass}")
        # print(f"--------------------------------------------")

        
        # temp_dir = f'Paper2Video/{base_name}_output/temp'
        # os.makedirs(temp_dir, exist_ok=True)
        # config_path = os.path.join(temp_dir, 'job_config.json')
        # with open(config_path, 'w', encoding='utf-8') as f:
        #     json.dump(config_to_pass, f)

        # ã€ä¿®æ”¹ã€‘ä½¿ç”¨ç»å¯¹è·¯å¾„
        # ==================== ã€æ ¸å¿ƒä¿®å¤é€»è¾‘ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„ã€‘ ====================
        with processing_lock:
            job = processing_jobs[process_id]
            # è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„
            # os.path.abspath(os.path.dirname(__file__)) ä¼šå¾—åˆ° services.py æ‰€åœ¨çš„ç›®å½•
            project_root = os.path.abspath(os.path.dirname(__file__))

            # å¦‚æœ job ä¸­ä¿å­˜çš„ custom_voice_path æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œä¹Ÿè½¬æ¢ä¸ºç»å¯¹è·¯å¾„
            custom_voice_path_rel = job.get("custom_voice_path")
            custom_voice_path_abs = None
            if custom_voice_path_rel:
                custom_voice_path_abs = os.path.join(project_root, custom_voice_path_rel)

            config_to_pass = {
                "voice_type": job.get("voice_type"),
                # ã€ä¿®æ”¹ã€‘ä¼ é€’ç»å¯¹è·¯å¾„ç»™é…ç½®æ–‡ä»¶
                "custom_voice_path": custom_voice_path_abs, 
                "custom_voice_text": job.get("custom_voice_text"),
            }
        
        print(f"--- [SERVICE DEBUG] run_final_processing ---")
        print(f"  å†…å®¹ (ä½¿ç”¨ç»å¯¹è·¯å¾„): {config_to_pass}")
        print(f"--------------------------------------------")
        
        # ä½¿ç”¨ç»å¯¹è·¯å¾„åˆ›å»ºä¸´æ—¶ç›®å½•å’Œé…ç½®æ–‡ä»¶
        temp_dir_abs = os.path.join(project_root, f'Paper2Video/{base_name}_output/temp')
        os.makedirs(temp_dir_abs, exist_ok=True)
        config_path_abs = os.path.join(temp_dir_abs, 'job_config.json')
        
        # ã€ä¿®æ”¹ã€‘å°†é…ç½®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ä¹Ÿä¿å­˜åˆ° job_info ä¸­ï¼Œä¾› shell è„šæœ¬ä½¿ç”¨
        with processing_lock:
            processing_jobs[process_id]['job_config_path'] = config_path_abs

        with open(config_path_abs, 'w', encoding='utf-8') as f:
            json.dump(config_to_pass, f, ensure_ascii=False) # å¢åŠ  ensure_ascii=False
        # =================================================================


        # # åˆ›å»ºä¸€ä¸ªä¸“é—¨ç”¨äºæœ€ç»ˆå¤„ç†çš„è„šæœ¬è°ƒç”¨
        # cmd = ['bash', 'final_pipeline.sh', output_dir]
        # ã€ä¿®æ”¹ã€‘å°†é…ç½®æ–‡ä»¶çš„ç»å¯¹è·¯å¾„ä½œä¸ºå‚æ•°ä¼ é€’ç»™ shell è„šæœ¬
        cmd = ['bash', 'final_pipeline.sh', output_dir, config_path_abs]

        # æ‰§è¡Œå¤„ç†è„šæœ¬
        import os
        env = os.environ.copy()
        env['PYTHONUNBUFFERED'] = '1'
        env['PYTHONIOENCODING'] = 'utf-8'
        
        process = subprocess.Popen(
            cmd, 
            stdout=subprocess.PIPE, 
            stderr=subprocess.STDOUT, 
            universal_newlines=True,
            bufsize=0,
            env=env
        )
        
        current_progress = 10
        
        if process.stdout:
            while True:
                line = process.stdout.readline()
                if not line and process.poll() is not None:
                    break
                
                if line:
                    line = line.rstrip()
                    if line:
                        update_job_status(log_msg=line)
                        
                        # æ ¹æ®è¾“å‡ºæ›´æ–°è¿›åº¦
                        if 'Step 6' in line:
                            current_progress = max(current_progress, 30)
                            update_job_status(progress=current_progress, step='ğŸµ Step 6: è¯­éŸ³åˆæˆ')
                        elif 'Step 7' in line:
                            current_progress = max(current_progress, 50)
                            update_job_status(progress=current_progress, step='ğŸ”„ Step 7: éŸ³è§†é¢‘å¯¹é½')
                        elif 'Step 8' in line:
                            current_progress = max(current_progress, 70)
                            update_job_status(progress=current_progress, step='ğŸ¬ Step 8: è§†é¢‘æ¸²æŸ“')
                        elif 'Step 9' in line:
                            current_progress = max(current_progress, 90)
                            update_job_status(progress=current_progress, step='ğŸ¦ Step 9: è§†é¢‘éŸ³é¢‘åˆå¹¶')
                        elif 'å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæ¯•' in line or 'æ•™å­¦è§†é¢‘å·²ç”Ÿæˆ' in line:
                            current_progress = 100
                            update_job_status(progress=current_progress, step='âœ… å®Œæˆ: å¤„ç†æµç¨‹ç»“æŸ')
        
        process.wait()
        
        if process.returncode == 0:
            # æŸ¥æ‰¾æœ€ç»ˆè§†é¢‘
            final_video = f"Paper2Video/{base_name}_output/final_results/Video_with_voice/Full.mp4"
            
            update_job_status(
                status='completed', 
                progress=100, 
                step='âœ… å¤„ç†å®Œæˆ', 
                log_msg='ğŸ‰ å®Œæ•´çš„è®ºæ–‡å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆï¼',
                final_video=final_video if os.path.exists(final_video) else None,
                stage='completed'
            )
        else:
            update_job_status(
                status='failed', 
                step='âŒ æœ€ç»ˆå¤„ç†å¤±è´¥', 
                error=f'å¤„ç†è„šæœ¬é€€å‡ºç : {process.returncode}',
                log_msg='æœ€ç»ˆå¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯'
            )
    
    # ...
    except Exception as e:
        # ã€æ–°å¢ã€‘å¯¼å…¥ traceback æ¨¡å—ä»¥è·å–è¯¦ç»†çš„é”™è¯¯å †æ ˆ
        import traceback
        
        # ã€ä¿®æ”¹ã€‘æ‰“å°æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯åˆ°åç«¯ç»ˆç«¯
        print(f"!!!!!!!!!!!!!! [FATAL ERROR] in run_final_processing !!!!!!!!!!!!!!")
        print(f"  Process ID: {process_id}")
        print(f"  Exception Type: {type(e).__name__}")
        print(f"  Exception Message: {e}")
        print(f"  Traceback:")
        # æ‰“å°å®Œæ•´çš„é”™è¯¯å †æ ˆï¼Œè¿™ä¼šå‘Šè¯‰æˆ‘ä»¬æ˜¯å“ªä¸€è¡Œä»£ç å‡ºçš„é”™
        traceback.print_exc()
        print(f"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!")

        # å°†è¯¦ç»†é”™è¯¯ä¿¡æ¯ä¹Ÿæ›´æ–°åˆ° job çŠ¶æ€ä¸­ï¼Œæ–¹ä¾¿å‰ç«¯æŸ¥çœ‹
        error_details = traceback.format_exc()
        update_job_status(
            status='failed', 
            step='âŒ æœ€ç»ˆå¤„ç†å¼‚å¸¸', 
            error=str(e),
            log_msg=f'æœ€ç»ˆå¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿä¸¥é‡å¼‚å¸¸: {error_details}'
        )

def get_processing_status(process_id):
    """è·å–å¤„ç†çŠ¶æ€"""
    with processing_lock:
        if process_id not in processing_jobs:
            return {'error': 'å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨'}
        
        job = processing_jobs[process_id].copy()
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"[DEBUG] è·å–å¤„ç†çŠ¶æ€ - Process ID: {process_id}")
        print(f"[DEBUG] çŠ¶æ€: {job['status']}, è¿›åº¦: {job['progress']}")
        print(f"[DEBUG] å½“å‰æ­¥éª¤: {job['current_step']}")
        print(f"[DEBUG] å¤„ç†é˜¶æ®µ: {job.get('stage', 'unknown')}")
        print(f"[DEBUG] æ—¥å¿—æ¶ˆæ¯æ•°é‡: {len(job['log_messages'])}")
        
        result = {
            'process_id': process_id,
            'status': job['status'],
            'progress': job['progress'],
            'current_step': job['current_step'],
            'start_time': job['start_time'],
            # 'pdf_filename': job['pdf_filename'],
            # ã€æ ¸å¿ƒä¿®æ­£ã€‘
            # ä½¿ç”¨ .get() æ–¹æ³•å®‰å…¨åœ°è·å–å€¼ã€‚
            # å¦‚æœ 'pdf_filename' ä¸å­˜åœ¨ï¼Œå®ƒä¼šå°è¯•è·å– 'folder_name'ã€‚
            # å¦‚æœä¸¤è€…éƒ½ä¸å­˜åœ¨ï¼Œåˆ™è¿”å› 'æœªçŸ¥ä»»åŠ¡'ã€‚
            'pdf_filename': job.get('pdf_filename', job.get('folder_name', 'æœªçŸ¥ä»»åŠ¡')),

            'output_dir': job['output_dir'],
            'final_video_path': job['final_video_path'],
            'error': job['error'],
            'stage': job.get('stage', 'unknown'),  # æ–°å¢stageå­—æ®µ
            'recent_logs': job['log_messages'][-30:] if job['log_messages'] else []  # æœ€è¿‘30æ¡æ—¥å¿—
        }
        # åˆ«å¿˜äº†åœ¨æœ€å¤–å±‚ä¹ŸåŠ ä¸Š success æ ‡å¿—
        result['success'] = True
        print(f"[DEBUG] è¿”å›çš„recent_logsæ•°é‡: {len(result['recent_logs'])}")
        return result

def get_processing_results():
    """è·å–æ‰€æœ‰å¤„ç†ç»“æœåˆ—è¡¨"""
    with processing_lock:
        results = []
        for process_id, job in processing_jobs.items():
            if job['status'] in ['completed', 'failed']:
                result_info = {
                    'process_id': process_id,
                    'pdf_filename': job['pdf_filename'],
                    'status': job['status'],
                    'start_time': job['start_time'],
                    'output_dir': job['output_dir'],
                    'final_video_path': job['final_video_path'],
                    'error': job['error']
                }
                results.append(result_info)
        
        return {'results': results}

def get_result_download_path(result_id):
    """è·å–ç»“æœä¸‹è½½è·¯å¾„"""
    with processing_lock:
        if result_id not in processing_jobs:
            print(f"[DEBUG] ä¸‹è½½å¤±è´¥ï¼šprocessing_jobsä¸­æ‰¾ä¸åˆ°result_id: {result_id}")
            return None
        
        job = processing_jobs[result_id]
        if job['status'] != 'completed':
            print(f"[DEBUG] ä¸‹è½½å¤±è´¥ï¼šä»»åŠ¡çŠ¶æ€ä¸æ˜¯completed: {job['status']}")
            return None
        
        # ã€ä¿®æ”¹ç‚¹ã€‘ä¼˜å…ˆä½¿ç”¨æˆ‘ä»¬æ–°æ·»åŠ çš„ã€é€šç”¨çš„ final_output_path å­—æ®µ
        # è¿™ä¸ªå­—æ®µæ—¢å¯ä»¥å­˜è§†é¢‘è·¯å¾„ï¼Œä¹Ÿå¯ä»¥å­˜æ–‡æ¡£çš„.zipè·¯å¾„
        file_path = job.get('final_output_path')
        print(f"[DEBUG] æ£€æŸ¥final_output_path: {file_path}")
        
        if file_path and os.path.exists(file_path):
            print(f"[DEBUG] æ‰¾åˆ°æ–‡ä»¶: {file_path}")
            return file_path
        elif file_path:
            print(f"[DEBUG] final_output_pathå­˜åœ¨ä½†æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        
        # ã€ä¸ºäº†å…¼å®¹æ—§æ•°æ®ã€‘å¦‚æœä¸Šé¢çš„æ–°å­—æ®µæ‰¾ä¸åˆ°ï¼Œå†å°è¯•æ£€æŸ¥æ—§çš„ final_video_path
        # è¿™å¯ä»¥ä¿è¯æ‚¨ä¹‹å‰åªç”Ÿæˆäº†è§†é¢‘çš„ä»»åŠ¡ä¹Ÿèƒ½æ­£å¸¸ä¸‹è½½
        file_path_legacy = job.get('final_video_path')
        print(f"[DEBUG] æ£€æŸ¥final_video_path: {file_path_legacy}")
        
        if file_path_legacy and os.path.exists(file_path_legacy):
            print(f"[DEBUG] æ‰¾åˆ°å…¼å®¹æ–‡ä»¶: {file_path_legacy}")
            return file_path_legacy
        elif file_path_legacy:
            print(f"[DEBUG] final_video_pathå­˜åœ¨ä½†æ–‡ä»¶ä¸å­˜åœ¨: {file_path_legacy}")
        
        print(f"[DEBUG] æ‰€æœ‰è·¯å¾„éƒ½ä¸å¯ç”¨")
        return None 

def run_folder_markdown_generation(process_id, base_name):
    """è¿è¡ŒMarkdownæ–‡æ¡£ç”Ÿæˆå’Œæ‰“åŒ…æµç¨‹"""
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, final_output=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if final_output: job['final_output_path'] = final_output
                if stage: job['stage'] = stage
                job['last_update'] = datetime.now().isoformat()

    try:
        update_job_status(progress=75, step='ğŸ“ Step 4.1: å‡†å¤‡æ–‡æ¡£ç”Ÿæˆ', log_msg='ğŸš€ å¼€å§‹æ‰§è¡Œæ–‡æ¡£ç”Ÿæˆè„šæœ¬...')
        
        output_base_dir = f"Paper2Video/{base_name}_output"
        input_sections_dir = os.path.join(output_base_dir, 'sections')
        output_md_dir_name = f"{base_name}_markdown"
        output_md_path = os.path.join(output_base_dir, output_md_dir_name)

        # ------------------- ã€æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šåŠ¨æ€æŸ¥æ‰¾å›¾ç‰‡è·¯å¾„ã€‘ -------------------
        update_job_status(log_msg=f'ğŸ” æ­£åœ¨æœç´¢å›¾ç‰‡æ–‡ä»¶å¤¹äº: {output_base_dir}')
        
        # ä½¿ç”¨ glob é€’å½’æœç´¢åä¸º 'images' çš„æ–‡ä»¶å¤¹
        # `**` è¡¨ç¤ºåŒ¹é…ä»»æ„å±‚çº§çš„å­ç›®å½•
        # search_pattern = os.path.join(output_base_dir, '**', 'images')
        # found_images_dirs = glob.glob(search_pattern, recursive=True)

        # ä½¿ç”¨ glob é€’å½’æœç´¢åä¸º 'images' çš„æ–‡ä»¶å¤¹
        # `**` è¡¨ç¤ºåŒ¹é…ä»»æ„å±‚çº§çš„å­ç›®å½•
        search_pattern_images = os.path.join(output_base_dir, '**', 'images')  # âœ… ä¿®æ”¹
        search_pattern_combined = os.path.join(output_base_dir, '**', 'combined_images')  # âœ… æ–°å¢

        found_images_dirs = glob.glob(search_pattern_images, recursive=True)
        found_combined_dirs = glob.glob(search_pattern_combined, recursive=True)  # âœ… æ–°å¢

        all_candidate_dirs = found_combined_dirs + found_images_dirs  # âœ… ä¼˜å…ˆä½¿ç”¨ combined_images

        images_dir = None
        # if found_images_dirs:
        if all_candidate_dirs:  # âœ… ä¿®æ”¹åŸæ¥çš„ found_images_dirs ä¸º all_candidate_dirs
            # é€šå¸¸æˆ‘ä»¬æœŸæœ›åªæ‰¾åˆ°ä¸€ä¸ªã€‚å¦‚æœæ‰¾åˆ°å¤šä¸ªï¼Œé»˜è®¤å–ç¬¬ä¸€ä¸ªã€‚
            # images_dir = found_images_dirs[0]
            images_dir = all_candidate_dirs[0]
            update_job_status(log_msg=f'âœ… æˆåŠŸæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶å¤¹: {images_dir}')
        else:
            # ã€å¤‡ç”¨æ–¹æ¡ˆã€‘å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œè®©è„šæœ¬å¯ä»¥ç»§ç»­æ‰§è¡Œ
            # è¿™å¯¹åº”äº†æ‚¨æä¾›çš„æ­£å¸¸è¾“å‡ºä¸­çš„ "[è­¦å‘Š] åœ¨å›¾ç‰‡ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾ç‰‡" çš„æƒ…å†µ
            update_job_status(log_msg='âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œå°†åˆ›å»ºä¸€ä¸ªç©ºç›®å½•ä»¥ç»§ç»­æµç¨‹ã€‚')
            images_dir = os.path.join(output_base_dir, 'temp_empty_images')
            os.makedirs(images_dir, exist_ok=True)
        # ------------------- å›¾ç‰‡è·¯å¾„æŸ¥æ‰¾ç»“æŸ -------------------
        
        os.makedirs(output_md_path, exist_ok=True)

        cmd = [
            'python3',
            '/home/EduAgent/Paper2Video/create_speech_package_multipaper.py',
            input_sections_dir,
            images_dir,# <--- ã€ä¿®æ”¹ã€‘ä½¿ç”¨æˆ‘ä»¬åŠ¨æ€æ‰¾åˆ°çš„æ­£ç¡®è·¯å¾„
            output_md_path
        ]

        update_job_status(log_msg=f'âš™ï¸ æ‰§è¡Œå‘½ä»¤: {" ".join(cmd)}') # å¢åŠ æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•

        # ... (å‡½æ•°ä½™ä¸‹çš„ subprocess.Popen å’Œæ‰“åŒ…é€»è¾‘ä¿æŒä¸å˜)
        process = subprocess.Popen(
            cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, 
            universal_newlines=True, bufsize=1, encoding='utf-8'
        )

        if process.stdout:
            for line in process.stdout:
                update_job_status(log_msg=line.strip())
        
        process.wait()

        if process.returncode == 0:
            update_job_status(progress=90, step='ğŸ“¦ Step 4.2: æ‰“åŒ…æ–‡æ¡£æ–‡ä»¶', log_msg='âœ… æ–‡æ¡£ç”ŸæˆæˆåŠŸï¼Œå¼€å§‹å‹ç¼©æ–‡ä»¶...')

            # æ‰“åŒ…æˆZIPæ–‡ä»¶
            zip_filename = f"{output_md_dir_name}.zip"
            zip_filepath = os.path.join(output_base_dir, zip_filename)

            with zipfile.ZipFile(zip_filepath, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, _, files in os.walk(output_md_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        # åˆ›å»ºåœ¨zipæ–‡ä»¶ä¸­çš„ç›¸å¯¹è·¯å¾„
                        archive_name = os.path.relpath(file_path, output_md_path)
                        zipf.write(file_path, archive_name)
            
            update_job_status(log_msg=f'ğŸ“¦ æˆåŠŸåˆ›å»ºå‹ç¼©åŒ…: {zip_filepath}')

            update_job_status(
                status='completed',
                progress=100,
                step='âœ… æ–‡æ¡£å·²ç”Ÿæˆ',
                log_msg='ğŸ‰ Markdownæ–‡æ¡£å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆï¼',
                final_output=zip_filepath,
                stage='completed'
            )
        else:
            raise Exception(f"æ–‡æ¡£ç”Ÿæˆè„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {process.returncode}")

    except Exception as e:
        update_job_status(
            status='failed',
            step='âŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥',
            error=str(e),
            log_msg=f'å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}',
            stage='completed'
        )


def run_markdown_generation(process_id, base_name):
    """è¿è¡ŒMarkdownæ–‡æ¡£ç”Ÿæˆå’Œæ‰“åŒ…æµç¨‹"""
    def update_job_status(status=None, progress=None, step=None, log_msg=None, error=None, final_output=None, stage=None):
        with processing_lock:
            if process_id in processing_jobs:
                job = processing_jobs[process_id]
                if status: job['status'] = status
                if progress is not None: job['progress'] = progress
                if step: job['current_step'] = step
                if log_msg: job['log_messages'].append({'time': datetime.now().isoformat(), 'message': log_msg})
                if error: job['error'] = error
                if final_output: job['final_output_path'] = final_output
                if stage: job['stage'] = stage
                job['last_update'] = datetime.now().isoformat()

    try:
        update_job_status(progress=75, step='ğŸ“ Step 4.1: å‡†å¤‡æ–‡æ¡£ç”Ÿæˆ', log_msg='ğŸš€ å¼€å§‹æ‰§è¡Œæ–‡æ¡£ç”Ÿæˆè„šæœ¬...')
        
        output_base_dir = f"Paper2Video/{base_name}_output"
        input_sections_dir = os.path.join(output_base_dir, 'sections')
        output_md_dir_name = f"{base_name}_markdown"
        output_md_path = os.path.join(output_base_dir, output_md_dir_name)

        # ------------------- ã€æ ¸å¿ƒä¿®æ”¹ç‚¹ï¼šåŠ¨æ€æŸ¥æ‰¾å›¾ç‰‡è·¯å¾„ã€‘ -------------------
        update_job_status(log_msg=f'ğŸ” æ­£åœ¨æœç´¢å›¾ç‰‡æ–‡ä»¶å¤¹äº: {output_base_dir}')
        
        # ä½¿ç”¨ glob é€’å½’æœç´¢åä¸º 'images' çš„æ–‡ä»¶å¤¹
        # `**` è¡¨ç¤ºåŒ¹é…ä»»æ„å±‚çº§çš„å­ç›®å½•
        # search_pattern = os.path.join(output_base_dir, '**', 'images')
        # found_images_dirs = glob.glob(search_pattern, recursive=True)

        # ä½¿ç”¨ glob é€’å½’æœç´¢åä¸º 'images' çš„æ–‡ä»¶å¤¹
        # `**` è¡¨ç¤ºåŒ¹é…ä»»æ„å±‚çº§çš„å­ç›®å½•
        search_pattern_images = os.path.join(output_base_dir, '**', 'images')  # âœ… ä¿®æ”¹
        search_pattern_combined = os.path.join(output_base_dir, '**', 'combined_images')  # âœ… æ–°å¢

        found_images_dirs = glob.glob(search_pattern_images, recursive=True)
        found_combined_dirs = glob.glob(search_pattern_combined, recursive=True)  # âœ… æ–°å¢

        all_candidate_dirs = found_combined_dirs + found_images_dirs  # âœ… ä¼˜å…ˆä½¿ç”¨ combined_images

        images_dir = None
        # if found_images_dirs:
        if all_candidate_dirs:  # âœ… ä¿®æ”¹åŸæ¥çš„ found_images_dirs ä¸º all_candidate_dirs
            # é€šå¸¸æˆ‘ä»¬æœŸæœ›åªæ‰¾åˆ°ä¸€ä¸ªã€‚å¦‚æœæ‰¾åˆ°å¤šä¸ªï¼Œé»˜è®¤å–ç¬¬ä¸€ä¸ªã€‚
            # images_dir = found_images_dirs[0]
            images_dir = all_candidate_dirs[0]
            update_job_status(log_msg=f'âœ… æˆåŠŸæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶å¤¹: {images_dir}')
        else:
            # ã€å¤‡ç”¨æ–¹æ¡ˆã€‘å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ›å»ºä¸€ä¸ªç©ºçš„ä¸´æ—¶å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œè®©è„šæœ¬å¯ä»¥ç»§ç»­æ‰§è¡Œ
            # è¿™å¯¹åº”äº†æ‚¨æä¾›çš„æ­£å¸¸è¾“å‡ºä¸­çš„ "[è­¦å‘Š] åœ¨å›¾ç‰‡ç›®å½•ä¸­æœªæ‰¾åˆ°å›¾ç‰‡" çš„æƒ…å†µ
            update_job_status(log_msg='âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶å¤¹ï¼Œå°†åˆ›å»ºä¸€ä¸ªç©ºç›®å½•ä»¥ç»§ç»­æµç¨‹ã€‚')
            images_dir = os.path.join(output_base_dir, 'temp_empty_images')
            os.makedirs(images_dir, exist_ok=True)
        # ------------------- å›¾ç‰‡è·¯å¾„æŸ¥æ‰¾ç»“æŸ -------------------
        
        os.makedirs(output_md_path, exist_ok=True)

        cmd = [
            'python3',
            '/home/EduAgent/Paper2Video/create_speech_package.py',
            input_sections_dir,
            images_dir,# <--- ã€ä¿®æ”¹ã€‘ä½¿ç”¨æˆ‘ä»¬åŠ¨æ€æ‰¾åˆ°çš„æ­£ç¡®è·¯å¾„
            output_md_path
        ]

        update_job_status(log_msg=f'âš™ï¸ æ‰§è¡Œå‘½ä»¤: {" ".join(cmd)}') # å¢åŠ æ—¥å¿—ï¼Œæ–¹ä¾¿è°ƒè¯•

        # ... (å‡½æ•°ä½™ä¸‹çš„ subprocess.Popen å’Œæ‰“åŒ…é€»è¾‘ä¿æŒä¸å˜)
        process = subprocess.Popen(
            cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, 
            universal_newlines=True, bufsize=1, encoding='utf-8'
        )

        if process.stdout:
            for line in process.stdout:
                update_job_status(log_msg=line.strip())
        
        process.wait()

        if process.returncode == 0:
            update_job_status(progress=90, step='ğŸ“¦ Step 4.2: æ‰“åŒ…æ–‡æ¡£æ–‡ä»¶', log_msg='âœ… æ–‡æ¡£ç”ŸæˆæˆåŠŸï¼Œå¼€å§‹å‹ç¼©æ–‡ä»¶...')

            # æ‰“åŒ…æˆZIPæ–‡ä»¶
            zip_filename = f"{output_md_dir_name}.zip"
            zip_filepath = os.path.join(output_base_dir, zip_filename)

            with zipfile.ZipFile(zip_filepath, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for root, _, files in os.walk(output_md_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        # åˆ›å»ºåœ¨zipæ–‡ä»¶ä¸­çš„ç›¸å¯¹è·¯å¾„
                        archive_name = os.path.relpath(file_path, output_md_path)
                        zipf.write(file_path, archive_name)
            
            update_job_status(log_msg=f'ğŸ“¦ æˆåŠŸåˆ›å»ºå‹ç¼©åŒ…: {zip_filepath}')

            update_job_status(
                status='completed',
                progress=100,
                step='âœ… æ–‡æ¡£å·²ç”Ÿæˆ',
                log_msg='ğŸ‰ Markdownæ–‡æ¡£å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆï¼',
                final_output=zip_filepath,
                stage='completed'
            )
        else:
            raise Exception(f"æ–‡æ¡£ç”Ÿæˆè„šæœ¬æ‰§è¡Œå¤±è´¥ï¼Œé€€å‡ºç : {process.returncode}")

    except Exception as e:
        update_job_status(
            status='failed',
            step='âŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥',
            error=str(e),
            log_msg=f'å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {str(e)}',
            stage='completed'
        )

# ========================= Webç‰ˆäº¤äº’ç¼–è¾‘å™¨åŠŸèƒ½ =========================

def get_editor_files(process_id):
    """è·å–æŒ‡å®šå¤„ç†ä»»åŠ¡çš„å¯ç¼–è¾‘æ–‡ä»¶åˆ—è¡¨"""
    with processing_lock:
        if process_id not in processing_jobs:
            raise Exception('å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨')
        
        job = processing_jobs[process_id]
        if not job['output_dir']:
            raise Exception('å¤„ç†ä»»åŠ¡å°šæœªç”Ÿæˆè¾“å‡ºç›®å½•')
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    code_dir = os.path.join(job['output_dir'], 'final_results', 'Code')
    speech_dir = os.path.join(job['output_dir'], 'final_results', 'Speech')
    video_preview_dir = os.path.join(job['output_dir'], 'final_results', 'Video_Preview')
    
    all_files = []
    
    # æ”¶é›†Codeæ–‡ä»¶
    if os.path.exists(code_dir):
        for file in os.listdir(code_dir):
            if file.endswith('.py'):
                file_path = os.path.join(code_dir, file)
                all_files.append({
                    'type': 'Code',
                    'filename': file,
                    'path': file_path,
                    'relative_path': os.path.join('Code', file),
                    'size': os.path.getsize(file_path)
                })
    
    # æ”¶é›†Speechæ–‡ä»¶
    if os.path.exists(speech_dir):
        for file in os.listdir(speech_dir):
            if file.endswith('.txt'):
                file_path = os.path.join(speech_dir, file)
                all_files.append({
                    'type': 'Speech',
                    'filename': file,
                    'path': file_path,
                    'relative_path': os.path.join('Speech', file),
                    'size': os.path.getsize(file_path)
                })
    
    # æ”¶é›†Video Previewè§†é¢‘æ–‡ä»¶
    page_videos = []
    if os.path.exists(video_preview_dir):
        for file in os.listdir(video_preview_dir):
            if file.endswith('.mp4'):
                file_path = os.path.join(video_preview_dir, file)
                page_videos.append({
                    'type': 'VideoPreview',
                    'filename': file,
                    'path': file_path,
                    'relative_path': os.path.join('Video_Preview', file),
                    'size': os.path.getsize(file_path)
                })
    
    # æŒ‰æ–‡ä»¶åæ’åº
    all_files.sort(key=lambda x: x['filename'])
    page_videos.sort(key=lambda x: x['filename'])
    
    return {
        'files': all_files,
        'page_videos': page_videos,
        'code_dir': code_dir,
        'speech_dir': speech_dir,
        'video_preview_dir': video_preview_dir,
        'total_count': len(all_files),
        'video_count': len(page_videos)
    }

def get_file_content(file_path):
    """è·å–æ–‡ä»¶å†…å®¹"""
    # å®‰å…¨æ£€æŸ¥
    if not os.path.exists(file_path):
        raise Exception('æ–‡ä»¶ä¸å­˜åœ¨')
    
    if '..' in file_path or not (file_path.endswith('.py') or file_path.endswith('.txt')):
        raise Exception('ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹æˆ–è·¯å¾„ä¸å®‰å…¨')
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è·å–æ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
        lines = content.split('\n')
        
        return {
            'content': content,
            'filename': os.path.basename(file_path),
            'file_path': file_path,
            'line_count': len(lines),
            'size': len(content.encode('utf-8'))
        }
    
    except Exception as e:
        raise Exception(f'è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}')

def save_file_content(file_path, content):
    """ä¿å­˜æ–‡ä»¶å†…å®¹"""
    # å®‰å…¨æ£€æŸ¥
    if '..' in file_path or not (file_path.endswith('.py') or file_path.endswith('.txt')):
        raise Exception('ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹æˆ–è·¯å¾„ä¸å®‰å…¨')
    
    if not os.path.exists(os.path.dirname(file_path)):
        raise Exception('ç›®æ ‡ç›®å½•ä¸å­˜åœ¨')
    
    try:
        # å¤‡ä»½åŸæ–‡ä»¶
        backup_path = file_path + '.backup'
        if os.path.exists(file_path):
            import shutil
            shutil.copy2(file_path, backup_path)
        
        # ä¿å­˜æ–°å†…å®¹
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # éªŒè¯ä¿å­˜ç»“æœ
        with open(file_path, 'r', encoding='utf-8') as f:
            saved_content = f.read()
        
        if saved_content != content:
            # å¦‚æœä¿å­˜å¤±è´¥ï¼Œæ¢å¤å¤‡ä»½
            if os.path.exists(backup_path):
                shutil.copy2(backup_path, file_path)
            raise Exception('æ–‡ä»¶ä¿å­˜éªŒè¯å¤±è´¥')
        
        # æ¸…ç†å¤‡ä»½æ–‡ä»¶
        if os.path.exists(backup_path):
            os.remove(backup_path)
        
        return {
            'message': 'æ–‡ä»¶ä¿å­˜æˆåŠŸ',
            'filename': os.path.basename(file_path),
            'size': len(content.encode('utf-8'))
        }
    
    except Exception as e:
        raise Exception(f'ä¿å­˜æ–‡ä»¶å¤±è´¥: {str(e)}')

def upload_background_image(file, process_id):
    """ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡"""
    from werkzeug.utils import secure_filename
    
    with processing_lock:
        if process_id not in processing_jobs:
            raise Exception('å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨')
        
        job = processing_jobs[process_id]
        if not job['output_dir']:
            raise Exception('å¤„ç†ä»»åŠ¡å°šæœªç”Ÿæˆè¾“å‡ºç›®å½•')
    
    # æ„å»ºç›®æ ‡ç›®å½•
    code_dir = os.path.join(job['output_dir'], 'final_results', 'Code')
    if not os.path.exists(code_dir):
        raise Exception('Codeç›®å½•ä¸å­˜åœ¨')
    
    # å®‰å…¨å¤„ç†æ–‡ä»¶å
    filename = secure_filename(file.filename)
    if not filename:
        raise Exception('æ— æ•ˆçš„æ–‡ä»¶å')
    
    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    valid_extensions = ('.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff', '.webp')
    if not filename.lower().endswith(valid_extensions):
        raise Exception(f'ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼ï¼Œæ”¯æŒçš„æ ¼å¼: {", ".join(valid_extensions)}')
    
    # ä¿å­˜æ–‡ä»¶
    file_path = os.path.join(code_dir, filename)
    try:
        file.save(file_path)
        
        # éªŒè¯æ–‡ä»¶ä¿å­˜
        if not os.path.exists(file_path):
            raise Exception('æ–‡ä»¶ä¿å­˜å¤±è´¥')
        
        file_size = os.path.getsize(file_path)
        
        return {
            'message': 'èƒŒæ™¯å›¾ç‰‡ä¸Šä¼ æˆåŠŸ',
            'filename': filename,
            'file_path': file_path,
            'size': file_size
        }
    
    except Exception as e:
        raise Exception(f'ä¸Šä¼ èƒŒæ™¯å›¾ç‰‡å¤±è´¥: {str(e)}')

def apply_background_to_code(process_id, background_file):
    """åº”ç”¨èƒŒæ™¯å›¾åˆ°æ‰€æœ‰ä»£ç æ–‡ä»¶"""
    import subprocess
    
    with processing_lock:
        if process_id not in processing_jobs:
            raise Exception('å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨')
        
        job = processing_jobs[process_id]
        if not job['output_dir']:
            raise Exception('å¤„ç†ä»»åŠ¡å°šæœªç”Ÿæˆè¾“å‡ºç›®å½•')
    
    # æ„å»ºç›®å½•è·¯å¾„
    code_dir = os.path.join(job['output_dir'], 'final_results', 'Code')
    if not os.path.exists(code_dir):
        raise Exception('Codeç›®å½•ä¸å­˜åœ¨')
    
    # æ£€æŸ¥èƒŒæ™¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    bg_file_path = os.path.join(code_dir, background_file)
    if not os.path.exists(bg_file_path):
        raise Exception('èƒŒæ™¯å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨')
    
    try:
        # è°ƒç”¨background.pyè„šæœ¬
        job = processing_jobs[process_id]
        chosen_format = job.get('output_format', 'video')
        if chosen_format == 'video':
            command = ['python3', 'background.py', code_dir, background_file]
        elif chosen_format == 'ppt':
            command = ['python3', 'replace_pptbackground.py', code_dir, background_file]
        
        result = subprocess.run(
            command,
            capture_output=True,
            text=True,
            check=True,
            timeout=30  # 30ç§’è¶…æ—¶
        )
        
        # ç»Ÿè®¡ä¿®æ”¹çš„æ–‡ä»¶æ•°é‡
        code_files = [f for f in os.listdir(code_dir) if f.endswith('.py')]
        
        return {
            'message': 'èƒŒæ™¯å›¾åº”ç”¨æˆåŠŸ',
            'modified_files': len(code_files),
            'background_file': background_file,
            'output': result.stdout if result.stdout else 'æ‰§è¡Œå®Œæˆ',
            'warnings': result.stderr if result.stderr else None
        }
    
    except subprocess.TimeoutExpired:
        raise Exception('èƒŒæ™¯å›¾åº”ç”¨è¶…æ—¶')
    except subprocess.CalledProcessError as e:
        error_msg = f'background.pyæ‰§è¡Œå¤±è´¥: {e}'
        if e.stderr:
            error_msg += f'\né”™è¯¯è¯¦æƒ…: {e.stderr}'
        raise Exception(error_msg)
    except Exception as e:
        raise Exception(f'åº”ç”¨èƒŒæ™¯å›¾å¤±è´¥: {str(e)}')

def search_editor_files(process_id, search_term):
    """æœç´¢ç¼–è¾‘å™¨æ–‡ä»¶"""
    # è·å–æ‰€æœ‰æ–‡ä»¶
    files_result = get_editor_files(process_id)
    all_files = files_result['files']
    page_videos = files_result['page_videos']
    
    if not search_term:
        return files_result
    
    # æœç´¢åŒ¹é…çš„æ–‡ä»¶
    search_term_lower = search_term.lower()
    matched_files = []
    matched_videos = []
    
    for file_info in all_files:
        if (search_term_lower in file_info['filename'].lower() or 
            search_term_lower in file_info['type'].lower()):
            matched_files.append(file_info)
    
    for video_info in page_videos:
        if (search_term_lower in video_info['filename'].lower() or 
            search_term_lower in video_info['type'].lower()):
            matched_videos.append(video_info)
    
    return {
        'files': matched_files,
        'page_videos': matched_videos,
        'search_term': search_term,
        'total_count': len(matched_files),
        'video_count': len(matched_videos),
        'original_count': len(all_files),
        'original_video_count': len(page_videos)
    }

def get_page_video_associations(process_id):
    """è·å–è§†é¢‘é¢„è§ˆä¸å¯¹åº”æ–‡ä»¶çš„å…³è”å…³ç³»"""
    with processing_lock:
        if process_id not in processing_jobs:
            raise Exception('å¤„ç†ä»»åŠ¡ä¸å­˜åœ¨')
        
        job = processing_jobs[process_id]
        if not job['output_dir']:
            raise Exception('å¤„ç†ä»»åŠ¡å°šæœªç”Ÿæˆè¾“å‡ºç›®å½•')
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    code_dir = os.path.join(job['output_dir'], 'final_results', 'Code')
    speech_dir = os.path.join(job['output_dir'], 'final_results', 'Speech')
    video_preview_dir = os.path.join(job['output_dir'], 'final_results', 'Video_Preview')
    
    associations = []
    
    # å¦‚æœè§†é¢‘é¢„è§ˆç›®å½•å­˜åœ¨
    if os.path.exists(video_preview_dir):
        for video_file in os.listdir(video_preview_dir):
            if video_file.endswith('.mp4'):
                # æå–åŸºç¡€åç§°ï¼ˆå»æ‰æ‰©å±•åï¼‰
                base_name = os.path.splitext(video_file)[0]
                
                # æŸ¥æ‰¾å¯¹åº”çš„ä»£ç æ–‡ä»¶å’Œè®²ç¨¿æ–‡ä»¶
                code_file = f"{base_name}_code.py"
                speech_file = f"{base_name}_speech.txt"
                
                code_path = os.path.join(code_dir, code_file)
                speech_path = os.path.join(speech_dir, speech_file)
                video_path = os.path.join(video_preview_dir, video_file)
                
                association = {
                    'base_name': base_name,
                    'video_file': video_file,
                    'video_path': video_path,
                    'video_size': os.path.getsize(video_path),
                    'code_file': code_file if os.path.exists(code_path) else None,
                    'speech_file': speech_file if os.path.exists(speech_path) else None,
                    'code_exists': os.path.exists(code_path),
                    'speech_exists': os.path.exists(speech_path)
                }
                
                associations.append(association)
    
    # æŒ‰åŸºç¡€åç§°æ’åº
    associations.sort(key=lambda x: x['base_name'])
    
    return {
        'associations': associations,
        'total_count': len(associations),
        'video_preview_dir': video_preview_dir
    } 

def ai_edit_code(original_code: str, edit_request: str, filename: str = None) -> dict:
    """
    ä½¿ç”¨AIæ™ºèƒ½ä½“ç¼–è¾‘ä»£ç 
    
    Args:
        original_code: åŸå§‹ä»£ç 
        edit_request: ç”¨æˆ·çš„ä¿®æ”¹éœ€æ±‚
        filename: æ–‡ä»¶åï¼ˆå¯é€‰ï¼‰
    
    Returns:
        dict: åŒ…å«ä¿®æ”¹åä»£ç çš„ç»“æœ
    """
    try:
        # è¯»å–é…ç½®
        with open('config.json', 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        api_key = config.get('api_key')
        model = config.get('model', 'gpt-4.5-preview')
        
        if not api_key:
            raise Exception("æœªé…ç½®APIå¯†é’¥")
        
        # æ„å»ºæç¤ºè¯
        file_info = f"æ–‡ä»¶å: {filename}\n\n" if filename else ""
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä»£ç ç¼–è¾‘åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„ä¿®æ”¹éœ€æ±‚ï¼Œå¯¹ç»™å®šçš„ä»£ç è¿›è¡Œä¿®æ”¹ã€‚

{file_info}ç”¨æˆ·ä¿®æ”¹éœ€æ±‚ï¼š
{edit_request}

åŸå§‹ä»£ç ï¼š
```
{original_code}
```

è¯·æä¾›ä¿®æ”¹åçš„å®Œæ•´ä»£ç ã€‚ä½ çš„å›ç­”åº”è¯¥åªåŒ…å«ä¿®æ”¹åçš„ä»£ç ï¼Œä¸éœ€è¦ä»»ä½•è§£é‡Šæˆ–è¯´æ˜ã€‚ç¡®ä¿ï¼š
1. ä¿æŒä»£ç çš„åŸºæœ¬ç»“æ„å’ŒåŠŸèƒ½
2. åªä¿®æ”¹éœ€è¦ä¿®æ”¹çš„éƒ¨åˆ†
3. ç¡®ä¿ä¿®æ”¹åçš„ä»£ç è¯­æ³•æ­£ç¡®
4. ä¿æŒä»£ç é£æ ¼ä¸€è‡´

ä¿®æ”¹åçš„ä»£ç ï¼š"""

        # è°ƒç”¨APIè·å–ä¿®æ”¹åçš„ä»£ç 
        ai_response = process_text(prompt, api_key, model)
        
        # æ¸…ç†å“åº”ï¼Œæå–ä»£ç éƒ¨åˆ†
        modified_code = ai_response.strip()
        
        # å¦‚æœå“åº”è¢«ä»£ç å—åŒ…è£¹ï¼Œæå–å…¶ä¸­çš„ä»£ç 
        if modified_code.startswith('```'):
            lines = modified_code.split('\n')
            # å»æ‰ç¬¬ä¸€è¡Œçš„```å’Œå¯èƒ½çš„è¯­è¨€æ ‡è¯†
            if len(lines) > 1:
                lines = lines[1:]
            # å»æ‰æœ€åä¸€è¡Œçš„```
            if lines and lines[-1].strip() == '```':
                lines = lines[:-1]
            modified_code = '\n'.join(lines)
        
        return {
            'original_code': original_code,
            'modified_code': modified_code,
            'edit_request': edit_request,
            'filename': filename
        }
        
    except Exception as e:
        raise Exception(f"AIç¼–è¾‘ä»£ç å¤±è´¥: {str(e)}")